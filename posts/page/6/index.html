<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | Cong's Log</title><meta name=keywords content><meta name=description content="Posts - Cong's Log"><meta name=author content="Cong"><link rel=canonical href=https://congchan.github.io/posts/><link crossorigin=anonymous href=/assets/css/stylesheet.1f908d890a7e84b56b73a7a0dc6591e6e3f782fcba048ce1eb46319195bedaef.css integrity="sha256-H5CNiQp+hLVrc6eg3GWR5uP3gvy6BIzh60YxkZW+2u8=" rel="preload stylesheet" as=style><link rel=icon href=https://congchan.github.io/favicons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://congchan.github.io/favicons/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://congchan.github.io/favicons/favicon-32x32.png><link rel=apple-touch-icon href=https://congchan.github.io/favicons/apple-touch-icon.png><link rel=mask-icon href=https://congchan.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://congchan.github.io/posts/index.xml><link rel=alternate hreflang=en href=https://congchan.github.io/posts/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}]})'></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-6T0DPR6SMC"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-6T0DPR6SMC")}</script><meta property="og:url" content="https://congchan.github.io/posts/"><meta property="og:site_name" content="Cong's Log"><meta property="og:title" content="Posts"><meta property="og:description" content="Hi, this is Cong. I’m documenting my learning notes in this blog."><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Posts"><meta name=twitter:description content="Hi, this is Cong. I’m documenting my learning notes in this blog."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://congchan.github.io/posts/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://congchan.github.io/ accesskey=h title="Cong's Log (Alt + H)">Cong's Log</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://congchan.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://congchan.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://congchan.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://congchan.github.io/>Home</a></div><h1>Posts
<a href=/posts/index.xml title=RSS aria-label=RSS><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Inf Course Note - Natural Language Understanding</h2></header><div class=entry-content><p>爱丁堡大学信息学院课程笔记 Natural Language Understanding, Informatics, University of Edinburgh
References: Natural language understanding CS224n: Natural Language Processing with Deep Learning Lecture Slides from the Stanford Coursera course Natural Language Processing, by Dan Jurafsky and Christopher Manning
Meaning representations 意思的表达有很多方法。一种有效的表示单词的含义的方法是 distributional semantic.
Semantics (from Ancient Greek: σημαντικός sēmantikos, “significant”) is the linguistic and philosophical study of meaning, in language, programming languages, formal logics, and semiotics.
语义学 Semantics 在语言学中的研究目的在于找出语义表达的规律性、内在解释、不同语言在语义表达方面的个性以及共性；与计算机科学相关的语义学研究在于机器对自然语言的理解。
Tradition solution of usable meaning in a computer: Use e.g. WordNet, a resource containing lists of synonym sets and hypernyms.
...</p></div><footer class=entry-footer><span title='2018-06-30 00:00:00 +0000 UTC'>2018-06-30</span>&nbsp;·&nbsp;28 min&nbsp;·&nbsp;Cong Chan</footer><a class=entry-link aria-label="post link to Inf Course Note - Natural Language Understanding" href=https://congchan.github.io/posts/inf-course-note-natural-language-understanding/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Inf Course Note - Parallel Programming Language and Systems</h2></header><div class=entry-content><p>爱丁堡大学信息学院课程笔记 Parallel Programming Language and Systems, Informatics, University of Edinburgh
Reference: http://www.inf.ed.ac.uk/teaching/courses/ppls/ CMU 15213: Introduction to Computer Systems (ICS) Computer Systems: A Programmer’s Perspective A Comprehensive MPI Tutorial Resource A chapter on MPI from Ian Foster’s online Book Designing and Building Parallel Programs
Introduction to parallel computer architecture Covering some of the nasty issues presented by the shared memory model, including weak consistency models and false sharing in the cache, and some architectural issues for the multicomputer model.
...</p></div><footer class=entry-footer><span title='2018-06-30 00:00:00 +0000 UTC'>2018-06-30</span>&nbsp;·&nbsp;63 min&nbsp;·&nbsp;Cong Chan</footer><a class=entry-link aria-label="post link to Inf Course Note - Parallel Programming Language and Systems" href=https://congchan.github.io/posts/inf-course-note-parallel-programming-language-and-systems/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Inf Course Note - Software Architecture, Process, and Management</h2></header><div class=entry-content><p>爱丁堡大学信息学院课程笔记 Software Architecture, Process, and Management, Informatics, University of Edinburgh
Reference: microsoft IBM Software Architecture in Practice (3rd edition), Bass, Clements, and Kazman
What is Software Architecture? Software architecture is often described as the organization or structure of a system, where the system represents a collection of components that accomplish a specific function or set of functions.
grouping components into areas of concern (layers): For example, the UI, business processing, and data access. focus on interaction between the components and how different components work together. 在书中的定义：
...</p></div><footer class=entry-footer><span title='2018-06-30 00:00:00 +0000 UTC'>2018-06-30</span>&nbsp;·&nbsp;45 min&nbsp;·&nbsp;Cong Chan</footer><a class=entry-link aria-label="post link to Inf Course Note - Software Architecture, Process, and Management" href=https://congchan.github.io/posts/inf-course-note-software-architecture-process-and-management/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Inf Course Note - Software Testing</h2></header><div class=entry-content><p>爱丁堡大学信息学院课程笔记 Software Testing, Informatics, University of Edinburgh
Reference: http://www.inf.ed.ac.uk/teaching/courses/st/2017-18/index.html Pezze and Young, Software Testing and Analysis: Process, Principles and Techniques, Wiley, 2007.
Why Software Testing? 1, 软件的漏洞, 错误和失效 Software Faults, Errors & Failures The problem start with Faults,
Fault(BUG): latent error, mistakes in programming.
e.g add(x, y) = x * y. With the Faults in programs, if and only if executing add(x, y) = x * y, the fault being activated, and generate an Errors.
...</p></div><footer class=entry-footer><span title='2018-06-30 00:00:00 +0000 UTC'>2018-06-30</span>&nbsp;·&nbsp;49 min&nbsp;·&nbsp;Cong Chan</footer><a class=entry-link aria-label="post link to Inf Course Note - Software Testing" href=https://congchan.github.io/posts/inf-course-note-software-testing/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>深入理解word2vec</h2></header><div class=entry-content><p>Word2vec Mikolov et al.
How to represent meanings? 如何在数学上表达词义？
Vector space models (VSMs) 表示把单词映射到(嵌入)连续的矢量空间, 而且理论上语义相似的单词会映射到空间中临近的位置。VSMs是一个历史悠久的NLP理论，但所有实现方法都不同程度依赖于Distributional Hypothesis, 即出现在相同（相似）的上下文中的单词具有相同（相似）的语义意义。利用此原则的方法大致可以分为两类: Count-based methods (例如, Latent Semantic Analysis))和Predictive models(例如 neural net language models (NNLM))。
具体的区别详见Baroni et al.. 但总的来说，Count-based methods 统计词汇间的共现频率，然后把co-occurs matrix 映射到向量空间中；而Predictive models直接通过上下文预测单词的方式来学习向量空间（也就是模型参数空间）。
Word2vec 是一种计算特别高效的predictive model, 用于从文本中学习word embeddings。它有两种方案, Continuous Bag-of-Words model (CBOW) 和 Skip-Gram model (Section 3.1 and 3.2 in Mikolov et al.).
从算法上讲, 两种方案是相似的, 只不过 CBOW 会从source context-words ('the cat sits on the')预测目标单词(例如"mat"); 而skip-gram则相反, 预测目标单词的source context-words。Skip-gram这种做法可能看起来有点随意. 但从统计上看, CBOW 会平滑大量分布信息(通过将整个上下文视为一个观测值), 在大多数情况下, 这对较小的数据集是很有用的。但是, Skip-gram将每个context-target pair视为新的观测值, 当数据集较大时, 这往往带来更好的效果。
...</p></div><footer class=entry-footer><span title='2018-06-22 00:00:00 +0000 UTC'>2018-06-22</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;Cong Chan</footer><a class=entry-link aria-label="post link to 深入理解word2vec" href=https://congchan.github.io/posts/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3word2vec/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>循环神经网络</h2></header><div class=entry-content><p>循环神经网络 当人类阅读时，会根据对之前单词的理解和记忆来辅助理解当前看到的每个单词。也就是人能够很好地处理语言的长距离依赖特性（long-term dependency）。在自然语言处理任务中，很多传统的模型无法做到这一点，比如前馈神经网络；而传统的n-gram模型固然可以通过把把n系数增大来捕捉长距离依赖，但带来的非常巨大的内存消耗。
循环神经网络（Recurrent Neural Networks, RNNs)可以看做是多个共享参数的前馈神经网络不断叠加的结果 ![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png “A recurrent neural network and the unfolding in time of the computation involved in its forward computation. “image from: http://colah.github.io”)
这里的核心是想办法解码历史信息, 即通过递归方程$s_i = R(x_i, s_{i−1})$让$s_i$解码序列$x_{1:n}$. 比如把所有历史信息累加就是一种非常简单粗暴的方式, 这样得到的是连续词袋模型(continuous-bag-of-words model)$s_i = R_{CBOW}(x_i, s_{i-1}) = x_i + s_{i−1}$, 虽然简单，但这种RNN其实忽略了数据的时序性质。
一般意义上的RNN是指Elman Network or Simple-RNN (S-RNN)(Elman [1990]), $s_i = R_{SRNN}(x_i, s_{i-1}) = g(x_iW^x + s_{i−1}W^s + b)$, 也就是把历史信息先进行线性变换(乘以矩阵), 再和bias加起来, 再通过一个非线性激活函数(tanh或ReLU). 添加了线性变换再进行非线性激活, 使网络对输入的顺序变得敏感。
在使用时, 给定输入序列（单词序列或语音）得出输出序列的过程如下：
...</p></div><footer class=entry-footer><span title='2018-05-15 00:00:00 +0000 UTC'>2018-05-15</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;Cong Chan</footer><a class=entry-link aria-label="post link to 循环神经网络" href=https://congchan.github.io/posts/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Python Digest</h2></header><div class=entry-content><p>What you will get from this Python digest: 1, Learn advanced python programming. 2, Learn new concepts, patterns, and methods that will expand your programming abilities, helping move you from a novice to an expert programmer. 3, Practice going from a problem description to a solution, using a series of assignments.
Operator Emulating numeric types In-place operation: One modifies the data-structure itself
object.__iadd__(self, other) object.__isub__(self, other) object.__imul__(self, other) object.__imatmul__(self, other) object.__itruediv__(self, other) object.__ifloordiv__(self, other) object.__imod__(self, other) object.__ipow__(self, other[, modulo]) object.__ilshift__(self, other) object.__irshift__(self, other) object.__iand__(self, other) object.__ixor__(self, other)¶ object.__ior__(self, other) These methods are called to implement the augmented arithmetic assignments. These methods should attempt to do the operation in-place (modifying self) and return the result (which could be, but does not have to be, self). If x is an instance of a class with an __iadd__() method, x += y is equivalent to x = operator.iadd(x, y)
...</p></div><footer class=entry-footer><span title='2018-05-08 00:00:00 +0000 UTC'>2018-05-08</span>&nbsp;·&nbsp;14 min&nbsp;·&nbsp;Cong Chan</footer><a class=entry-link aria-label="post link to Python Digest" href=https://congchan.github.io/posts/python-digest/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Computer Systems - A Programmer's Perspective (CSAPP) - CMU 15213</h2></header><div class=entry-content><p>CSAPP 非常巧妙的把程序设计及优化、数字电路基础、指令集体系、汇编语言、存储器体系结构、链接与装载、进程、虚存等来自不同学科的核心知识点和在一起，并以程序员的视角呈现; 告诉我们作为一个程序员，究竟需要对计算机的硬件了解到什么程度？
本笔记是 CMU CSAPP 的学习笔记, 使用 CMU 15-213, UW CSE351 的课程视频, lab, 作业, project 辅助练习.
Computer Systems: A Programmer’s Perspective (csapp), 豆瓣-深入理解计算机系统 卡内基梅隆大学 CMU 15-213 Introduction to Computer Systems (ICS) 华盛顿大学 UW CSE351: The Hardware/Software Interface 信息的表达与操作 Information is Bits + Context. Study systems by tracing the lifetime of the hello program, from the time it is created by a programmer, until it runs on a system, prints its simple message, and terminates.
...</p></div><footer class=entry-footer><span title='2018-01-29 00:00:00 +0000 UTC'>2018-01-29</span>&nbsp;·&nbsp;14 min&nbsp;·&nbsp;Cong Chan</footer><a class=entry-link aria-label="post link to Computer Systems - A Programmer's Perspective (CSAPP) - CMU 15213" href=https://congchan.github.io/posts/computer-systems-a-programmers-perspective-csapp-cmu-15213/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>神经网络用于文本分类</h2></header><div class=entry-content><p>文本分类 文本分类是很多业务问题中广泛使用到的NLP/监督机器学习（ML）。文本分类的目标是自动将文本/文档分类为一个或多个预定义类别。目前的成熟思路是用词向量解码文本，然后使用传统机器学习模型或者深度神经网络模型来做分类。
文本分类是学术界和工业界非常活跃的研究领域。本文主要介绍用于文本分类的几种神经网络模型方法，并比较它们的性能，代码实现主要基于Keras。文中代码都在这个DeepTextGitHub项目中.
文本分类的一些示例包括：
从社交媒体中了解受众情绪（😁 😐 😥） 检测垃圾邮件和非垃圾邮件 自动标记客户查询 将新闻文章📰分类为预定义主题 端到端文本分类流水线 端到端文本分类流水线由以下组件组成：
训练文本：输入文本，有监督模型能够通过已标注数据来学习和预测所需的类。 特征向量：特征向量是用于解码输入数据特征的信息的向量。 标签：预定义的类别/类，作为模型预测的目标。 算法模型：能够处理文本分类的算法（在我们的例子中：CNN，RNN，HAN, Fasttext） 预测：已经在历史数据集上训练过的模型，可以用于执行标签预测。 这里使用汽车消费者的评测数据集，在tsv文件中, 第一列是序号对我们没用, 第二列是label(0, 1)，分别代表（消极，积极）评价，第三列是文本.
1 操控性舒服、油耗低，性价比高 0 动力的确有点点让我相信了up的确是个代步车而已! 1 1。车的外观很喜欢。2。省油，现在磨合期7.3，相信以后还会下降。 1 内饰的做工和用料同级别同价位最厚道的 0 减震系统太硬！ 数据处理使用的类，具体见代码链接
class DataProcessor(object): """ Base class for data converters for sequence classification data sets. helper funcitons [read_tsv, read_text, read_json] """ ... class SampleProcessor(DataProcessor): """ Sample processor for the classification data set. Tranform the text to tensor for training if use pre-train model, need vocabulary file usage: process data files >>> processer = SampleProcessor(config, ) provide your own data in list format [train_X, train_Y, test_X, test_Y] >>> processer = SampleProcessor(config, data) """ 词向量 使用包含外部知识的embedding表达字词是目前的主流方法，经典的如word2vec，GLoVe，较新进的 ELMo，BERT，等预训练向量，集成了关于单词的新信息（词汇和语义），这些信息已经在非常大的数据集上进行了训练和提炼。
...</p></div><footer class=entry-footer><span title='2018-01-15 00:00:00 +0000 UTC'>2018-01-15</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;Cong Chan</footer><a class=entry-link aria-label="post link to 神经网络用于文本分类" href=https://congchan.github.io/posts/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%94%A8%E4%BA%8E%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>信息抽取</h2></header><div class=entry-content><p>信息抽取 1997年MUC会议（MUC-7） 召开时，评测任务已经增加到5个： ① 场景模板（scenario template, ST）填充：定义了描述场景的模板及槽填充规范； ② 命名实体（named entity, NE）识别：识别出文本中出现的专有名称和有意义的数量短语， 并加以归类； ③ 共指（coreference, CR）关系确定：识别出给定文本中的参照表达（ referring expressions），并确定这些表达之间的共指关系； ④ 模板元素（template element, TE）填充：类似于人名和组织机构名识别，但是要求系统必须识别出实体的描述和名字，如果一个实体在文本中被提到了多次，使用了几种可能的描述和不同的名字形式，要求系统都要把它们识别出来，一个文本中的每个实体只有一个模板元素［Grishman and Sundheim, 1996］； ⑤ 模板关系（template relation, TR）：确定实体之间与特定领域无关的关系。
1999年起美国NIST组织了自动内容抽取（automatic content extraction, ACE）评测会议，旨在研究和 开发自动内容技术以支持对三种不同来源文本（普通文本、经语音识别后得到的文本、 由OCR识别得到的文本）的自动处理，以实现新闻语料中出现的实体、关系、事件等内容的自动抽取。评测任务设计: 实体检测与跟踪（entity detection and tracking, EDT）、数值检测与识别（value detection and recognition, VDR）、时间识别和规范化（time expression recognition and normalization, TERN）、关系检测与描述（relation detection and characterization, RDC）、事件检测与描述（event detection and characterization, EDC）和实体翻译（entity translation, ET）等。
TF-IDF 关键词抽取 import jieba.analyse jieba.analyse.extract_tags(sentence, topK=20, withWeight=False, allowPOS=()) sentence 为待提取的文本 topK 为返回几个 TF/IDF 权重最大的关键词，默认值为 20 withWeight 为是否一并返回关键词权重值，默认值为 False allowPOS 仅包括指定词性的词，默认值为空，即不筛选. 如电商评论指定要形容词
...</p></div><footer class=entry-footer><span title='2018-01-11 00:00:00 +0000 UTC'>2018-01-11</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Cong Chan</footer><a class=entry-link aria-label="post link to 信息抽取" href=https://congchan.github.io/posts/%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://congchan.github.io/posts/page/5/>«&nbsp;Prev&nbsp;5/14
</a><a class=next href=https://congchan.github.io/posts/page/7/>Next&nbsp;7/14&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://congchan.github.io/>Cong's Log</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>