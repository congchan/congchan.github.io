<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Stanford CS106A/B Programming Intro 斯坦福大学编程入门课 | Cong's Log</title><meta name=keywords content="Software Engineer,C++,编程,Java"><meta name=description content="Stanford CS106B Programming Abstractions 和 CS106A 的学习笔记. 课程作业(cs106b spring 2017)实现代码见 https://github.com/ShootingSpace/cs106b-programming-abstraction
Topics:
A: Intro (by Java)
B: Recursion, algorithms analysis (sort/search/hash), dynamic data structures (lists, trees, heaps), data abstraction (stacks, queues, maps), implementation strategies/tradeoffs

Purposes

become acquainted with the C++ programming language
learn more advanced programming techniques
explore classic data structures and algorithms
and apply these tools to solving complex problems

Reference

Text Book: Data Structures & Algorithm Analysis in C++, 4th ed, by Mark A. Weiss
Text Book: Programming Abstractions in C++ 1st Edition by Eric Roberts
Text Book: Algorithms, 4th Edition
Blog: Red Blob Games, Amit’s A* Pages


Coding style
Why writing clean, well-structured code"><meta name=author content="Cong Chan"><link rel=canonical href=https://congchan.github.io/posts/stanford-cs106a/b-programming-intro-%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8%E8%AF%BE/><link crossorigin=anonymous href=/assets/css/stylesheet.1f908d890a7e84b56b73a7a0dc6591e6e3f782fcba048ce1eb46319195bedaef.css integrity="sha256-H5CNiQp+hLVrc6eg3GWR5uP3gvy6BIzh60YxkZW+2u8=" rel="preload stylesheet" as=style><link rel=icon href=https://congchan.github.io/favicons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://congchan.github.io/favicons/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://congchan.github.io/favicons/favicon-32x32.png><link rel=apple-touch-icon href=https://congchan.github.io/favicons/apple-touch-icon.png><link rel=mask-icon href=https://congchan.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://congchan.github.io/posts/stanford-cs106a/b-programming-intro-%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8%E8%AF%BE/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}]})'></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-6T0DPR6SMC"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-6T0DPR6SMC")}</script><meta property="og:url" content="https://congchan.github.io/posts/stanford-cs106a/b-programming-intro-%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8%E8%AF%BE/"><meta property="og:site_name" content="Cong's Log"><meta property="og:title" content="Stanford CS106A/B Programming Intro 斯坦福大学编程入门课"><meta property="og:description" content="Stanford CS106B Programming Abstractions 和 CS106A 的学习笔记. 课程作业(cs106b spring 2017)实现代码见 https://github.com/ShootingSpace/cs106b-programming-abstraction
Topics: A: Intro (by Java) B: Recursion, algorithms analysis (sort/search/hash), dynamic data structures (lists, trees, heaps), data abstraction (stacks, queues, maps), implementation strategies/tradeoffs
Purposes become acquainted with the C++ programming language learn more advanced programming techniques explore classic data structures and algorithms and apply these tools to solving complex problems Reference Text Book: Data Structures & Algorithm Analysis in C++, 4th ed, by Mark A. Weiss Text Book: Programming Abstractions in C++ 1st Edition by Eric Roberts Text Book: Algorithms, 4th Edition Blog: Red Blob Games, Amit’s A* Pages Coding style Why writing clean, well-structured code"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2017-06-23T00:00:00+00:00"><meta property="article:modified_time" content="2017-06-23T00:00:00+00:00"><meta property="article:tag" content="Software Engineer"><meta property="article:tag" content="C++"><meta property="article:tag" content="编程"><meta property="article:tag" content="Java"><meta name=twitter:card content="summary"><meta name=twitter:title content="Stanford CS106A/B Programming Intro 斯坦福大学编程入门课"><meta name=twitter:description content="Stanford CS106B Programming Abstractions 和 CS106A 的学习笔记. 课程作业(cs106b spring 2017)实现代码见 https://github.com/ShootingSpace/cs106b-programming-abstraction
Topics:
A: Intro (by Java)
B: Recursion, algorithms analysis (sort/search/hash), dynamic data structures (lists, trees, heaps), data abstraction (stacks, queues, maps), implementation strategies/tradeoffs

Purposes

become acquainted with the C++ programming language
learn more advanced programming techniques
explore classic data structures and algorithms
and apply these tools to solving complex problems

Reference

Text Book: Data Structures & Algorithm Analysis in C++, 4th ed, by Mark A. Weiss
Text Book: Programming Abstractions in C++ 1st Edition by Eric Roberts
Text Book: Algorithms, 4th Edition
Blog: Red Blob Games, Amit’s A* Pages


Coding style
Why writing clean, well-structured code"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://congchan.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Stanford CS106A/B Programming Intro 斯坦福大学编程入门课","item":"https://congchan.github.io/posts/stanford-cs106a/b-programming-intro-%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8%E8%AF%BE/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Stanford CS106A/B Programming Intro 斯坦福大学编程入门课","name":"Stanford CS106A\/B Programming Intro 斯坦福大学编程入门课","description":"Stanford CS106B Programming Abstractions 和 CS106A 的学习笔记. 课程作业(cs106b spring 2017)实现代码见 https://github.com/ShootingSpace/cs106b-programming-abstraction\nTopics: A: Intro (by Java) B: Recursion, algorithms analysis (sort/search/hash), dynamic data structures (lists, trees, heaps), data abstraction (stacks, queues, maps), implementation strategies/tradeoffs\nPurposes become acquainted with the C++ programming language learn more advanced programming techniques explore classic data structures and algorithms and apply these tools to solving complex problems Reference Text Book: Data Structures \u0026amp; Algorithm Analysis in C++, 4th ed, by Mark A. Weiss Text Book: Programming Abstractions in C++ 1st Edition by Eric Roberts Text Book: Algorithms, 4th Edition Blog: Red Blob Games, Amit’s A* Pages Coding style Why writing clean, well-structured code\n","keywords":["Software Engineer","C++","编程","Java"],"articleBody":"Stanford CS106B Programming Abstractions 和 CS106A 的学习笔记. 课程作业(cs106b spring 2017)实现代码见 https://github.com/ShootingSpace/cs106b-programming-abstraction\nTopics: A: Intro (by Java) B: Recursion, algorithms analysis (sort/search/hash), dynamic data structures (lists, trees, heaps), data abstraction (stacks, queues, maps), implementation strategies/tradeoffs\nPurposes become acquainted with the C++ programming language learn more advanced programming techniques explore classic data structures and algorithms and apply these tools to solving complex problems Reference Text Book: Data Structures \u0026 Algorithm Analysis in C++, 4th ed, by Mark A. Weiss Text Book: Programming Abstractions in C++ 1st Edition by Eric Roberts Text Book: Algorithms, 4th Edition Blog: Red Blob Games, Amit’s A* Pages Coding style Why writing clean, well-structured code\nThe messy code trap harder to build and debug harder to clean up Decomposition Decompose the problem, not the programs, program is written from the already decomposed framework. Logical and readable Methods should be short and to the point, Strive to design methods that are general enough for a variety of situations and achieve specifics trough use of parameters. Avoid redundants methods. Avoid repeated lines or methods. Readable code: Writing readable code not only help future readers but also help avoid your own bugs: Because bugs are codes that fail to expresses idea in mind. Reader can see the algorithmic idea when sweeping the code. Works correctly in all situations: Using a listing of specific test cases to exercise the program on.\nThe overall approach is straight-forward, data structure is cleanly organized, tasks are nicely decomposed, algorithms are clear and easy to follow, comments are helpful, layout is consistent.\nHow to write clean, well-structured code? Choosing good names for variables Name reflect what it stores, normally nouns; In Java, conventionly, begin variables with the first word lowercase, and upper case later words bestScore Widely used idiomatic one-letter names: i, j, k for int loop counters; x, y, z for coordinates. Choosing good names for methods Name reflect the action they perform, verbs normally; The prefixes get and set have a typical role: A get method gets a piece of information from an object; set methods are used to pass a value in to an object Returning a boolean are ofter named starting with is or has. Using whitespace to separate logical parts: Put in blank lines to separate the code into its natural sub sections that accomplis logical sub-parts of the whole algoriithm. Each little section might have a comment to describe what it accomplishes. Use Indentation to show hierarchy structure Comments Attributions: consider as an important tennet of academic integrity. Comments Examples of information you might include in comments:\nGeneral overview. What are the goals and requirements of this program? this function? The overview comment should also contain author and version information: who worked on this file and when. Data structures. How is the data stored? How is it ordered, searched, accessed? Design decisions. Why was a particular data structure or algorithm chosen? What other strategies were tried and rejected? Error handling. How are error conditions handled? What assumptions are made? What happens if those assumptions are violated? Nitty-gritty code details. Comments are invaluable for explaining the inner workings of particularly complicated (often labeled “clever”) paths of the code. Planning for the future. How might one make modifications or extensions later? And more… (This list is by no means exhaustive) ADT An abstract data type is a set of objects together with a set of operations. Abstract data types are mathematical abstractions; nowhere in an ADT’s definition is there any mention of how the set of operations is implemented. Objects such as lists, sets, and graphs, along with their operations, can be viewed as ADTs. Also there are search tree, set, hash table, priority queue.\nClient uses class as abstraction Invokes public operations only Internal implementation not relevant! Client can’t and shouldn’t muck with internals: Class data should private Imagine a “wall” between client and implementor Wall prevents either from getting involved in other’s business Interface is the “chink” in the wall Conduit allows controlled access between the two Consider Lexicon Abstraction is a word list, operations to verify word/prefix How does it store list? using array? vector? set? does it matter to client? Why ADTs?\nAbstraction: Client insulated from details, works at higher-level Encapsulation: Internals private to ADT, not accessible by client Independence: Separate tasks for each side (once agreed on interface) Flexibility: ADT implementation can be changed without affecting client The C++ language includes, in its library, an implementation of common data structures. This part of the language is popularly known as the Standard Template Library (STL). In general, these data structures are called collections or containers.\nIterators In the STL, a position is represented by a nested type, iterator.\nGetting an Iterator\niterator begin( ) returns an appropriate iterator representing the first item in the container. iterator end( ) returns an appropriate iterator representing the endmarker in the container (i.e., the position after the last item in the container). Iterator Methods * itr++ and ++itr advances the iterator itr to the next location. Both the prefix and postfix forms are allowable. * itr returns a reference to the object stored at iterator itr’s location. The reference returned may or may not be modifiable (we discuss these details shortly). * itr1==itr2 / itr1!=itr2, returns true if iterators itr1 and itr2 refer to the same / different location and false otherwise.\nContainer Operations that require Iterators. The three most popular methods that require iterators are those that add or remove from the list (either a vector or list) at a specified position:\niterator insert( iterator pos, const Object \u0026 x ): adds x into the list, prior to the position given by the iterator pos. This is a constant-time operation for list, but not for vector. The return value is an iterator representing the position of the inserted item. iterator erase( iterator pos ): removes the object at the position given by the iterator. This is a constant-time operation for list, but not for vector. The return value is the position of the element that followed pos prior to the call. This operation invalidates pos, which is now stale, since the container item it was viewing has been removed. iterator erase( iterator start, iterator end ): removes all items beginning at position start, up to, but not including end. Observe that the entire list can be erased by the call c.erase( c.begin( ), c.end( ) ) Range for loop: C++11 also allows the use of the reserved word auto to signify that the compiler will automatically infer the appropriate type, for simple data type: for( auto x : squares ) cout\u003c\u003c x; for complicate data type like map: Each element of the container is a map::value_type, which is a typedef for std::pair. Consequently, you’d write this as for (auto\u0026 kv : myMap) { std::cout \u003c\u003c kv.first \u003c\u003c \" has value \" \u003c\u003c kv.second \u003c\u003c std::endl; } Recursion Helper Function\nNo clear definition of helper function How to utilize helper function to help constructing recursion algarithm: construct a same-name recursive function with extra parameters to pass in. In some other cases, decomposition with several step into a function is itself a helper function, which help to make the main function simple and clean. Exhaustive recursion Permutations/subsets are about choice\nBoth have deep/wide tree of recursive calls Depth represents total number of decisions made Width of branching represents number of available options per decision Explores every possible option at every decision point, typically very expensive, N! permutations, 2N subsets Recursive Backtracking Partial exploration of exhaustive space. In the case that if we are interested in finding any solution, whichever one that works out first is fine. If we eventually reach our goal from here, we have no need to consider the paths not taken. However, if this choice didn’t work out and eventually leads to nothing but dead ends; when we backtrack to this decision point, we try one of the other alternatives.\nThe back track based on the stacks of recursion, if a stack return false (or fail result), we back to previous stack and try another way(un-making choice). Need something return(normally bool) to step out of the entire recursion once any one solution found. One great tip for writing a backtracking function is to abstract away the details of managing the configuration (what choices are available, making a choice, checking for success, etc.) into other helper functions so that the body of the recursion itself is as clean as can be. This helps to make sure you have the heart of the algorithm correct and allows the other pieces to be developed, test, and debugged independently. Pointer lvalue: In C++, any expression that refers to an internal memory location capable of storing data is called an lvalue (pronounced “ell-value”). x = 1.0;\nDeclaring pointer variables\nint main() { -------------------------------------------------- // Declaration, in the stack // Not yet initialized! int num; int *p, *q; // If cout \u003c\u003c num \u003c\u003c p \u003c\u003c q \u003c\u003c endl; // There will be junk number, junk address. // If now *p=10, it may blow up, because what *p point to is an address points to somewhere around that could be invalid. --------------------------------------------------- // new operator allocate memory from the heap, returns address p = new int; // P -----\u003e [ int ] （heep 1000） *p = 10; // P -----\u003e [ 10 ] （heep 1000） q = new int; // P -----\u003e [ int ] （heep 1004） *q = *p; // q -----\u003e [ 10 ] （heep 1004） q = p; // q -----\u003e [ 10 ] （heep 1000） // [ 10 ] （heep 1004） became orphan, and could not be reclaim back --------------------------------------------------- delete p; // [ 10 ] （heep 1000）memory was reclaimed and free, // and available for others as [ ]（heep 1000）, // but p still hold the address delete q; // bad idea, [ 10 ]（heep 1000） already been reclaimed! q = NULL; // NULL is zero pointer, means the pointer does not hold any address, // used as sentinel value, sometimes better than delete. // Accessing \"deleted\" memory has unpredictable consequences --------------------------------------------------- // int *p declaration reserves only a single word, which is large enough to hold a machine address. // ≠ // int *p = NULL declare pointer p as nullptr --------------------------------------------------- (*newOne).name = name // \".\" \u003e \"*\" newOne-\u003ename = name Use of pointer Big program that contains a certain amout of classes and objects that are share some relationship. Instead of copying data from each other, using pointer to point to specific data is better:\nSaves space by not repeating the same information. If some objects gets new information to update, change in one place only! Dynamic allocation Request memory: To acquire new memory when you need it and to free it explicitly when it is no longer needed. Acquiring new storage when the program is running. While the program is running, you can reserve part of the unallocated memory, leaving the rest for subsequent allocations. The pool of unallocated memory available to a program is called the heap. int *p = new int; //new operator to allocate memory from the heap In its simplest form, the new operator takes a type and allocates space for a variable of that type located in the heap. The call to new operator will return the address of a storage location in the heap that has been set aside to hold an integer.\nFree occupied memory: Delete which takes a pointer previously allocated by new and returns the memory associated with that pointer to the heap.\nTree Node, tree, subtree, parent, child, root, edge, leaf For any node ni, the depth of ni is the length of the unique path from the root to ni. The height of ni is the length of the longest path from ni to a leaf Rules for all trees Recursive branching structure Single root node Every node reachable from root by unique path Binary tree Each node has at most 2 children.\nBinary search tree\nAll nodes in left subtree are less than root, all nodes in right subtree are greater. Arranged for efficient search/insert. It is the basis for the implementation of two library collections classes, set and map. Most operations’ average running time is O(log N). Operating on trees Many tree algorithms are recursive\nHandle current node, recur on subtrees Base case is empty tree (NULL) Tree traversals to visit all nodes, order of traversal:\nPre: cur, left, right In: left, cur, right Post: left, right, cur Others: level-by-level, reverse orders, etc Balanced Search Trees Binary search tree have poor worst-case performance.\nTo make costs are guaranteed to be logarithmic, no matter what sequence of keys is used to construct them, the ideal is to keep binary search trees perfectly balanced. Unfortunately, maintaining perfect balance for dynamic insertions is too expensive. So consider data structure that slightly relaxes the perfect balance requirement to provide guaranteed logarithmic performance not just for the insert and search operations, but also for all of the ordered operations (except range search).\nAVL tree Adelson-Velskii and Landis tree is a binary search tree with a balance condition.\nTrack balance factor for each node: Height of right subtree - height of left subtree information is kept for each node (in the node structure) For every node in the tree, the height of the left and right subtrees can differ by at most 1 (Balance factor = 0 or 1). When balance factor hits 2, restructure Rotation moves nodes from heavy to light side Local rearrangement around specific node When finished, node has 0 balance factor Single rotation: one time rotation between new insert node and its parent node Double rotation: two single rotation of the new insert node 2-3 trees Allow the nodes in the tree to hold more than one key: 3-nodes, which hold three links and two keys.\nA 2-3 search tree is a tree that is either empty or\nA 2-node, with one key (and associated value) and two links, a left link to a 2-3 search tree with smaller keys, and a right link to a 2-3 search tree with larger keys A 3-node, with two keys (and associated values) and three links, a left link to a 2-3 search tree with smaller keys, a middle link to a 2-3 search tree with keys between the node’s keys, and a right link to a 2-3 search tree with larger keys A perfectly balanced 2-3 search tree is one whose null links are all the same distance from the root. The concept guarantee that search and insert operations in a 2-3 tree with N keys are to visit at most lg N nodes.\nBut its dicrect implementation is inconvenient: Not only is there a substantial amount of code involved, but the overhead incurred could make the algorithms slower than standard BST search and insert. Consider a simple representation known as a red-black BST that leads to a natural implementation. Binary Heap A heap is a binary tree that is completely filled, with the possible exception of the bottom level, which is filled from left to right. Such a tree is known as a complete binary tree.\nA heap data structure consist of an array (of Comparable objects) and an integer representing the current heap size. For any element in array position i, the left child is in position 2i, the right child is in the cell after the left child [2i + 1], and the parent is in position [i/2]. Heap-Order Property: For every node X, the key in the parent of X is smaller than (or equal to) the key in X. So to make find minimum operation quick. Basic Heap Operation\ninsert: To insert an element X into the heap, create a hole in the next available location. Then Percolate up - swap X with its parent index (i/2) so long as X has a higher priority than its parent. Continue this process until X has no more lower priority parent. //Percolate up int hole = ++size; binaryQueue[0]=std::move(*newOne); for ( ; (priority \u003c binaryQueue[hole/2].priority || (priority == binaryQueue[hole/2].priority \u0026\u0026 name \u003c binaryQueue[hole/2].name) ); hole/=2) { binaryQueue[hole] = std::move(binaryQueue[hole/2]); } binaryQueue[hole] = std::move(binaryQueue[0]); deleteMin: When the minimum is removed, a hole is created at the root. Move the last element X in the heap to place in the root hole. Then Percolate down - swapp X with its more urgent-priority child [index (i2 or i2+1)] so long as it has a lower priority than its child. Repeat this step until X has no more higher priority child. //Percolate down int child; for (; hole*2\u003c=size;hole=child) { child = hole*2; if ( child!=size \u0026\u0026 (binaryQueue[child+1].priority\u003cbinaryQueue[child].priority || (binaryQueue[child+1].priority==binaryQueue[child].priority \u0026\u0026 binaryQueue[child+1].name\u003cbinaryQueue[child].name)) ) ++child; if ( binaryQueue[child].priority\u003cpriority_tobePerD || (binaryQueue[child].priority==priority_tobePerD \u0026\u0026 binaryQueue[child].name\u003cname_tobePerD) ) { binaryQueue[hole] = std::move(binaryQueue[child]); } else break; } Use integer division to avoid even odd index. Priority Queues A priority queue is a data structure that allows at least the following two operations: insert, and deleteMin, which finds, returns, and removes the minimum element in the priority queue.\nAlgorithm Analysis Space/time, big-O, scalability\nBig-O Computational complexity: The relationship between N and the performance of an algorithm as N becomes large Big-O notation: to denote the computational complexity of algorithms. Standard simplifications of big-O Eliminate any term whose contribution to the total ceases to be significant as N becomes large. Eliminate any constant factors. Worst-case versus average-case complexity Average-case performance often reflects typical behavior, while worst-case performance represents a guarantee for performance on any possible input. Predicting computational complexity from code structure Constant time: Code whose execution time does not depend on the problem size is said to run in constant time, which is expressed in big-O notation as O(1). Linear time: function that are executed exactly n times, once for each cycle of the for loop, O(N) Quadratic time: Algorithms like selection sort that exhibit O(N2) performance are said to run in quadratic tim For many programs, you can determine the computational complexity simply by finding the piece of the code that is executed most often and determining how many times it runs as a function of N Space/time In general, the most important measure of performance is execution time. It also possible to apply complexity analysis to the amount of memory space required. Nowadays the memory is cheap, but it still matters when designing extreamly big programs, or APPs on small memory device, such as phones and wearable devices. Sorting There are lots of different sorting algoritms, from the simple to very complex. Some optimized for certain situations (lots of duplicates, almost sorted, etc.). So why do we need multiple algorithms?\nSelection sort Select smallest and swap to front/backend\nvoid SelectionSort(Vector\u003cint\u003e \u0026arr) { for (int i = 0; i \u003c arr.size()-1; i++) { int minIndex = i; for (int j = i+1; j \u003c arr.size(); j++) { if (arr[j] \u003c arr[minIndex]) minIndex = j; } Swap(arr[i], arr[minIndex]); } } Count work inside loops:\nFirst iteration does N-1 compares, second does N-2, and so on. One swap per iteration O(N2) Insertion sort As sorting hand of just-dealt cards, each subsequent element inserted into proper place\nStart with first element (already sorted) Insert next element relative to first Repeat for third, fourth, etc. Slide elements over to make space during insert void InsertionSort(Vector\u003cint\u003e \u0026v) { for (int i = 1; i \u003c v.size(); i++) { int cur = v[i]; // slide cur down into position to left for (int j=i-1; j \u003e= 0 \u0026\u0026 v[j] \u003e cur; j--) v[j+1] = v[j]; v[j+1] = cur; } } Because of the nested loops, each of which can take N iterations, insertion sort is O(N2).\nHeapsort Priority queues can be used to sort in O(N log N) time. The algorithm based on this idea is known as heapsort.\nThe building of the heap, uses less than 2N comparisons. In the second phase, the ith deleteMax uses at most less than 2\\*log (N − i + 1) comparisons, for a total of at most 2N log N − O(N) comparisons (assuming N ≥ 2). Consequently, in the worst case, at most 2N log N − O(N) comparisons are used by heapsort.\nMerge sort Inspiration: Algorithm like selection sort is quadratic growth (O(N2)). Double input -\u003e 4X time, halve input -\u003e 1/4 time. Can recursion save the day? If there are two sorted halves, how to produce sorted full result?\nDivide and conquer algorithm\nDivide input in half Recursively sort each half Merge two halves together “Easy-split hard-join”\nNo complex decision about which goes where, just divide in middle Merge step preserves ordering from each half Merge depends on the fact that the first element in the complete ordering must be either the first element in v1 or the first element in v2, whichever is smaller.\nvoid MergeSort(Vector\u003cint\u003e \u0026v) { if (v.size() \u003e 1) { int n1 = v.size()/2; int n2 = v.size() - n1; Vector\u003cint\u003e left = Copy(v, 0, n1); Vector\u003cint\u003e right = Copy(v, n1, n2); MergeSort(left); MergeSort(right); v.clear(); Merge(v, left, right); } } void Merge(Vector\u003cint\u003e \u0026v,Vector\u003cint\u003e \u0026left,Vector\u003cint\u003e \u0026right) { int l=0, r=0; while(l\u003cleft.size() \u0026\u0026 r\u003cright.size()) { if (left[l]\u003cright[r]) v.add(left[l++]); else v.add(right[r++]); } while(l\u003cleft.size()) v.add(left[l++]); while(r\u003cright.size()) v.add(right[r++]); } The time to mergesort N numbers is equal to the time to do two recursive mergesorts of size N/2, plus the time to merge, which is linear. T(N) = N + 2T(N/2). log N levels * N per level= O(NlogN). Mergesort uses the lowest number of comparisons of all the popular sorting algorithms.\nTheoretical result show that no general sort algorithm could be better than NlogN.\nBut there is still better in practice:\nThe running time of mergesort, when compared with other O(N log N) alternatives, depends heavily on the relative costs of comparing elements and moving elements in the array (and the temporary array). These costs are language dependent. In Java, when performing a generic sort (using a Comparator), an element comparison can be expensive, but moving elements is cheap (because they are reference assignments, rather than copies of large objects). In C++, in a generic sort, copying objects can be expensive if the objects are large, while comparing objects often is relatively cheap because of the ability of the compiler to aggressively perform inline optimization. Quicksort Most sorting programs in use today are based on an algorithm called Quicksort, which employs a Divide and conquer strategy as merge sort, but instead take a different approach to divide up input vector into low half and high half. Quicksort uses a few more comparisons, in exchange for significantly fewer data movements. The reason that quicksort is faster is that the partitioning step can actually be performed in place and very efficiently.\n“Hard-split easy-join”, Each element examined and placed in correct half, so that join step become trivial.\nChoose an element (pivot) to serve as the boundary between the small and large elements. Partitioning: Rearrange the elements in the vector so that all elements to the left of the boundary are less than the pivot and all elements to the right are greater than or possibly equal to the pivot. Sort the elements in each of the partial vectors. void Quicksort(Vector\u003cint\u003e \u0026v, int start, int stop) { if (stop \u003e start) { int pivot = Partition(v, start, stop); Quicksort(v, start, pivot-1); Quicksort(v, pivot+1, stop); } } The running time of quicksort is equal to the running time of the two recursive calls plus the linear time spent in the partition (the pivot selection takes only constant time). T(N) = T(i) + T(N − i − 1) + cN, where i = |S1| is the number of elements in S1.\nThere are thre cases\nIdeal 50/50 split: The pivot is in the middle, T(N) = cN + 2T(N/2) =\u003e O(NlogN) Average bad 90/10 split: N per level, but more levels, solve N*(9/10)k = 1, still k = O(NlogN) Worst N-1/1 split: The pivot is the smallest element, all the time. Then i = 0, T(N) = T(N − 1) + cN, N \u003e 1. With N levels! O(N2) In a vector with randomly chosen elements, Quicksort tends to perform well, with an average-case complexity of O(N log N). In the worst case — which paradoxically consists of a vector that is already sorted — the performance degenerates to O(N2). Despite this inferior behavior in the worst case, Quicksort is so much faster in practice than most other algorithms that it has become the standard.\nQuicksort strategy Picking the pivot Picking a good pivot improves performance, but also costs some time. If the algorithm spends more time choosing the pivot than it gets back from making a good choice, you will end up slowing down the implementation rather than speeding it up.\nThe popular, uninformed choice is to use the first element as the pivot. This is acceptable if the input is random, but if the input is presorted or in reverse order, then the pivot provides a poor partition. A safe approach is to choose the pivot element randomly. On the other hand, random number generation is generally an expensive commodity and does not reduce the average running time of the rest of the algorithm at all. A good estimate can be obtained by picking three elements randomly and using the median of these three as pivot. The randomness turns out not to help much, so the common course is to use as pivot the median of the left, right, and center elements. Quicksort partitioning strategy A known method that is very easy to do it wrong or inefficiently.\nGeneral process: The first step is to get the pivot element out of the way by swapping it with the last element. Two pointers, i point to the first element and j to the next-to-last element. What our partitioning stage wants to do is to move all the small elements to the left part of the array and all the large elements to the right part. “Small” and “large” are relative to the pivot. While i is to the left of j, we move i right, skipping over elements that are smaller than the pivot. We move j left, skipping over elements that are larger than the pivot. When i and j have stopped, i is pointing at a large element and j is pointing at a small element. If i is to the left of j (not yet cross), those elements are swapped. Repeat the process until i and j cross The final is to swap the pivot element with present i element One important detail we must consider is how to handle elements that are equal to the pivot? Suppose there are 10,000,000 elements, of which 500,000 are identical (or, more likely, complex elements whose sort keys are identical). To get an idea of what might be good, we consider the case where all the elements in the array are identical. If neither i nor j stops, and code is present to prevent them from running off the end of the array, no swaps will be performed. Although this seems good, a correct implementation would then swap the pivot into the last spot that i touched, which would be the next-to last position (or last, depending on the exact implementation). This would create very uneven subarrays. If all the elements are identical, the running time is O(N2). If both i and j stop, there will be many swaps between identical elements. The partition creates two nearly equal subarrays. The total running time would then be O(N log N). Thus it is better to do the unnecessary swaps and create even subarrays than to risk wildly uneven subarrays. Small arrays For very small arrays (N ≤ 20), quicksort does not perform as well as insertion sort. Furthermore, because quicksort is recursive, these cases will occur frequently. A common solution is not to use quicksort recursively for small arrays, but instead use a sorting algorithm that is efficient for small arrays, such as insertion sort. A good cutoff range is N = 10, although any cutoff between 5 and 20 is likely to produce similar results. This also saves nasty degenerate cases, such as taking the median of three elements when there are only one or two. Design Strategy When an algorithm is given, the actual data structures need not be specified. It is up to the programmer to choose the appropriate data structure in order to make the running time as small as possible. There are many to be considered: algorithms, data structure, space-time tradeoff, code complexity.\nDynamic Programming To solve optimization problems in which we make a set of choices in order to arrive at an optimal solution. As we make each choice, subproblems of the same form often arise. Dynamic programming is effective when a given subproblem may arise from more than one partial set of choices; the key technique is to store the solution to each such subproblem in case it should reappear. Unlike divide-and-conquer algorithms which partition the problem into disjoint subproblems, dynamic programming applies when the subproblems overlap.\n“Programming” in this context refers to a tabular method. When should look for a dynamic-programming solution to a problem? Optimal substructure: a problem exhibits optimal substructure if an optimal solution to the problem contains within it optimal solutions to subproblems. Overlapping subproblems: When a recursive algorithm revisits the same problem repeatedly, we say that the optimization problem has overlapping subproblems. In contrast, a problem for which a divide-andconquer approach is suitable usually generates brand-new problems at each step of the recursion. General setps of Dynamic Programming Characterize the structure of an optimal solution. Recursively define the value of an optimal solution. Compute the value of an optimal solution, typically in a bottom-up fashion. Construct an optimal solution from computed information. Greedy Algorithms Greedy algorithms work in phases. In each phase, a decision is made in a locally optimal manner, without regard for future consequences. When the algorithm terminates, we hope that the local optimum is equal to the global optimum. If this is the case, then the algorithm is correct; otherwise, the algorithm has produced a suboptimal solution.\nHuffman Codes\nA Huffman code is a particular type of optimal prefix code that is commonly used for lossless data compression. The reason that this is a greedy algorithm is that at each stage we perform a merge without regard to global considerations. We merely select the two smallest trees. If we maintain the trees in a priority queue, ordered by weight, then the running time is O(C logC), since there will be one buildHeap, 2C − 2 deleteMins, and C − 2 inserts. A simple implementation of the priority queue, using a list, would give an O(C2) algorithm. The choice of priority queue implementation depends on how large C is. In the typical case of an ASCII character set, C is small enough that the quadratic running time is acceptable. Divide and Conquer Traditionally, routines in which the text contains at least two recursive calls and subproblems be disjoint (that is, essentially nonoverlapping) are called divide-and-conquer algorithms.\nDivide: Smaller problems are solved recursively (except, of course, base cases). Conquer: The solution to the original problem is then formed from the solutions to the subproblems. We have already seen several divide-and-conquer algorithms: mergesort and quicksort, which have O(N log N) worst-case and averagecase bounds, respectively. Backtracking Algorithms See Recursive Backtracking In some cases, the savings over a brute-force exhaustive search can be significant. The elimination of a large group of possibilities in one step is known as pruning.\nHow to evaluate/compare alternatives Often interested in execution performance: Time spent and memory used Should also consider ease of developing, verifying, maintaining code Text editor case study Buffer requirements\nSequence of characters + cursor position Operations to match commands above What to consider?\nImplementation choices performance implications Buffer class interface\nclass Buffer { public: Buffer(); ~Buffer(); void moveCursorForward(); void moveCursorBackward(); void moveCursorToStart(); void moveCursorToEnd(); void insertCharacter(char ch); void deleteCharacter(); void display(); private: // TBD! }; Buffer layered on Vector\nNeed character data + cursor Chars in Vector Represent cursor as integer index Minor detail – is index before/after cursor? Buffer contains: AB|CDE // for Buffer class private: Vector\u003cchar\u003e chars; int cursor; Performance insertCharacter() and deleteCharacter() is linear, other operation is just O(1) Space used ~1 byte per char Buffer layered on Stack\nInspiration: add/remove at end of vector is fast If chars next to cursor were at end… Build on top of stack? Another layered abstraction! How is cursor represented? Buffer contains:AB|CDE There is no explicit cursor representation, instead using two stack to represent a whole data structure being seperated by the implicit cursor. // for Buffer class private: Stack\u003cchar\u003e before, after; Performance moveCursorToStart(), moveCursorToEnd() operation is linear, other operation is just O(1) Space used ~2 byte per char Buffer as double linked list\nInspiration: contiguous memory is constraining Connect chars without locality Add tail pointer to get direct access to last cell Add prev link to speed up moving backwards Buffer contains:AB|CDE // for Buffer class private: struct cellT { char ch; cellT *prev, *next; }; cellT *head, *tail, *cursor; Cursor design To cell before or after? 5 letters, 6 cursor positions… Add “dummy cell” to front of list Performance destruction is linear, other operation is just O(1) Space used ~9 byte per char Compare implementations\nOperation Vector Stack Single linked list Double linked list Buffer() O(1) O(1) O(1) O(1) ~Buffer() O(1) O(1) O(N) O(N) moveCursorForward() O(1) O(1) O(1) O(1) moveCursorBackward() O(1) O(1) O(N) O(1) moveCursorToStart() O(1) O(N) O(1) O(1) moveCursorToEnd() O(1) O(N) O(N) O(1) insertCharacter() O(N) O(1) O(1) O(1) deleteCharacter() O(N) O(1) O(1) O(1) Space used 1N 2N 5N 9N Space-time tradeoff Doubly-linked list is O(1) on all six operations But, each char uses 1 byte + 8 bytes of pointers =\u003e 89% overhead! Compromise: chunklist Array and linked list hybrid Shares overhead cost among several chars Chunksize can be tuned as appropriate Cost shows up in code complexity Cursor must traverse both within and across chunks Splitting/merging chunks on insert/deletes Map Map is super-useful, support any kind of dictionary, lookup table, index, database, etc. Map stores key-value pairs, support fast access via key, operations to optimize: add, getValue How to make it work efficiently?\nImplement Map as Vector Layer on Vector, provides convenience with low overhead Define pair struct, to olds key and value together, Vector Vector sorted or unsorted? If sorted, sorted by what? Sorting: Provides fast lookup, but still slow to insert (because of shuffling) How to implement getValue, add? Does a linked list help? Easy to insert, once at a position But hard to find position to insert… Implementing Map as tree Implementatation Each Map entry adds node to tree, node contains: string key, client-type value, pointers to left/right subtrees Tree organized for binary search, Key is used as search field getValue: Searches tree, comparing keys, find existing match or error add: Searches tree, comparing keys, overwrites existing or adds new node Private members for Map template \u003ctypename ValType\u003e class Map { public: // as before private: struct node { string key; ValType value; node *left, *right; }; node *root; node *treeSearch(node * t, string key); void treeEnter(node *\u0026t, string key, ValType val); DISALLOW_COPYING(Map) }; Evaluate Map as tree Space used: Overhead of two pointers per entry (typically 8 bytes total) Runtime performance: Add/getValue take time proportional to tree height(expected to be O(logN)) Degenerate trees The insert order is “sorted”: 2 8 14 15 18 20 21, totally unbalanced with height = 7 The insert order is “alternately sorted”: 21 2 20 8 14 15 18 or 2 8 21 20 18 14 15 Association: What is the relationship between worst-case inputs for tree insertion and Quicksort? What to do about it: AVL tree Compare Map implementations Operation Vector BST Sorted Vector getValue O(N) O(lgN) O(lgN) add O(N) O(lgN) O(N) Space used N 9N N Hashing Hash table ADT Hash table data structure: A list of keys and TableSize Hash function: A mapping that map each key into some number in the range 0 to TableSize-1 and distributes the keys evenly among the appropriate cell Hashing The major problems are choosing a function, deciding what to do when two keys hash to the same value (this is known as a collision), and deciding on the table size Rehashing If the table gets too full, the running time for the operations will start taking too long, and insertions might fail for open addressing hashing with quadratic resolution. A solution is to build another table that is about twice as big (with an associated new hash function) and scan down the entire original hash table, computing the new hash value for each (nondeleted) element and inserting it in the new table. The Big-Five In C++11, classes come with five special functions that are already written for you. These are the destructor, copy constructor, move constructor, copy assignment operator, and move assignment operator. Collectively these are the big-five.\nDestructor The destructor is called whenever an object goes out of scope or is subjected to a delete. Typically, the only responsibility of the destructor is to free up any resources that were acquired during the use of the object. This includes calling delete for any corresponding news, closing any files that were opened, and so on. The default simply applies the destructor on each data member.\nConstructor A constructor is a method that describes how an instance of the class is constructed. If no constructor is explicitly defined, one that initializes the data members using language defaults is automatically generated.\nCopy Constructor and Move Constructor\nCopy Assignment and Move Assignment (operator=) By Defaults, if a class consists of data members that are exclusively primitive types and objects for which the defaults make sense, the class defaults will usually make sense. The main problem occurs in a class that contains a data member that is a pointer.\nThe default destructor does nothing to data members that are pointers (for good reason—recall that we must delete ourselves). Furthermore, the copy constructor and copy assignment operator both copy the value of the pointer rather than the objects being pointed at. Thus, we will have two class instances that contain pointers that point to the same object. This is a so-called shallow copy (contrast to deep copy). To avoid shallow copy, ban the copy funtionality by calling DISALLOW_COPYING(ClassType). As a result, when a class contains pointers as data members, and deep semantics are important, we typically must implement the destructor, copy assignment, and copy constructors ourselves.\nExplicit constructor: All one-parameter constructors should be made explicit to avoid behind-the-scenes type conversions. Otherwise, there are somewhat lenient rules that will allow type conversions without explicit casting operations. Usually, this is unwanted behavior that destroys strong typing and can lead to hard-to-find bugs. The use of explicit means that a one-parameter constructor cannot be used to generate an implicit temporary\nclass IntCell { public: explicit IntCell( int initialValue = 0 ) : storedValue{ initialValue } { } int read( ) const { return storedValue; } private: int storedValue; }; IntCell obj; // obj is an IntCell obj = 37; // Should not compile: type mismatch Since IntCell constructor is declared explicit, the compiler will correctly complain that there is a type mismatch\nTemplate Type-independent When we write C++ code for a type-independent algorithm or data structure, we would prefer to write the code once rather than recode it for each different type\nFunction template A function template is not an actual function, but instead is a pattern for what could become a function. An expansion for each new type generates additional code; this is known as code bloat when it occurs in large projects. Class template template \u003ctypename Object\u003e class MemoryCell { public: explicit MemoryCell( const Object \u0026 initialValue = Object{ } ) : storedValue{ initialValue } { } private: Object storedValue; }; MemoryCell is not a class, it is only a class template. It will be a class if specify the Object type. MemoryCell and MemoryCell are the actual classes.\nGraph Algorithms Definitions: vertices, edges, arcs, directed arcs = digraphs, weight/cost, path, length, acyclic(no cycles)\nTopological Sort A topological sort is an ordering of vertices in a directed acyclic graph, such that if there is a path from vi to vj, then vj appears after vi in the ordering. A topological ordering is not possible if the graph has a cycle To find a topological ordering, define the indegree of a vertex v as the number of edges (u, v), then use a queue or stack to keep the present 0 indegree vertexes. At each stage, as long as the queue is not empty, dequeue a 0 indegree vertexes in the queue, enqueue each new generated 0 indegree vertexes into the queue. Shortest-Path Algorithms Breadth-first search\nExplores equally in all directions To find unweighted shortest paths Operates by processing vertices in layers: The vertices closest to the start are evaluated first, and the most distant vertices are evaluated last. Dijkstra’s Algorithm\nAlso called Uniform Cost Search, cost matters Instead of exploring all possible paths equally, it favors lower cost paths. Dijkstra’s algorithm proceeds in stages. At each stage, while there are still vertices waiting to be known: Selects a vertex v, which has the smallest dv among all the unknown vertices, and declares v as known stage. For each of v’s neighbors, w, if the new path’s cost from v to w is better than previous dw, dw will be updated. But w will not be marked as known, unless at next while-loop stage, dw happens to be the smalles. The above steps could be implemented via a priority queue. A proof by contradiction will show that this algorithm always works as long as no edge has a negative cost. If the graph is sparse, with |E| =θ(|V|), this algorithm is too slow. In this case, the distances would need to be kept in a priority queue. Selection of the vertex v is a deleteMin operation. The update of w’s distance can be implemented two ways. One way treats the update as a decreaseKey operation. An alternate method is to insert w and the new value dw into the priority queue every time w’s distance changes. Greedy Best First Search(Heuristic search)\nWith Breadth First Search and Dijkstra’s Algorithm, the frontier expands in all directions. This is a reasonable choice if you’re trying to find a path to all locations or to many locations. However, a common case is to find a path to only one location. A modification of Dijkstra’s Algorithm, optimized for a single destination. It prioritizes paths that seem to be leading closer to the goal. To make the frontier expand towards the goal more than it expands in other directions. First, define a heuristic function that tells us how close we are to the goal, design a heuristic for each type of graph def heuristic(a, b): # Manhattan distance on a square grid return abs(a.x - b.x) + abs(a.y - b.y) Use the estimated distance to the goal for the priority queue ordering. The location closest to the goal will be explored first. This algorithm runs faster when there aren’t a lot of obstacles, but the paths aren’t as good(not always the shortest). A* Algorithm\nDijkstra’s Algorithm works well to find the shortest path, but it wastes time exploring in directions that aren’t promising. Greedy Best First Search explores in promising directions but it may not find the shortest path. The A* algorithm uses both the actual distance from the start and the estimated distance to the goal. Compare the algorithms: Dijkstra’s Algorithm calculates the distance from the start point. Greedy Best-First Search estimates the distance to the goal point. A* is using the sum of those two distances. So A* is the best of both worlds. As long as the heuristic does not overestimate distances, A* does not use the heuristic to come up with an approximate answer. It finds an optimal path, like Dijkstra’s Algorithm does. A* uses the heuristic to reorder the nodes so that it’s more likely that the goal node will be encountered sooner. Conclusion: Which algorithm should you use for finding paths on a map?\nIf you want to find paths from or to all all locations, use Breadth First Search or Dijkstra’s Algorithm. Use Breadth First Search if movement costs are all the same; use Dijkstra’s Algorithm if movement costs vary. If you want to find paths to one location, use Greedy Best First Search or A*. Prefer A* in most cases. When you’re tempted to use Greedy Best First Search, consider using A* with an “inadmissible” heuristic. If you want the optimal paths, Breadth First Search and Dijkstra’s Algorithm are guaranteed to find the shortest path given the input graph. Greedy Best First Search is not. A* is guaranteed to find the shortest path if the heuristic is never larger than the true distance. (As the heuristic becomes smaller, A* turns into Dijkstra’s Algorithm. As the heuristic becomes larger, A* turns into Greedy Best First Search.) Advanced Data Structures Red-Black Trees Red-black tree leads to a natural implementation of the insertion algorithm for 2-3 trees\nRBT definition\nRed-black tree means encoding 2-3 trees in this way: red links, which bind together two 2-nodes to represent 3-nodes, and black links, which bind together the 2-3 tree. An equivalent definition is to define red-black BSTs as BSTs having red and black links and satisfying the following three restrictions: Red links lean left. No node has two red links connected to it. The tree has perfect black balance : every path from the root to a null link has the same number of black links. A 1-1 correspondence: If we draw the red links horizontally in a red-black BST, all of the null links are the same distance from the root, and if we then collapse together the nodes connected by red links, the result is a 2-3 tree. RBT implementaion\nColor representation: Each node is pointed to by precisely one link from its parent, Encode the color of links in nodes, by adding a boolean instance variable color to our Node data type, which is true if the link from the parent is red and false if it is black. By convention, null links are black. For clarity, define constants RED and BLACK for use in setting and testing this variable. Rotation To correct right-leaning red links or two red links in a row conditions. takes a link to a red-black BST as argument and, assuming that link to be to a Node h whose right link is red, makes the necessary adjustments and returns a link to a node that is the root of a red-black BST for the same set of keys whose left link is red. Actually it is switching from having the smaller of the two keys at the root to having the larger of the two keys at the root. Flipping colors to split a 4-node In addition to flipping the colors of the children from red to black, we also flip the color of the parent from black to red. Keeping the root black. Insertion Maintain the 1-1 correspondence between 2-3 trees and red-black BSTs during insertion by judicious use of three simple operations: left rotate, right rotate, and color flip. If the right child is red and the left child is black, rotate left. If both the left child and its left child are red, rotate right. If both children are red, flip colors. Deletion Assignments Name Hash Game of Life Serafini Recursion Boggle! Patient Queue Huffman Encoding Trailblazer ","wordCount":"7935","inLanguage":"en","datePublished":"2017-06-23T00:00:00Z","dateModified":"2017-06-23T00:00:00Z","author":{"@type":"Person","name":"Cong Chan"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://congchan.github.io/posts/stanford-cs106a/b-programming-intro-%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8%E8%AF%BE/"},"publisher":{"@type":"Organization","name":"Cong's Log","logo":{"@type":"ImageObject","url":"https://congchan.github.io/favicons/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://congchan.github.io/ accesskey=h title="Cong's Log (Alt + H)">Cong's Log</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://congchan.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://congchan.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://congchan.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://congchan.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://congchan.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Stanford CS106A/B Programming Intro 斯坦福大学编程入门课</h1><div class=post-meta><span title='2017-06-23 00:00:00 +0000 UTC'>2017-06-23</span>&nbsp;·&nbsp;38 min&nbsp;·&nbsp;Cong Chan&nbsp;|&nbsp;<a href=https://github.com/%3cgitlab%20user%3e/%3crepo%20name%3e/tree/%3cbranch%20name%3e/%3cpath%20to%20content%3e//posts/stanford-cs106ab.md rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#topics aria-label=Topics:>Topics:</a></li><li><a href=#purposes aria-label=Purposes>Purposes</a></li><li><a href=#reference aria-label=Reference>Reference</a></li><li><a href=#coding-style aria-label="Coding style">Coding style</a><ul><li><a href=#how-to-write-clean-well-structured-code aria-label="How to write clean, well-structured code?">How to write clean, well-structured code?</a></li><li><a href=#comments aria-label=Comments>Comments</a></li></ul></li><li><a href=#adt aria-label=ADT>ADT</a><ul><li><a href=#iterators aria-label=Iterators>Iterators</a></li></ul></li><li><a href=#recursion aria-label=Recursion>Recursion</a><ul><li><a href=#exhaustive-recursion aria-label="Exhaustive recursion">Exhaustive recursion</a></li><li><a href=#recursive-backtracking aria-label="Recursive Backtracking">Recursive Backtracking</a></li></ul></li><li><a href=#pointer aria-label=Pointer>Pointer</a><ul><li><a href=#use-of-pointer aria-label="Use of pointer">Use of pointer</a></li><li><a href=#dynamic-allocation aria-label="Dynamic allocation">Dynamic allocation</a></li></ul></li><li><a href=#tree aria-label=Tree>Tree</a><ul><li><a href=#binary-tree aria-label="Binary tree">Binary tree</a></li><li><a href=#operating-on-trees aria-label="Operating on trees">Operating on trees</a></li><li><a href=#balanced-search-trees aria-label="Balanced Search Trees">Balanced Search Trees</a></li><li><a href=#avl-tree aria-label="AVL tree">AVL tree</a></li><li><a href=#2-3-trees aria-label="2-3 trees">2-3 trees</a></li><li><a href=#binary-heap aria-label="Binary Heap">Binary Heap</a></li></ul></li><li><a href=#priority-queues aria-label="Priority Queues">Priority Queues</a></li><li><a href=#algorithm-analysis aria-label="Algorithm Analysis">Algorithm Analysis</a><ul><li><a href=#big-o aria-label=Big-O>Big-O</a></li><li><a href=#spacetime aria-label=Space/time>Space/time</a></li></ul></li><li><a href=#sorting aria-label=Sorting>Sorting</a><ul><li><a href=#selection-sort aria-label="Selection sort">Selection sort</a></li><li><a href=#insertion-sort aria-label="Insertion sort">Insertion sort</a></li><li><a href=#heapsort aria-label=Heapsort>Heapsort</a></li><li><a href=#merge-sort aria-label="Merge sort">Merge sort</a></li><li><a href=#quicksort aria-label=Quicksort>Quicksort</a><ul><li><a href=#quicksort-strategy aria-label="Quicksort strategy">Quicksort strategy</a></li></ul></li></ul></li><li><a href=#design-strategy aria-label="Design Strategy">Design Strategy</a></li><li><a href=#dynamic-programming aria-label="Dynamic Programming">Dynamic Programming</a></li><li><a href=#greedy-algorithms aria-label="Greedy Algorithms">Greedy Algorithms</a></li><li><a href=#divide-and-conquer aria-label="Divide and Conquer">Divide and Conquer</a></li><li><a href=#backtracking-algorithms aria-label="Backtracking Algorithms">Backtracking Algorithms</a></li><li><a href=#how-to-evaluatecompare-alternatives aria-label="How to evaluate/compare alternatives">How to evaluate/compare alternatives</a></li><li><a href=#text-editor-case-study aria-label="Text editor case study">Text editor case study</a></li><li><a href=#map aria-label=Map>Map</a></li><li><a href=#hashing aria-label=Hashing>Hashing</a></li><li><a href=#the-big-five aria-label="The Big-Five">The Big-Five</a><ul><li><a href=#destructor aria-label=Destructor>Destructor</a></li><li><a href=#constructor aria-label=Constructor>Constructor</a></li></ul></li><li><a href=#template aria-label=Template>Template</a><ul><li><a href=#type-independent aria-label=Type-independent>Type-independent</a></li><li><a href=#function-template aria-label="Function template">Function template</a></li><li><a href=#class-template aria-label="Class template">Class template</a></li></ul></li><li><a href=#graph-algorithms aria-label="Graph Algorithms">Graph Algorithms</a><ul><li><a href=#topological-sort aria-label="Topological Sort">Topological Sort</a></li><li><a href=#shortest-path-algorithms aria-label="Shortest-Path Algorithms">Shortest-Path Algorithms</a></li></ul></li><li><a href=#advanced-data-structures aria-label="Advanced Data Structures">Advanced Data Structures</a><ul><li><a href=#red-black-trees aria-label="Red-Black Trees">Red-Black Trees</a></li><li><a href=#assignments aria-label=Assignments>Assignments</a></li></ul></li></ul></div></details></div><div class=post-content><p><a href=https://see.stanford.edu/Course/CS106B>Stanford CS106B Programming Abstractions</a> 和 <a href=https://see.stanford.edu/Course/CS106A>CS106A</a> 的学习笔记. 课程作业(cs106b spring 2017)实现代码见 <a href=https://github.com/ShootingSpace/cs106b-programming-abstraction>https://github.com/ShootingSpace/cs106b-programming-abstraction</a></p><h2 id=topics>Topics:<a hidden class=anchor aria-hidden=true href=#topics>#</a></h2><p>A: Intro (by Java)
B: Recursion, algorithms analysis (sort/search/hash), dynamic data structures (lists, trees, heaps), data abstraction (stacks, queues, maps), implementation strategies/tradeoffs</p><h2 id=purposes>Purposes<a hidden class=anchor aria-hidden=true href=#purposes>#</a></h2><ol><li>become acquainted with the C++ programming language</li><li>learn more advanced programming techniques</li><li>explore classic data structures and algorithms</li><li>and apply these tools to solving complex problems</li></ol><h2 id=reference>Reference<a hidden class=anchor aria-hidden=true href=#reference>#</a></h2><ol><li>Text Book: <a href=https://www.pearson.com/us/higher-education/program/Weiss-Data-Structures-and-Algorithm-Analysis-in-C-4th-Edition/PGM148299.html>Data Structures & Algorithm Analysis in C++, 4th ed, by Mark A. Weiss</a></li><li>Text Book: <a href=https://www.pearson.com/us/higher-education/program/Roberts-Programming-Abstractions-in-C/PGM80147.html>Programming Abstractions in C++ 1st Edition by Eric Roberts</a></li><li>Text Book: <a href=http://algs4.cs.princeton.edu/home/>Algorithms, 4th Edition</a></li><li>Blog: <a href=http://www.redblobgames.com/pathfinding/a-star/introduction.html>Red Blob Games</a>, <a href=http://theory.stanford.edu/~amitp/GameProgramming/>Amit’s A* Pages</a></li></ol><hr><h2 id=coding-style>Coding style<a hidden class=anchor aria-hidden=true href=#coding-style>#</a></h2><p>Why writing clean, well-structured code</p><ol><li>The messy code trap<ul><li>harder to build and debug</li><li>harder to clean up</li></ul></li><li>Decomposition<ul><li>Decompose the problem, not the programs, program is written from the already decomposed framework.</li><li>Logical and readable</li><li>Methods should be short and to the point,</li><li>Strive to design methods that are general enough for a variety of situations and achieve specifics trough use of parameters.<ul><li>Avoid redundants methods.</li><li>Avoid repeated lines or methods.</li></ul></li></ul></li><li>Readable code:<ul><li>Writing readable code not only help future readers but also help avoid your own bugs: Because bugs are codes that fail to expresses idea in mind.</li><li>Reader can see the algorithmic idea when sweeping the code.</li></ul></li></ol><p>Works correctly in all situations: Using a listing of specific test cases to exercise the program on.</p><p>The overall approach is straight-forward, data structure is cleanly organized, tasks are nicely decomposed, algorithms are clear and easy to follow, comments are helpful, layout is consistent.</p><h3 id=how-to-write-clean-well-structured-code>How to write clean, well-structured code?<a hidden class=anchor aria-hidden=true href=#how-to-write-clean-well-structured-code>#</a></h3><ol><li>Choosing good names for variables<ul><li>Name reflect what it stores, normally nouns;</li><li>In Java, conventionly, begin variables with the first word lowercase, and upper case later words <code>bestScore</code></li><li>Widely used idiomatic one-letter names: <code>i, j, k</code> for int loop counters; <code>x, y, z</code> for coordinates.</li></ul></li><li>Choosing good names for methods<ul><li>Name reflect the action they perform, verbs normally;</li><li>The prefixes <code>get</code> and <code>set</code> have a typical role: A get method gets a piece of information from an object; set methods are used to pass a value in to an object</li><li>Returning a boolean are ofter named starting with <code>is</code> or <code>has</code>.</li></ul></li><li>Using whitespace to separate logical parts: Put in blank lines to separate the code into its natural sub sections that accomplis logical sub-parts of the whole algoriithm. Each little section might have a comment to describe what it accomplishes.</li><li>Use Indentation to show hierarchy structure</li><li>Comments</li><li>Attributions: consider as an important tennet of academic integrity.</li></ol><h3 id=comments>Comments<a hidden class=anchor aria-hidden=true href=#comments>#</a></h3><p>Examples of information you might include in comments:</p><ul><li>General overview. What are the goals and requirements of this program? this function? The overview comment should also contain author and version information: who worked on this file and when.</li><li>Data structures. How is the data stored? How is it ordered, searched, accessed?</li><li>Design decisions. Why was a particular data structure or algorithm chosen? What other strategies were tried and rejected?</li><li>Error handling. How are error conditions handled? What assumptions are made? What happens if those assumptions are violated?</li><li>Nitty-gritty code details. Comments are invaluable for explaining the inner workings of particularly complicated (often labeled &ldquo;clever&rdquo;) paths of the code.</li><li>Planning for the future. How might one make modifications or extensions later?</li><li>And more&mldr; (This list is by no means exhaustive)</li></ul><h2 id=adt>ADT<a hidden class=anchor aria-hidden=true href=#adt>#</a></h2><p>An abstract data type is a set of objects together with a set of operations. Abstract data types are mathematical abstractions; nowhere in an ADT’s definition is there any mention of how the set of operations is implemented.
Objects such as lists, sets, and graphs, along with their operations, can be viewed as ADTs.
Also there are search <a href=/posts/stanford-cs106a/b-programming-intro-%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8%E8%AF%BE/#tree>tree</a>, set, <a href=/posts/stanford-cs106a/b-programming-intro-%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8%E8%AF%BE/#hashing>hash table</a>, <a href=/posts/stanford-cs106a/b-programming-intro-%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8%E8%AF%BE/#priority-queues>priority queue</a>.</p><ul><li>Client uses class as abstraction<ul><li>Invokes public operations only</li><li>Internal implementation not relevant!</li></ul></li><li>Client can&rsquo;t and shouldn&rsquo;t muck with internals: Class data should private</li><li>Imagine a &ldquo;wall&rdquo; between client and implementor<ul><li>Wall prevents either from getting involved in other&rsquo;s business</li><li>Interface is the &ldquo;chink&rdquo; in the wall</li><li>Conduit allows controlled access between the two</li></ul></li><li>Consider Lexicon<ul><li>Abstraction is a word list, operations to verify word/prefix</li><li>How does it store list? using array? vector? set? does it matter to client?</li></ul></li></ul><p>Why ADTs?</p><ul><li>Abstraction: Client insulated from details, works at higher-level</li><li>Encapsulation: Internals private to ADT, not accessible by client</li><li>Independence: Separate tasks for each side (once agreed on interface)</li><li>Flexibility: ADT implementation can be changed without affecting client</li></ul><p>The C++ language includes, in its library, an implementation of common data structures. This part of the language is popularly known as the Standard Template Library (STL). In general, these data structures are called collections or containers.</p><h3 id=iterators>Iterators<a hidden class=anchor aria-hidden=true href=#iterators>#</a></h3><p>In the STL, a position is represented by a nested type, iterator.</p><p>Getting an Iterator</p><ul><li><code>iterator begin( )</code> returns an appropriate iterator representing the first item in the container.</li><li><code>iterator end( )</code> returns an appropriate iterator representing the endmarker in the container (i.e., the position after the last item in the container).</li></ul><p>Iterator Methods
* <code>itr++</code> and <code>++itr</code> advances the iterator itr to the next location. Both the prefix and postfix forms are allowable.
* <code>itr</code> returns a reference to the object stored at iterator itr’s location. The reference returned may or may not be modifiable (we discuss these details shortly).
* <code>itr1==itr2</code> / <code>itr1!=itr2</code>, returns true if iterators itr1 and itr2 refer to the same / different location and false otherwise.</p><p>Container Operations that require Iterators. The three most popular methods that require iterators are those that add or remove from the list (either a vector or list) at a specified position:</p><ul><li><code>iterator insert( iterator pos, const Object & x )</code>: adds <code>x</code> into the list, prior to the position given by the <code>iterator pos</code>. This is a constant-time operation for list, but not for vector. The return value is an iterator representing the position of the inserted item.</li><li><code>iterator erase( iterator pos )</code>: removes the object at the position given by the iterator. This is a constant-time operation for list, but not for vector. The return value is the position of the element that followed pos prior to the call. This operation invalidates pos, which is now stale, since the container item it was viewing has been removed.</li><li>iterator erase( iterator start, iterator end ): removes all items beginning at position start, up to, but not including end. Observe that the entire list can be erased by the call c.erase( c.begin( ), c.end( ) )</li><li>Range for loop: C++11 also allows the use of the reserved word auto to signify that the compiler will automatically infer the appropriate type,<ul><li>for simple data type:</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=k>for</span><span class=p>(</span> <span class=k>auto</span> <span class=nl>x</span> <span class=p>:</span> <span class=n>squares</span> <span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=n>cout</span><span class=o>&lt;&lt;</span> <span class=n>x</span><span class=p>;</span>
</span></span></code></pre></div><ul><li>for complicate data type like map: Each element of the container is a <code>map&lt;K, V>::value_type</code>, which is a typedef for <code>std::pair&lt;const K, V></code>. Consequently, you&rsquo;d write this as</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=k>auto</span><span class=o>&amp;</span> <span class=nl>kv</span> <span class=p>:</span> <span class=n>myMap</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=n>std</span><span class=o>::</span><span class=n>cout</span> <span class=o>&lt;&lt;</span> <span class=n>kv</span><span class=p>.</span><span class=n>first</span> <span class=o>&lt;&lt;</span> <span class=s>&#34; has value &#34;</span> <span class=o>&lt;&lt;</span> <span class=n>kv</span><span class=p>.</span><span class=n>second</span> <span class=o>&lt;&lt;</span> <span class=n>std</span><span class=o>::</span><span class=n>endl</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div></li></ul><h2 id=recursion>Recursion<a hidden class=anchor aria-hidden=true href=#recursion>#</a></h2><p>Helper Function</p><ul><li>No clear definition of helper function</li><li>How to utilize helper function to help constructing recursion algarithm: construct a same-name recursive function with extra parameters to pass in.</li><li>In some other cases, decomposition with several step into a function is itself a helper function, which help to make the main function simple and clean.</li></ul><h3 id=exhaustive-recursion>Exhaustive recursion<a hidden class=anchor aria-hidden=true href=#exhaustive-recursion>#</a></h3><p>Permutations/subsets are about choice</p><ul><li>Both have deep/wide tree of recursive calls</li><li>Depth represents total number of decisions made</li><li>Width of branching represents number of available options per decision</li><li>Explores every possible option at every decision point, typically very expensive, N! permutations, 2N subsets</li></ul><h3 id=recursive-backtracking>Recursive Backtracking<a hidden class=anchor aria-hidden=true href=#recursive-backtracking>#</a></h3><p>Partial exploration of exhaustive space. In the case that if we are interested in finding any solution, whichever one that works out first is fine. If we eventually reach our goal from here, we have no need to consider the paths not taken. However, if this choice didn&rsquo;t work out and eventually leads to nothing but dead ends; when we backtrack to this decision point, we try one of the other alternatives.</p><ul><li>The back track based on the stacks of recursion, if a stack return false (or fail result), we back to previous stack and try another way(un-making choice).</li><li>Need something return(normally bool) to step out of the entire recursion once any one solution found.</li><li>One great tip for writing a backtracking function is to abstract away the details of managing the configuration (what choices are available, making a choice, checking for success, etc.) into other helper functions so that the body of the recursion itself is as clean as can be. This helps to make sure you have the heart of the algorithm correct and allows the other pieces to be developed, test, and debugged independently.</li></ul><h2 id=pointer>Pointer<a hidden class=anchor aria-hidden=true href=#pointer>#</a></h2><p>lvalue: In C++, any expression that refers to an internal memory location capable of storing data is called an lvalue (pronounced “ell-value”). <code>x = 1.0;</code></p><p>Declaring pointer variables</p><pre tabindex=0><code>int main() {
     --------------------------------------------------
     // Declaration, in the stack
     // Not yet initialized!
     int num;
     int *p, *q;
     // If cout &lt;&lt; num &lt;&lt; p &lt;&lt; q &lt;&lt; endl;
     // There will be junk number, junk address.
     // If now *p=10, it may blow up, because what *p point to is an address points to somewhere around that could be invalid.
     ---------------------------------------------------
     // new operator allocate memory from the heap, returns address
     p = new int;     // P -----&gt; [ int ] （heep 1000）
     *p = 10;           // P -----&gt; [ 10 ] （heep 1000）
     q = new int;    // P -----&gt; [ int ] （heep 1004）
     *q = *p;           // q -----&gt; [ 10 ]  （heep 1004）
     q = p;              // q -----&gt; [ 10 ] （heep 1000）
     // [ 10 ] （heep 1004） became orphan, and could not be reclaim back
     ---------------------------------------------------
     delete p;          // [ 10 ] （heep 1000）memory was reclaimed and free,
                             // and available for others as [  ]（heep 1000）,
                             // but p still hold the address
     delete q;          // bad idea,  [ 10 ]（heep 1000） already been reclaimed!
     q = NULL;         // NULL is zero pointer, means the pointer does not hold any address,
                              // used as sentinel value, sometimes better than delete.
     // Accessing &#34;deleted&#34; memory has unpredictable consequences
     ---------------------------------------------------

     // int *p  declaration reserves only a single word, which is large enough to hold a machine address.
     // ≠
     // int *p = NULL declare pointer p as nullptr
     ---------------------------------------------------
     (*newOne).name = name // &#34;.&#34; &gt; &#34;*&#34;
     newOne-&gt;name = name
</code></pre><h3 id=use-of-pointer>Use of pointer<a hidden class=anchor aria-hidden=true href=#use-of-pointer>#</a></h3><p>Big program that contains a certain amout of classes and objects that are share some relationship. Instead of copying data from each other, using pointer to point to specific data is better:</p><ul><li>Saves space by not repeating the same information.</li><li>If some objects gets new information to update, change in one place only!</li></ul><h3 id=dynamic-allocation>Dynamic allocation<a hidden class=anchor aria-hidden=true href=#dynamic-allocation>#</a></h3><p>Request memory: To acquire new memory when you need it and to free it explicitly when it is no longer needed. Acquiring new storage when the program is running. While the program is running, you can reserve part of the unallocated memory, leaving the rest for subsequent allocations.
The pool of unallocated memory available to a program is called the <strong>heap</strong>.
<code>int *p = new int; //new operator to allocate memory from the heap</code>
In its simplest form, the new operator takes a type and allocates space for a variable of that type located in the heap.
The call to new operator will return the address of a storage location in the heap that has been set aside to hold an integer.</p><p>Free occupied memory: <code>Delete</code> which takes a pointer previously allocated by new and returns the memory associated with that pointer to the heap.</p><h2 id=tree>Tree<a hidden class=anchor aria-hidden=true href=#tree>#</a></h2><ul><li>Node, tree, subtree, parent, child, root, edge, leaf</li><li>For any node ni, the depth of ni is the length of the unique path from the root to ni. The height of ni is the length of the longest path from ni to a leaf</li><li>Rules for all trees<ul><li>Recursive branching structure</li><li>Single root node</li><li>Every node reachable from root by unique path</li></ul></li></ul><h3 id=binary-tree>Binary tree<a hidden class=anchor aria-hidden=true href=#binary-tree>#</a></h3><p>Each node has at most 2 children.</p><p>Binary search tree</p><ul><li>All nodes in left subtree are less than root, all nodes in right subtree are greater.</li><li>Arranged for efficient search/insert.</li><li>It is the basis for the implementation of two library collections classes, set and map.</li><li>Most operations&rsquo; average running time is O(log N).</li></ul><h3 id=operating-on-trees>Operating on trees<a hidden class=anchor aria-hidden=true href=#operating-on-trees>#</a></h3><p>Many tree algorithms are recursive</p><ul><li>Handle current node, recur on subtrees</li><li>Base case is empty tree (NULL)</li></ul><p>Tree traversals to visit all nodes, order of traversal:</p><ul><li>Pre: cur, left, right</li><li>In: left, cur, right</li><li>Post: left, right, cur</li><li>Others: level-by-level, reverse orders, etc</li></ul><h3 id=balanced-search-trees><a href=http://algs4.cs.princeton.edu/33balanced/>Balanced Search Trees</a><a hidden class=anchor aria-hidden=true href=#balanced-search-trees>#</a></h3><p>Binary search tree have poor worst-case performance.</p><p>To make costs are guaranteed to be logarithmic, no matter what sequence of keys is used to construct them, the ideal is to keep binary search trees perfectly balanced. Unfortunately, maintaining perfect balance for dynamic insertions is too expensive. So consider data structure that slightly relaxes the perfect balance requirement to provide guaranteed logarithmic performance not just for the insert and search operations, but also for all of the ordered operations (except range search).</p><h3 id=avl-tree>AVL tree<a hidden class=anchor aria-hidden=true href=#avl-tree>#</a></h3><p>Adelson-Velskii and Landis tree is a binary search tree with a <strong>balance condition</strong>.</p><ul><li>Track balance factor for each node: Height of right subtree - height of left subtree information is kept for each node (in the node structure)</li><li>For every node in the tree, the height of the left and right subtrees can differ by at most 1 (Balance factor = 0 or 1).</li><li>When balance factor hits 2, restructure</li><li><strong>Rotation</strong> moves nodes from heavy to light side<ul><li>Local rearrangement around specific node</li><li>When finished, node has 0 balance factor</li><li>Single rotation: one time rotation between new insert node and its parent node</li><li>Double rotation: two single rotation of the new insert node  </li></ul></li></ul><h3 id=2-3-trees>2-3 trees<a hidden class=anchor aria-hidden=true href=#2-3-trees>#</a></h3><p>Allow the nodes in the tree to hold more than one key: 3-nodes, which hold three links and two keys.</p><p>A 2-3 search tree is a tree that is either empty or</p><ul><li>A 2-node, with one key (and associated value) and two links, a left link to a 2-3 search tree with smaller keys, and a right link to a 2-3 search tree with larger keys</li><li>A 3-node, with two keys (and associated values) and three links, a left link to a 2-3 search tree with smaller keys, a middle link to a 2-3 search tree with keys between the node’s keys, and a right link to a 2-3 search tree with larger keys</li><li>A perfectly balanced 2-3 search tree is one whose null links are all the same distance from the root.</li></ul><p>The concept guarantee that search and insert operations in a 2-3 tree with N keys are to visit at most <code>lg N</code> nodes.</p><ul><li>But its dicrect implementation is inconvenient: Not only is there a substantial amount of code involved, but the overhead incurred could make the algorithms slower than standard BST search and insert.</li><li>Consider a simple representation known as a <a href=/posts/stanford-cs106a/b-programming-intro-%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8%E8%AF%BE/#red-black-trees>red-black BST</a> that leads to a natural implementation.</li></ul><h3 id=binary-heap>Binary Heap<a hidden class=anchor aria-hidden=true href=#binary-heap>#</a></h3><p>A heap is a binary tree that is completely filled, with the possible exception of the bottom level, which is filled from left to right. Such a tree is known as a complete binary tree.</p><ul><li>A heap data structure consist of an array (of Comparable objects) and an integer representing the current heap size.</li><li>For any element in array position i, the left child is in position 2i, the right child is in the cell after the left child [2i + 1], and the parent is in position [i/2].</li><li>Heap-Order Property: For every node X, the key in the parent of X is smaller than (or equal to) the key in X. So to make find minimum operation quick.</li></ul><p>Basic Heap Operation</p><ul><li><code>insert</code>: To insert an element X into the heap, create a hole in the next available location. Then <strong>Percolate up</strong> - swap X with its parent index (i/2) so long as X has a higher priority than its parent. Continue this process until X has no more lower priority parent.</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=c1>//Percolate up
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kt>int</span> <span class=n>hole</span> <span class=o>=</span> <span class=o>++</span><span class=n>size</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=n>binaryQueue</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>=</span><span class=n>std</span><span class=o>::</span><span class=n>move</span><span class=p>(</span><span class=o>*</span><span class=n>newOne</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span> <span class=p>;</span> <span class=p>(</span><span class=n>priority</span> <span class=o>&lt;</span> <span class=n>binaryQueue</span><span class=p>[</span><span class=n>hole</span><span class=o>/</span><span class=mi>2</span><span class=p>].</span><span class=n>priority</span> <span class=o>||</span> <span class=p>(</span><span class=n>priority</span> <span class=o>==</span> <span class=n>binaryQueue</span><span class=p>[</span><span class=n>hole</span><span class=o>/</span><span class=mi>2</span><span class=p>].</span><span class=n>priority</span> <span class=o>&amp;&amp;</span> <span class=n>name</span> <span class=o>&lt;</span> <span class=n>binaryQueue</span><span class=p>[</span><span class=n>hole</span><span class=o>/</span><span class=mi>2</span><span class=p>].</span><span class=n>name</span><span class=p>)</span> <span class=p>);</span> <span class=n>hole</span><span class=o>/=</span><span class=mi>2</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=n>binaryQueue</span><span class=p>[</span><span class=n>hole</span><span class=p>]</span> <span class=o>=</span> <span class=n>std</span><span class=o>::</span><span class=n>move</span><span class=p>(</span><span class=n>binaryQueue</span><span class=p>[</span><span class=n>hole</span><span class=o>/</span><span class=mi>2</span><span class=p>]);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=n>binaryQueue</span><span class=p>[</span><span class=n>hole</span><span class=p>]</span> <span class=o>=</span> <span class=n>std</span><span class=o>::</span><span class=n>move</span><span class=p>(</span><span class=n>binaryQueue</span><span class=p>[</span><span class=mi>0</span><span class=p>]);</span>
</span></span></code></pre></div><ul><li><code>deleteMin</code>: When the minimum is removed, a hole is created at the root. Move the last element X in the heap to place in the root hole. Then <strong>Percolate down</strong> - swapp X with its more urgent-priority child [index (i<em>2 or i</em>2+1)] so long as it has a lower priority than its child. Repeat this step until X has no more higher priority child.</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=c1>//Percolate down
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kt>int</span> <span class=n>child</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=p>(;</span> <span class=n>hole</span><span class=o>*</span><span class=mi>2</span><span class=o>&lt;=</span><span class=n>size</span><span class=p>;</span><span class=n>hole</span><span class=o>=</span><span class=n>child</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=n>child</span> <span class=o>=</span> <span class=n>hole</span><span class=o>*</span><span class=mi>2</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=k>if</span> <span class=p>(</span> <span class=n>child</span><span class=o>!=</span><span class=n>size</span> <span class=o>&amp;&amp;</span> <span class=p>(</span><span class=n>binaryQueue</span><span class=p>[</span><span class=n>child</span><span class=o>+</span><span class=mi>1</span><span class=p>].</span><span class=n>priority</span><span class=o>&lt;</span><span class=n>binaryQueue</span><span class=p>[</span><span class=n>child</span><span class=p>].</span><span class=n>priority</span> <span class=o>||</span> <span class=p>(</span><span class=n>binaryQueue</span><span class=p>[</span><span class=n>child</span><span class=o>+</span><span class=mi>1</span><span class=p>].</span><span class=n>priority</span><span class=o>==</span><span class=n>binaryQueue</span><span class=p>[</span><span class=n>child</span><span class=p>].</span><span class=n>priority</span> <span class=o>&amp;&amp;</span> <span class=n>binaryQueue</span><span class=p>[</span><span class=n>child</span><span class=o>+</span><span class=mi>1</span><span class=p>].</span><span class=n>name</span><span class=o>&lt;</span><span class=n>binaryQueue</span><span class=p>[</span><span class=n>child</span><span class=p>].</span><span class=n>name</span><span class=p>))</span> <span class=p>)</span>
</span></span><span class=line><span class=cl>	    <span class=o>++</span><span class=n>child</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=k>if</span> <span class=p>(</span> <span class=n>binaryQueue</span><span class=p>[</span><span class=n>child</span><span class=p>].</span><span class=n>priority</span><span class=o>&lt;</span><span class=n>priority_tobePerD</span> <span class=o>||</span> <span class=p>(</span><span class=n>binaryQueue</span><span class=p>[</span><span class=n>child</span><span class=p>].</span><span class=n>priority</span><span class=o>==</span><span class=n>priority_tobePerD</span> <span class=o>&amp;&amp;</span> <span class=n>binaryQueue</span><span class=p>[</span><span class=n>child</span><span class=p>].</span><span class=n>name</span><span class=o>&lt;</span><span class=n>name_tobePerD</span><span class=p>)</span> <span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	    <span class=n>binaryQueue</span><span class=p>[</span><span class=n>hole</span><span class=p>]</span> <span class=o>=</span> <span class=n>std</span><span class=o>::</span><span class=n>move</span><span class=p>(</span><span class=n>binaryQueue</span><span class=p>[</span><span class=n>child</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span> <span class=k>else</span> <span class=k>break</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><ul><li>Use integer division to avoid even odd index.</li></ul><h2 id=priority-queues>Priority Queues<a hidden class=anchor aria-hidden=true href=#priority-queues>#</a></h2><p>A priority queue is a data structure that allows at least the following two operations: <strong>insert</strong>, and <strong>deleteMin</strong>, which finds, returns, and removes the minimum element in the priority queue.</p><h2 id=algorithm-analysis>Algorithm Analysis<a hidden class=anchor aria-hidden=true href=#algorithm-analysis>#</a></h2><p>Space/time, big-O, scalability</p><h3 id=big-o>Big-O<a hidden class=anchor aria-hidden=true href=#big-o>#</a></h3><ul><li>Computational complexity: The relationship between N and the performance of an algorithm as N becomes large</li><li>Big-O notation: to denote the computational complexity of algorithms.</li><li>Standard simplifications of big-O<ul><li>Eliminate any term whose contribution to the total ceases to be significant as N becomes large.</li><li>Eliminate any constant factors.</li></ul></li><li>Worst-case versus average-case complexity
Average-case performance often reflects typical behavior, while worst-case performance represents a guarantee for performance on any possible input.</li><li>Predicting computational complexity from code structure<ul><li>Constant time: Code whose execution time does not depend on the problem size is said to run in constant time, which is expressed in big-O notation as O(1).</li><li>Linear time: function that are executed exactly n times, once for each cycle of the for loop, O(N)</li><li>Quadratic time: Algorithms like selection sort that exhibit O(N<sup>2</sup>) performance are said to run in quadratic tim</li><li>For many programs, you can determine the computational complexity simply by finding the piece of the code that is executed most often and determining how many times it runs as a function of N</li></ul></li></ul><h3 id=spacetime>Space/time<a hidden class=anchor aria-hidden=true href=#spacetime>#</a></h3><ul><li>In general, the most important measure of performance is execution time.</li><li>It also possible to apply complexity analysis to the amount of memory space required. Nowadays the memory is cheap, but it still matters when designing extreamly big programs, or APPs on small memory device, such as phones and wearable devices.</li></ul><h2 id=sorting>Sorting<a hidden class=anchor aria-hidden=true href=#sorting>#</a></h2><p>There are lots of different sorting algoritms, from the simple to very complex. Some optimized for certain situations (lots of duplicates, almost sorted, etc.). So why do we need multiple algorithms?</p><h3 id=selection-sort>Selection sort<a hidden class=anchor aria-hidden=true href=#selection-sort>#</a></h3><p>Select smallest and swap to front/backend</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=kt>void</span> <span class=nf>SelectionSort</span><span class=p>(</span><span class=n>Vector</span><span class=o>&lt;</span><span class=kt>int</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>arr</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl> <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>arr</span><span class=p>.</span><span class=n>size</span><span class=p>()</span><span class=o>-</span><span class=mi>1</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	 <span class=kt>int</span> <span class=n>minIndex</span> <span class=o>=</span> <span class=n>i</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	 <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>j</span> <span class=o>=</span> <span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>;</span> <span class=n>j</span> <span class=o>&lt;</span> <span class=n>arr</span><span class=p>.</span><span class=n>size</span><span class=p>();</span> <span class=n>j</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		 <span class=k>if</span> <span class=p>(</span><span class=n>arr</span><span class=p>[</span><span class=n>j</span><span class=p>]</span> <span class=o>&lt;</span> <span class=n>arr</span><span class=p>[</span><span class=n>minIndex</span><span class=p>])</span>
</span></span><span class=line><span class=cl>		 <span class=n>minIndex</span> <span class=o>=</span> <span class=n>j</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	 <span class=p>}</span>
</span></span><span class=line><span class=cl>	 <span class=n>Swap</span><span class=p>(</span><span class=n>arr</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>arr</span><span class=p>[</span><span class=n>minIndex</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Count work inside loops:</p><ul><li>First iteration does N-1 compares, second does N-2, and so on.</li><li>One swap per iteration</li><li>O(N<sup>2</sup>)</li></ul><h3 id=insertion-sort>Insertion sort<a hidden class=anchor aria-hidden=true href=#insertion-sort>#</a></h3><p>As sorting hand of just-dealt cards, each subsequent element inserted into proper place</p><ul><li>Start with first element (already sorted)</li><li>Insert next element relative to first</li><li>Repeat for third, fourth, etc.</li><li>Slide elements over to make space during insert</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=kt>void</span> <span class=nf>InsertionSort</span><span class=p>(</span><span class=n>Vector</span><span class=o>&lt;</span><span class=kt>int</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>v</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl> <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>v</span><span class=p>.</span><span class=n>size</span><span class=p>();</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl> <span class=kt>int</span> <span class=n>cur</span> <span class=o>=</span> <span class=n>v</span><span class=p>[</span><span class=n>i</span><span class=p>];</span> <span class=c1>// slide cur down into position to left
</span></span></span><span class=line><span class=cl><span class=c1></span> <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>j</span><span class=o>=</span><span class=n>i</span><span class=o>-</span><span class=mi>1</span><span class=p>;</span> <span class=n>j</span> <span class=o>&gt;=</span> <span class=mi>0</span> <span class=o>&amp;&amp;</span> <span class=n>v</span><span class=p>[</span><span class=n>j</span><span class=p>]</span> <span class=o>&gt;</span> <span class=n>cur</span><span class=p>;</span> <span class=n>j</span><span class=o>--</span><span class=p>)</span>
</span></span><span class=line><span class=cl> <span class=n>v</span><span class=p>[</span><span class=n>j</span><span class=o>+</span><span class=mi>1</span><span class=p>]</span> <span class=o>=</span> <span class=n>v</span><span class=p>[</span><span class=n>j</span><span class=p>];</span>
</span></span><span class=line><span class=cl> <span class=n>v</span><span class=p>[</span><span class=n>j</span><span class=o>+</span><span class=mi>1</span><span class=p>]</span> <span class=o>=</span> <span class=n>cur</span><span class=p>;</span>
</span></span><span class=line><span class=cl> <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Because of the nested loops, each of which can take N iterations, insertion sort is O(N<sup>2</sup>).</p><h3 id=heapsort>Heapsort<a hidden class=anchor aria-hidden=true href=#heapsort>#</a></h3><p><a href=/posts/stanford-cs106a/b-programming-intro-%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8%E8%AF%BE/#priority-queues>Priority queues</a> can be used to sort in O(N log N) time. The algorithm based on this idea is known as heapsort.</p><p>The building of the heap, uses less than 2N comparisons. In the second phase, the ith <code>deleteMax</code> uses at most less than <code>2\*log (N − i + 1)</code> comparisons, for a total of at most <code>2N log N − O(N)</code> comparisons (assuming N ≥ 2). Consequently, in the worst case, at most <code>2N log N − O(N)</code> comparisons are used by heapsort.</p><h3 id=merge-sort>Merge sort<a hidden class=anchor aria-hidden=true href=#merge-sort>#</a></h3><p>Inspiration: Algorithm like selection sort is quadratic growth (O(N<sup>2</sup>)). Double input -> 4X time, halve input -> 1/4 time.
Can recursion save the day? If there are two sorted halves, how to produce sorted full result?</p><p><a href=/posts/stanford-cs106a/b-programming-intro-%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8%E8%AF%BE/#divide-and-conquer>Divide and conquer</a> algorithm</p><ul><li>Divide input in half</li><li>Recursively sort each half</li><li>Merge two halves together</li></ul><p>&ldquo;Easy-split hard-join&rdquo;</p><ul><li>No complex decision about which goes where, just divide in middle</li><li>Merge step preserves ordering from each half</li></ul><p>Merge depends on the fact that the first element in the complete ordering must be either the first element in v1 or the first element in v2, whichever is smaller.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=kt>void</span> <span class=nf>MergeSort</span><span class=p>(</span><span class=n>Vector</span><span class=o>&lt;</span><span class=kt>int</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>v</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl> <span class=k>if</span> <span class=p>(</span><span class=n>v</span><span class=p>.</span><span class=n>size</span><span class=p>()</span> <span class=o>&gt;</span> <span class=mi>1</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl> <span class=kt>int</span> <span class=n>n1</span> <span class=o>=</span> <span class=n>v</span><span class=p>.</span><span class=n>size</span><span class=p>()</span><span class=o>/</span><span class=mi>2</span><span class=p>;</span>
</span></span><span class=line><span class=cl> <span class=kt>int</span> <span class=n>n2</span> <span class=o>=</span> <span class=n>v</span><span class=p>.</span><span class=n>size</span><span class=p>()</span> <span class=o>-</span> <span class=n>n1</span><span class=p>;</span>
</span></span><span class=line><span class=cl> <span class=n>Vector</span><span class=o>&lt;</span><span class=kt>int</span><span class=o>&gt;</span> <span class=n>left</span> <span class=o>=</span> <span class=n>Copy</span><span class=p>(</span><span class=n>v</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=n>n1</span><span class=p>);</span>
</span></span><span class=line><span class=cl> <span class=n>Vector</span><span class=o>&lt;</span><span class=kt>int</span><span class=o>&gt;</span> <span class=n>right</span> <span class=o>=</span> <span class=n>Copy</span><span class=p>(</span><span class=n>v</span><span class=p>,</span> <span class=n>n1</span><span class=p>,</span> <span class=n>n2</span><span class=p>);</span>
</span></span><span class=line><span class=cl> <span class=n>MergeSort</span><span class=p>(</span><span class=n>left</span><span class=p>);</span>
</span></span><span class=line><span class=cl> <span class=n>MergeSort</span><span class=p>(</span><span class=n>right</span><span class=p>);</span>
</span></span><span class=line><span class=cl> <span class=n>v</span><span class=p>.</span><span class=n>clear</span><span class=p>();</span>
</span></span><span class=line><span class=cl> <span class=n>Merge</span><span class=p>(</span><span class=n>v</span><span class=p>,</span> <span class=n>left</span><span class=p>,</span> <span class=n>right</span><span class=p>);</span>
</span></span><span class=line><span class=cl> <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kt>void</span> <span class=nf>Merge</span><span class=p>(</span><span class=n>Vector</span><span class=o>&lt;</span><span class=kt>int</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>v</span><span class=p>,</span><span class=n>Vector</span><span class=o>&lt;</span><span class=kt>int</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>left</span><span class=p>,</span><span class=n>Vector</span><span class=o>&lt;</span><span class=kt>int</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>right</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=kt>int</span> <span class=n>l</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>r</span><span class=o>=</span><span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>	<span class=k>while</span><span class=p>(</span><span class=n>l</span><span class=o>&lt;</span><span class=n>left</span><span class=p>.</span><span class=n>size</span><span class=p>()</span> <span class=o>&amp;&amp;</span> <span class=n>r</span><span class=o>&lt;</span><span class=n>right</span><span class=p>.</span><span class=n>size</span><span class=p>())</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=k>if</span> <span class=p>(</span><span class=n>left</span><span class=p>[</span><span class=n>l</span><span class=p>]</span><span class=o>&lt;</span><span class=n>right</span><span class=p>[</span><span class=n>r</span><span class=p>])</span>
</span></span><span class=line><span class=cl>			<span class=n>v</span><span class=p>.</span><span class=n>add</span><span class=p>(</span><span class=n>left</span><span class=p>[</span><span class=n>l</span><span class=o>++</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>		<span class=k>else</span>
</span></span><span class=line><span class=cl>			<span class=n>v</span><span class=p>.</span><span class=n>add</span><span class=p>(</span><span class=n>right</span><span class=p>[</span><span class=n>r</span><span class=o>++</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl>	<span class=k>while</span><span class=p>(</span><span class=n>l</span><span class=o>&lt;</span><span class=n>left</span><span class=p>.</span><span class=n>size</span><span class=p>())</span> <span class=n>v</span><span class=p>.</span><span class=n>add</span><span class=p>(</span><span class=n>left</span><span class=p>[</span><span class=n>l</span><span class=o>++</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>	<span class=k>while</span><span class=p>(</span><span class=n>r</span><span class=o>&lt;</span><span class=n>right</span><span class=p>.</span><span class=n>size</span><span class=p>())</span> <span class=n>v</span><span class=p>.</span><span class=n>add</span><span class=p>(</span><span class=n>right</span><span class=p>[</span><span class=n>r</span><span class=o>++</span><span class=p>]);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>The time to mergesort N numbers is equal to the time to do two recursive mergesorts of size N/2, plus the time to merge, which is linear. <code>T(N) = N + 2T(N/2)</code>. <code>log N levels * N per level= O(NlogN)</code>. Mergesort uses the lowest number of comparisons of all the popular sorting algorithms.</p><p>Theoretical result show that no general sort algorithm could be better than NlogN.</p><p>But there is still better in practice:</p><ul><li>The running time of mergesort, when compared with other O(N log N) alternatives, depends heavily on the relative costs of comparing elements and moving elements in the array (and the temporary array). These costs are language dependent.</li><li>In <strong>Java</strong>, when performing a generic sort (using a Comparator), an element <strong>comparison can be expensive</strong>, but <strong>moving elements is cheap</strong> (because they are reference assignments, rather than copies of large objects).</li><li>In <strong>C++</strong>, in a generic sort, <strong>copying objects can be expensive</strong> if the objects are large, while <strong>comparing objects often is relatively cheap</strong> because of the ability of the compiler to aggressively perform inline optimization.</li></ul><h3 id=quicksort>Quicksort<a hidden class=anchor aria-hidden=true href=#quicksort>#</a></h3><p>Most sorting programs in use today are based on an algorithm called Quicksort, which employs a <a href=/posts/stanford-cs106a/b-programming-intro-%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8%E8%AF%BE/#divide-and-conquer>Divide and conquer</a> strategy as merge sort, but instead take a different approach to divide up input vector into low half and high half. Quicksort uses a few more comparisons, in exchange for significantly fewer data movements. The reason that quicksort is faster is that the partitioning step can actually be performed in place and very efficiently.</p><p>&ldquo;Hard-split easy-join&rdquo;, Each element examined and placed in correct half, so that join step become trivial.</p><ul><li>Choose an element (<strong>pivot</strong>) to serve as the boundary between the small and large elements.</li><li>Partitioning: Rearrange the elements in the vector so that all elements to the left of the boundary are less than the pivot and all elements to the right are greater than or possibly equal to the pivot.</li><li>Sort the elements in each of the partial vectors.</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=kt>void</span> <span class=nf>Quicksort</span><span class=p>(</span><span class=n>Vector</span><span class=o>&lt;</span><span class=kt>int</span><span class=o>&gt;</span> <span class=o>&amp;</span><span class=n>v</span><span class=p>,</span> <span class=kt>int</span> <span class=n>start</span><span class=p>,</span> <span class=kt>int</span> <span class=n>stop</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl> <span class=k>if</span> <span class=p>(</span><span class=n>stop</span> <span class=o>&gt;</span> <span class=n>start</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl> <span class=kt>int</span> <span class=n>pivot</span> <span class=o>=</span> <span class=n>Partition</span><span class=p>(</span><span class=n>v</span><span class=p>,</span> <span class=n>start</span><span class=p>,</span> <span class=n>stop</span><span class=p>);</span>
</span></span><span class=line><span class=cl> <span class=n>Quicksort</span><span class=p>(</span><span class=n>v</span><span class=p>,</span> <span class=n>start</span><span class=p>,</span> <span class=n>pivot</span><span class=o>-</span><span class=mi>1</span><span class=p>);</span>
</span></span><span class=line><span class=cl> <span class=n>Quicksort</span><span class=p>(</span><span class=n>v</span><span class=p>,</span> <span class=n>pivot</span><span class=o>+</span><span class=mi>1</span><span class=p>,</span> <span class=n>stop</span><span class=p>);</span>
</span></span><span class=line><span class=cl> <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>The running time of quicksort is equal to the running time of the two recursive calls plus the linear time spent in the partition (the pivot selection takes only constant time). T(N) = T(i) + T(N − i − 1) + cN, where i = |S1| is the number of elements in S1.</p><p>There are thre cases</p><ul><li>Ideal 50/50 split: The pivot is in the middle, T(N) = cN + 2T(N/2) => O(NlogN)</li><li>Average bad 90/10 split: N per level, but more levels, solve N*(9/10)<sup>k</sup> = 1, still k = O(NlogN)</li><li>Worst N-1/1 split: The pivot is the smallest element, all the time. Then i = 0, T(N) = T(N − 1) + cN, N > 1. With N levels! O(N<sup>2</sup>)</li></ul><p>In a vector with randomly chosen elements, Quicksort tends to perform well, with an average-case complexity of O(N log N). In the worst case — which paradoxically consists of a vector that is already sorted — the performance degenerates to O(N<sup>2</sup>). Despite this inferior behavior in the worst case, Quicksort is so much faster in practice than most other algorithms that it has become the standard.</p><h4 id=quicksort-strategy>Quicksort strategy<a hidden class=anchor aria-hidden=true href=#quicksort-strategy>#</a></h4><p>Picking the pivot
Picking a good pivot improves performance, but also costs some time. If the algorithm spends more time choosing the pivot than it gets back from making a good choice, you will end up slowing down the implementation rather than speeding it up.</p><ul><li>The popular, uninformed choice is to use the first element as the pivot. This is acceptable if the input is random, but if the input is presorted or in reverse order, then the pivot provides a poor partition.</li><li>A safe approach is to choose the pivot element randomly. On the other hand, random number generation is generally an expensive commodity and does not reduce the average running time of the rest of the algorithm at all.</li><li>A good estimate can be obtained by picking three elements randomly and using the median of these three as pivot. The randomness turns out not to help much, so the common course is to use as pivot the median of the left, right, and center elements.</li></ul><p>Quicksort partitioning strategy
A known method that is very easy to do it wrong or inefficiently.</p><ul><li>General process:<ul><li>The first step is to get the pivot element out of the way by swapping it with the last element.</li><li>Two pointers, i point to the first element and j to the next-to-last element. What our partitioning stage wants to do is to move all the small elements to the left part of the array and all the large elements to the right part. “Small” and “large” are relative to the pivot.</li><li>While i is to the left of j, we move i right, skipping over elements that are smaller than the pivot. We move j left, skipping over elements that are larger than the pivot.</li><li>When i and j have stopped, i is pointing at a large element and j is pointing at a small element. If i is to the left of j (not yet cross), those elements are swapped.</li><li>Repeat the process until i and j cross</li><li>The final is to swap the pivot element with present i element</li></ul></li><li>One important detail we must consider is how to handle elements that are equal to the pivot? Suppose there are 10,000,000 elements, of which 500,000 are identical (or, more likely, complex elements whose sort keys are identical).<ul><li>To get an idea of what might be good, we consider the case where all the elements in the array are identical.</li><li>If neither i nor j stops, and code is present to prevent them from running off the end of the array, no swaps will be performed. Although this seems good, a correct implementation would then swap the pivot into the last spot that i touched, which would be the next-to last position (or last, depending on the exact implementation). This would create very uneven subarrays. If all the elements are identical, the running time is O(N<sup>2</sup>).</li><li>If both i and j stop, there will be many swaps between identical elements. The partition creates two nearly equal subarrays. The total running time would then be O(N log N).</li><li>Thus it is better to do the unnecessary swaps and create even subarrays than to risk wildly uneven subarrays.</li></ul></li><li>Small arrays<ul><li>For very small arrays (N ≤ 20), quicksort does not perform as well as insertion sort.</li><li>Furthermore, because quicksort is recursive, these cases will occur frequently.</li><li>A common solution is not to use quicksort recursively for small arrays, but instead use a sorting algorithm that is efficient for small arrays, such as insertion sort.</li><li>A good cutoff range is N = 10, although any cutoff between 5 and 20 is likely to produce similar results. This also saves nasty degenerate cases, such as taking the median of three elements when there are only one or two.</li></ul></li></ul><h2 id=design-strategy>Design Strategy<a hidden class=anchor aria-hidden=true href=#design-strategy>#</a></h2><p>When an algorithm is given, the actual data structures need not be specified. It is up to the programmer to choose the appropriate data structure in order to make the running time as small as possible. There are many to be considered: algorithms, data structure, space-time tradeoff, code complexity.</p><h2 id=dynamic-programming>Dynamic Programming<a hidden class=anchor aria-hidden=true href=#dynamic-programming>#</a></h2><p>To solve optimization problems in which we make a set of choices in order to arrive at an optimal solution. As we make each choice, subproblems of the same form often arise. Dynamic programming is effective when a given subproblem may arise from more than one partial set of choices; the key technique is to store the solution to each such subproblem in case it should reappear. Unlike divide-and-conquer algorithms which partition the problem into disjoint subproblems, dynamic programming applies when the subproblems overlap.</p><ul><li>“Programming” in this context refers to a tabular method.</li><li>When should look for a dynamic-programming solution to a problem?<ul><li>Optimal substructure: a problem exhibits optimal substructure if an optimal solution to the problem contains within it optimal solutions to subproblems.</li><li>Overlapping subproblems: When a recursive algorithm revisits the same problem repeatedly, we say that the optimization problem
has overlapping subproblems. In contrast, a problem for which a divide-andconquer approach is suitable usually generates brand-new problems at each step of the recursion.</li></ul></li><li>General setps of Dynamic Programming<ul><li>Characterize the structure of an optimal solution.</li><li>Recursively define the value of an optimal solution.</li><li>Compute the value of an optimal solution, typically in a bottom-up fashion.</li><li>Construct an optimal solution from computed information.</li></ul></li></ul><h2 id=greedy-algorithms>Greedy Algorithms<a hidden class=anchor aria-hidden=true href=#greedy-algorithms>#</a></h2><p>Greedy algorithms work in phases. In each phase, a decision is made in a locally optimal manner, without regard for future consequences. When the algorithm terminates, we hope that the local optimum is equal to the global optimum. If this is the case, then the algorithm is correct; otherwise, the algorithm has produced a suboptimal solution.</p><p><a href=https://en.wikipedia.org/wiki/Huffman_coding>Huffman Codes</a></p><ul><li>A Huffman code is a particular type of optimal prefix code that is commonly used for lossless data compression.</li><li>The reason that this is a greedy algorithm is that at each stage we perform a merge without regard to global considerations. We merely select the two smallest trees.</li><li>If we maintain the trees in a priority queue, ordered by weight, then the running time is O(C logC), since there will be one buildHeap, 2C − 2 deleteMins, and C − 2 inserts. A simple implementation of the priority queue, using a list, would give an O(C<sup>2</sup>) algorithm. The choice of priority queue implementation depends on how large C is. In the typical case of an ASCII character set, C is small enough that the quadratic running time is acceptable.</li></ul><h2 id=divide-and-conquer>Divide and Conquer<a hidden class=anchor aria-hidden=true href=#divide-and-conquer>#</a></h2><p>Traditionally, routines in which the text contains at least two recursive calls and subproblems be disjoint (that is, essentially nonoverlapping) are called divide-and-conquer algorithms.</p><ul><li>Divide: Smaller problems are solved recursively (except, of course, base cases).</li><li>Conquer: The solution to the original problem is then formed from the solutions to the subproblems.
We have already seen several divide-and-conquer algorithms: mergesort and quicksort, which have <code>O(N log N)</code> worst-case and averagecase bounds, respectively.</li></ul><h2 id=backtracking-algorithms>Backtracking Algorithms<a hidden class=anchor aria-hidden=true href=#backtracking-algorithms>#</a></h2><p>See <a href=/posts/stanford-cs106a/b-programming-intro-%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8%E8%AF%BE/#recursive-backtracking>Recursive Backtracking</a>
In some cases, the savings over a brute-force exhaustive search can be significant.
The elimination of a large group of possibilities in one step is known as <strong>pruning</strong>.</p><h2 id=how-to-evaluatecompare-alternatives>How to evaluate/compare alternatives<a hidden class=anchor aria-hidden=true href=#how-to-evaluatecompare-alternatives>#</a></h2><ul><li>Often interested in execution performance: Time spent and memory used</li><li>Should also consider ease of developing, verifying, maintaining code</li></ul><h2 id=text-editor-case-study>Text editor case study<a hidden class=anchor aria-hidden=true href=#text-editor-case-study>#</a></h2><ol><li><p>Buffer requirements</p><ul><li>Sequence of characters + cursor position</li><li>Operations to match commands above</li></ul></li><li><p>What to consider?</p><ul><li>Implementation choices</li><li>performance implications</li></ul></li><li><p>Buffer class interface</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=k>class</span> <span class=nc>Buffer</span> <span class=p>{</span>
</span></span><span class=line><span class=cl> <span class=k>public</span><span class=o>:</span>
</span></span><span class=line><span class=cl> <span class=n>Buffer</span><span class=p>();</span>
</span></span><span class=line><span class=cl> <span class=o>~</span><span class=n>Buffer</span><span class=p>();</span>
</span></span><span class=line><span class=cl> <span class=kt>void</span> <span class=nf>moveCursorForward</span><span class=p>();</span>
</span></span><span class=line><span class=cl> <span class=kt>void</span> <span class=nf>moveCursorBackward</span><span class=p>();</span>
</span></span><span class=line><span class=cl> <span class=kt>void</span> <span class=nf>moveCursorToStart</span><span class=p>();</span>
</span></span><span class=line><span class=cl> <span class=kt>void</span> <span class=nf>moveCursorToEnd</span><span class=p>();</span>
</span></span><span class=line><span class=cl> <span class=kt>void</span> <span class=nf>insertCharacter</span><span class=p>(</span><span class=kt>char</span> <span class=n>ch</span><span class=p>);</span>
</span></span><span class=line><span class=cl> <span class=kt>void</span> <span class=nf>deleteCharacter</span><span class=p>();</span>
</span></span><span class=line><span class=cl> <span class=kt>void</span> <span class=nf>display</span><span class=p>();</span>
</span></span><span class=line><span class=cl> <span class=k>private</span><span class=o>:</span>
</span></span><span class=line><span class=cl> <span class=c1>// TBD!
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=p>};</span>
</span></span></code></pre></div></li><li><p>Buffer layered on Vector</p><ul><li>Need character data + cursor<ul><li>Chars in <code>Vector&lt;char></code></li><li>Represent cursor as integer index</li><li>Minor detail &ndash; is index before/after cursor?</li></ul></li><li>Buffer contains: AB|CDE</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=c1>// for Buffer class
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>private</span><span class=o>:</span>
</span></span><span class=line><span class=cl> <span class=n>Vector</span><span class=o>&lt;</span><span class=kt>char</span><span class=o>&gt;</span> <span class=n>chars</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=n>cursor</span><span class=p>;</span>
</span></span></code></pre></div><ul><li>Performance<ul><li>insertCharacter() and deleteCharacter() is linear, other operation is just O(1)</li><li>Space used ~1 byte per char</li></ul></li></ul></li><li><p>Buffer layered on Stack</p><ul><li>Inspiration: add/remove at end of vector is fast<ul><li>If chars next to cursor were at end…</li><li>Build on top of stack?</li><li>Another layered abstraction!</li><li>How is cursor represented?</li></ul></li><li>Buffer contains:AB|CDE
There is no explicit cursor representation, instead using two stack to represent a whole data structure being seperated by the implicit cursor.</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=c1>// for Buffer class
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>private</span><span class=o>:</span>
</span></span><span class=line><span class=cl> <span class=n>Stack</span><span class=o>&lt;</span><span class=kt>char</span><span class=o>&gt;</span> <span class=n>before</span><span class=p>,</span> <span class=n>after</span><span class=p>;</span>
</span></span></code></pre></div><ul><li>Performance<ul><li>moveCursorToStart(), moveCursorToEnd() operation is linear, other operation is just O(1)</li><li>Space used ~2 byte per char</li></ul></li></ul></li><li><p>Buffer as double linked list</p><ul><li>Inspiration: contiguous memory is constraining<ul><li>Connect chars without locality</li><li>Add tail pointer to get direct access to last cell</li><li>Add prev link to speed up moving backwards</li></ul></li><li>Buffer contains:AB|CDE</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=c1>// for Buffer class
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>private</span><span class=o>:</span>
</span></span><span class=line><span class=cl> <span class=k>struct</span> <span class=nc>cellT</span> <span class=p>{</span>
</span></span><span class=line><span class=cl> <span class=kt>char</span> <span class=n>ch</span><span class=p>;</span>
</span></span><span class=line><span class=cl> <span class=n>cellT</span> <span class=o>*</span><span class=n>prev</span><span class=p>,</span> <span class=o>*</span><span class=n>next</span><span class=p>;</span>
</span></span><span class=line><span class=cl> <span class=p>};</span>
</span></span><span class=line><span class=cl> <span class=n>cellT</span> <span class=o>*</span><span class=n>head</span><span class=p>,</span> <span class=o>*</span><span class=n>tail</span><span class=p>,</span> <span class=o>*</span><span class=n>cursor</span><span class=p>;</span>
</span></span></code></pre></div><ul><li>Cursor design<ul><li>To cell before or after?</li><li>5 letters, 6 cursor positions…</li><li>Add &ldquo;dummy cell&rdquo; to front of list</li></ul></li><li>Performance<ul><li>destruction is linear, other operation is just O(1)</li><li>Space used ~9 byte per char</li></ul></li></ul></li><li><p>Compare implementations</p></li></ol><style>table th:nth-of-type(1){width:200px}table th:nth-of-type(2){width:80px}table th:nth-of-type(3){width:80px}</style><table><thead><tr><th>Operation</th><th style=text-align:center>Vector</th><th style=text-align:center>Stack</th><th style=text-align:center>Single linked list</th><th style=text-align:center>Double linked list</th></tr></thead><tbody><tr><td>Buffer()</td><td style=text-align:center>O(1)</td><td style=text-align:center>O(1)</td><td style=text-align:center>O(1)</td><td style=text-align:center>O(1)</td></tr><tr><td>~Buffer()</td><td style=text-align:center>O(1)</td><td style=text-align:center>O(1)</td><td style=text-align:center>O(N)</td><td style=text-align:center>O(N)</td></tr><tr><td>moveCursorForward()</td><td style=text-align:center>O(1)</td><td style=text-align:center>O(1)</td><td style=text-align:center>O(1)</td><td style=text-align:center>O(1)</td></tr><tr><td>moveCursorBackward()</td><td style=text-align:center>O(1)</td><td style=text-align:center>O(1)</td><td style=text-align:center>O(N)</td><td style=text-align:center>O(1)</td></tr><tr><td>moveCursorToStart()</td><td style=text-align:center>O(1)</td><td style=text-align:center>O(N)</td><td style=text-align:center>O(1)</td><td style=text-align:center>O(1)</td></tr><tr><td>moveCursorToEnd()</td><td style=text-align:center>O(1)</td><td style=text-align:center>O(N)</td><td style=text-align:center>O(N)</td><td style=text-align:center>O(1)</td></tr><tr><td>insertCharacter()</td><td style=text-align:center>O(N)</td><td style=text-align:center>O(1)</td><td style=text-align:center>O(1)</td><td style=text-align:center>O(1)</td></tr><tr><td>deleteCharacter()</td><td style=text-align:center>O(N)</td><td style=text-align:center>O(1)</td><td style=text-align:center>O(1)</td><td style=text-align:center>O(1)</td></tr><tr><td>Space used</td><td style=text-align:center>1N</td><td style=text-align:center>2N</td><td style=text-align:center>5N</td><td style=text-align:center>9N</td></tr></tbody></table><ol start=9><li>Space-time tradeoff<ul><li>Doubly-linked list is O(1) on all six operations<ul><li>But, each char uses 1 byte + 8 bytes of pointers => 89% overhead!</li></ul></li><li>Compromise: chunklist<ul><li>Array and linked list hybrid</li><li>Shares overhead cost among several chars</li><li>Chunksize can be tuned as appropriate</li></ul></li><li>Cost shows up in code complexity<ul><li>Cursor must traverse both within and across chunks</li><li>Splitting/merging chunks on insert/deletes</li></ul></li></ul></li></ol><h2 id=map>Map<a hidden class=anchor aria-hidden=true href=#map>#</a></h2><p>Map is super-useful, support any kind of dictionary, lookup table, index, database, etc.
Map stores key-value pairs, support fast access via key, operations to optimize: add, getValue
How to make it work efficiently?</p><ol><li>Implement Map as Vector<ul><li>Layer on Vector, provides convenience with low overhead</li><li>Define pair struct, to olds key and value together, <code>Vector&lt;pair></code></li><li>Vector sorted or unsorted? If sorted, sorted by what?<ul><li>Sorting: Provides fast lookup, but still slow to insert (because of shuffling)</li></ul></li><li>How to implement getValue, add?</li><li>Does a linked list help?<ul><li>Easy to insert, once at a position</li><li>But hard to find position to insert&mldr;</li></ul></li></ul></li><li>Implementing Map as tree<ul><li>Implementatation<ul><li>Each Map entry adds node to tree, node contains: string key, client-type value, pointers to left/right subtrees</li><li>Tree organized for binary search, Key is used as search field</li><li>getValue: Searches tree, comparing keys, find existing match or error</li><li>add: Searches tree, comparing keys, overwrites existing or adds new node</li></ul></li><li>Private members for Map</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=k>template</span> <span class=o>&lt;</span><span class=k>typename</span> <span class=n>ValType</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl> <span class=k>class</span> <span class=nc>Map</span>
</span></span><span class=line><span class=cl> <span class=p>{</span>
</span></span><span class=line><span class=cl> <span class=k>public</span><span class=o>:</span>
</span></span><span class=line><span class=cl> <span class=c1>// as before
</span></span></span><span class=line><span class=cl><span class=c1></span> <span class=k>private</span><span class=o>:</span>
</span></span><span class=line><span class=cl> <span class=k>struct</span> <span class=nc>node</span> <span class=p>{</span>
</span></span><span class=line><span class=cl> <span class=n>string</span> <span class=n>key</span><span class=p>;</span>
</span></span><span class=line><span class=cl> <span class=n>ValType</span> <span class=n>value</span><span class=p>;</span>
</span></span><span class=line><span class=cl> <span class=n>node</span> <span class=o>*</span><span class=n>left</span><span class=p>,</span> <span class=o>*</span><span class=n>right</span><span class=p>;</span>
</span></span><span class=line><span class=cl> <span class=p>};</span>
</span></span><span class=line><span class=cl> <span class=n>node</span> <span class=o>*</span><span class=n>root</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl> <span class=n>node</span> <span class=o>*</span><span class=nf>treeSearch</span><span class=p>(</span><span class=n>node</span> <span class=o>*</span> <span class=n>t</span><span class=p>,</span> <span class=n>string</span> <span class=n>key</span><span class=p>);</span>
</span></span><span class=line><span class=cl> <span class=kt>void</span> <span class=nf>treeEnter</span><span class=p>(</span><span class=n>node</span> <span class=o>*&amp;</span><span class=n>t</span><span class=p>,</span> <span class=n>string</span> <span class=n>key</span><span class=p>,</span> <span class=n>ValType</span> <span class=n>val</span><span class=p>);</span>
</span></span><span class=line><span class=cl> <span class=n>DISALLOW_COPYING</span><span class=p>(</span><span class=n>Map</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>};</span>
</span></span></code></pre></div><ul><li>Evaluate Map as tree<ul><li>Space used: Overhead of two pointers per entry (typically 8 bytes total)</li><li>Runtime performance: Add/getValue take time proportional to tree height(expected to be O(logN))</li></ul></li><li>Degenerate trees<ul><li>The insert order is &ldquo;sorted&rdquo;: 2 8 14 15 18 20 21, totally unbalanced with height = 7</li><li>The insert order is &ldquo;alternately sorted&rdquo;: 21 2 20 8 14 15 18 or 2 8 21 20 18 14 15</li><li>Association: What is the relationship between worst-case inputs for tree insertion and Quicksort?</li><li>What to do about it: AVL tree</li></ul></li></ul></li><li>Compare Map implementations</li></ol><table><thead><tr><th>Operation</th><th style=text-align:center>Vector</th><th style=text-align:center>BST</th><th style=text-align:center>Sorted Vector</th></tr></thead><tbody><tr><td>getValue</td><td style=text-align:center>O(N)</td><td style=text-align:center>O(lgN)</td><td style=text-align:center>O(lgN)</td></tr><tr><td>add</td><td style=text-align:center>O(N)</td><td style=text-align:center>O(lgN)</td><td style=text-align:center>O(N)</td></tr><tr><td>Space used</td><td style=text-align:center>N</td><td style=text-align:center>9N</td><td style=text-align:center>N</td></tr></tbody></table><h2 id=hashing>Hashing<a hidden class=anchor aria-hidden=true href=#hashing>#</a></h2><ul><li>Hash table ADT<ul><li>Hash table data structure: A list of keys and TableSize</li><li>Hash function: A mapping that map each key into some number in the range 0 to TableSize-1 and distributes the keys evenly among the appropriate cell</li></ul></li><li>Hashing
The major problems are choosing a function, deciding what to do when two keys hash to the same value (this is known as a
collision), and deciding on the table size</li><li>Rehashing
If the table gets too full, the running time for the operations will start taking too long, and insertions might fail for open addressing hashing with quadratic resolution. A solution is to build another table that is about twice as big (with an associated new hash function) and scan down the entire original hash table, computing the new hash value for each (nondeleted) element and inserting it in the new table.</li></ul><h2 id=the-big-five>The Big-Five<a hidden class=anchor aria-hidden=true href=#the-big-five>#</a></h2><p>In C++11, classes come with five special functions that are already written for you. These are the destructor, copy constructor, move constructor, copy assignment operator, and move assignment operator. Collectively these are the big-five.</p><h3 id=destructor>Destructor<a hidden class=anchor aria-hidden=true href=#destructor>#</a></h3><p>The destructor is called whenever an object goes out of scope or is subjected to a delete. Typically, the only responsibility of the destructor is to free up any resources that were acquired during the use of the object. This includes calling delete for any corresponding news, closing any files that were opened, and so on. The default simply applies the destructor on each data member.</p><h3 id=constructor>Constructor<a hidden class=anchor aria-hidden=true href=#constructor>#</a></h3><p>A constructor is a method that describes how an instance of the class is constructed. If no constructor is explicitly defined, one that initializes the data members using language defaults is automatically generated.</p><ul><li><p>Copy Constructor and Move Constructor</p></li><li><p>Copy Assignment and Move Assignment (operator=)
By Defaults, if a class consists of data members that are exclusively primitive types and objects for which the defaults make sense, the class defaults will usually make sense.
The main problem occurs in a class that contains a data member that is a pointer.</p><ul><li>The default destructor does nothing to data members that are pointers (for good reason—recall that we must delete ourselves).</li><li>Furthermore, the copy constructor and copy assignment operator both copy the value of the pointer rather than the objects being pointed at. Thus, we will have two class instances that contain pointers that point to the same object. This is a so-called <strong>shallow copy</strong> (contrast to deep copy).  </li><li>To avoid shallow copy, ban the copy funtionality by calling <code>DISALLOW_COPYING(ClassType)</code>.</li></ul><p>As a result, when a class contains pointers as data members, and deep semantics are important, we typically must implement the destructor, copy assignment, and copy constructors ourselves.</p></li><li><p>Explicit constructor:
All one-parameter constructors should be made explicit to avoid behind-the-scenes type conversions. Otherwise, there are somewhat lenient rules that will allow type conversions without explicit casting operations. Usually, this is unwanted behavior that destroys strong typing and can lead to hard-to-find bugs.
The use of explicit means that a one-parameter constructor cannot be used to generate an implicit temporary</p></li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=k>class</span> <span class=nc>IntCell</span>  <span class=p>{</span>
</span></span><span class=line><span class=cl><span class=k>public</span><span class=o>:</span>
</span></span><span class=line><span class=cl>	<span class=k>explicit</span> <span class=n>IntCell</span><span class=p>(</span> <span class=kt>int</span> <span class=n>initialValue</span> <span class=o>=</span> <span class=mi>0</span> <span class=p>)</span>
</span></span><span class=line><span class=cl>	 <span class=o>:</span> <span class=n>storedValue</span><span class=p>{</span> <span class=n>initialValue</span> <span class=p>}</span> <span class=p>{</span> <span class=p>}</span>
</span></span><span class=line><span class=cl>	<span class=kt>int</span> <span class=nf>read</span><span class=p>(</span> <span class=p>)</span> <span class=k>const</span>
</span></span><span class=line><span class=cl>	 <span class=p>{</span> <span class=k>return</span> <span class=n>storedValue</span><span class=p>;</span> <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=k>private</span><span class=o>:</span>
</span></span><span class=line><span class=cl>	<span class=kt>int</span> <span class=n>storedValue</span><span class=p>;</span>
</span></span><span class=line><span class=cl> <span class=p>};</span>
</span></span><span class=line><span class=cl><span class=n>IntCell</span> <span class=n>obj</span><span class=p>;</span> <span class=c1>// obj is an IntCell
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>obj</span> <span class=o>=</span> <span class=mi>37</span><span class=p>;</span> <span class=c1>// Should not compile: type mismatch
</span></span></span></code></pre></div><p>Since <code>IntCell</code> constructor is declared explicit, the compiler will correctly complain that there is a type mismatch</p><h2 id=template>Template<a hidden class=anchor aria-hidden=true href=#template>#</a></h2><h3 id=type-independent>Type-independent<a hidden class=anchor aria-hidden=true href=#type-independent>#</a></h3><p>When we write C++ code for a type-independent algorithm or data structure, we would prefer to write the code once rather than recode it for each different type</p><h3 id=function-template>Function template<a hidden class=anchor aria-hidden=true href=#function-template>#</a></h3><ul><li>A function template is not an actual function, but instead is a pattern for what could become a function.</li><li>An expansion for each new type generates additional code; this is known as <strong>code bloat</strong> when it occurs in large projects.</li></ul><h3 id=class-template>Class template<a hidden class=anchor aria-hidden=true href=#class-template>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=k>template</span> <span class=o>&lt;</span><span class=k>typename</span> <span class=n>Object</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>MemoryCell</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>     <span class=k>public</span><span class=o>:</span>
</span></span><span class=line><span class=cl>     <span class=k>explicit</span> <span class=n>MemoryCell</span><span class=p>(</span> <span class=k>const</span> <span class=n>Object</span> <span class=o>&amp;</span> <span class=n>initialValue</span> <span class=o>=</span> <span class=n>Object</span><span class=p>{</span> <span class=p>}</span> <span class=p>)</span>
</span></span><span class=line><span class=cl>     <span class=o>:</span> <span class=n>storedValue</span><span class=p>{</span> <span class=n>initialValue</span> <span class=p>}</span> <span class=p>{</span> <span class=p>}</span>
</span></span><span class=line><span class=cl>     <span class=k>private</span><span class=o>:</span>
</span></span><span class=line><span class=cl>     <span class=n>Object</span> <span class=n>storedValue</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>};</span>
</span></span></code></pre></div><p><code>MemoryCell</code> is not a class, it is only a class template. It will be a class if specify the Object type. <code>MemoryCell&lt;int></code> and <code>MemoryCell&lt;string></code> are the actual classes.</p><h2 id=graph-algorithms>Graph Algorithms<a hidden class=anchor aria-hidden=true href=#graph-algorithms>#</a></h2><p>Definitions: vertices, edges, arcs, directed arcs = digraphs, weight/cost, path, length, acyclic(no cycles)</p><h3 id=topological-sort>Topological Sort<a hidden class=anchor aria-hidden=true href=#topological-sort>#</a></h3><ul><li>A topological sort is an ordering of vertices in a directed acyclic graph, such that if there is a path from vi to vj, then vj appears after vi in the ordering.</li><li>A topological ordering is not possible if the graph has a cycle</li><li>To find a topological ordering, define the indegree of a vertex v as the number of edges (u, v), then use a queue or stack to keep the present 0 indegree vertexes. At each stage, as long as the queue is not empty, dequeue a 0 indegree vertexes in the queue, enqueue each new generated 0 indegree vertexes into the queue.</li></ul><h3 id=shortest-path-algorithms>Shortest-Path Algorithms<a hidden class=anchor aria-hidden=true href=#shortest-path-algorithms>#</a></h3><ul><li><p><a href=http://www.redblobgames.com/pathfinding/a-star/introduction.html#breadth-first-search>Breadth-first search</a></p><ul><li>Explores equally in all directions</li><li>To find unweighted shortest paths</li><li>Operates by processing vertices in layers: The vertices closest to the start are evaluated first, and the most distant vertices are evaluated last.</li></ul></li><li><p><a href=http://www.redblobgames.com/pathfinding/a-star/introduction.html#dijkstra>Dijkstra&rsquo;s Algorithm</a></p><ul><li>Also called Uniform Cost Search, cost matters</li><li>Instead of exploring all possible paths equally, it favors lower cost paths.</li><li>Dijkstra’s algorithm proceeds in stages. At each stage, while there are still vertices waiting to be known:<ul><li>Selects a vertex v, which has the <strong>smallest</strong> dv among all the <em>unknown</em> vertices, and declares v as <em>known</em> stage.</li><li>For each of v&rsquo;s neighbors, w, if the new path&rsquo;s cost from v to w is better than previous dw, dw will be updated.</li><li>But w will not be marked as <strong>known</strong>, unless at next while-loop stage, dw happens to be the smalles.</li></ul></li><li>The above steps could be implemented via a priority queue.</li><li>A proof by contradiction will show that this algorithm always works as long as no edge has a negative cost.</li><li>If the graph is sparse, with |E| =θ(|V|), this algorithm is too slow. In this case, the distances would need to be kept in a priority queue. Selection of the vertex v is a <strong>deleteMin</strong> operation. The update of w’s distance can be implemented two ways.<ul><li>One way treats the update as a decreaseKey operation.</li><li>An alternate method is to insert w and the new value dw into the priority queue every time w’s distance changes.</li></ul></li></ul></li><li><p><a href=http://www.redblobgames.com/pathfinding/a-star/introduction.html#greedy-best-first>Greedy Best First Search(Heuristic search)</a></p><ul><li>With Breadth First Search and Dijkstra’s Algorithm, the frontier expands in all directions. This is a reasonable choice if you’re trying to find a path to all locations or to many locations. However, a common case is to find a path to only one location.</li><li>A modification of Dijkstra’s Algorithm, optimized for a single destination. It prioritizes paths that seem to be leading closer to the goal.</li><li>To make the frontier expand towards the goal more than it expands in other directions.<ul><li>First, define a <em>heuristic</em> function that tells us how close we are to the goal, design a heuristic for each type of graph</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=n>def</span> <span class=n>heuristic</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>)</span><span class=o>:</span>
</span></span><span class=line><span class=cl>    <span class=cp># Manhattan distance on a square grid
</span></span></span><span class=line><span class=cl><span class=cp></span>    <span class=k>return</span> <span class=n>abs</span><span class=p>(</span><span class=n>a</span><span class=p>.</span><span class=n>x</span> <span class=o>-</span> <span class=n>b</span><span class=p>.</span><span class=n>x</span><span class=p>)</span> <span class=o>+</span> <span class=n>abs</span><span class=p>(</span><span class=n>a</span><span class=p>.</span><span class=n>y</span> <span class=o>-</span> <span class=n>b</span><span class=p>.</span><span class=n>y</span><span class=p>)</span>
</span></span></code></pre></div><ul><li>Use the estimated distance to the goal for the priority queue ordering. The location closest to the goal will be explored first.</li></ul></li><li>This algorithm runs faster when there aren’t a lot of obstacles, but the paths aren’t as good(not always the shortest).</li></ul></li><li><p><a href=http://www.redblobgames.com/pathfinding/a-star/introduction.html#astar>A* Algorithm</a></p><ul><li>Dijkstra’s Algorithm works well to find the shortest path, but it wastes time exploring in directions that aren’t promising. Greedy Best First Search explores in promising directions but it may not find the shortest path.</li><li>The A* algorithm uses both the actual distance from the start and the estimated distance to the goal.</li><li>Compare the algorithms: Dijkstra’s Algorithm calculates the distance from the start point. Greedy Best-First Search estimates the distance to the goal point. A* is using the sum of those two distances.</li><li>So A* is the best of both worlds. As long as the heuristic does not overestimate distances, A* does not use the heuristic to come up with an approximate answer. It finds an optimal path, like Dijkstra’s Algorithm does. A* uses the heuristic to reorder the nodes so that it’s more likely that the goal node will be encountered sooner.</li></ul></li><li><p>Conclusion: Which algorithm should you use for finding paths on a map?</p><ul><li>If you want to find paths from or to all all locations, use Breadth First Search or Dijkstra’s Algorithm. Use Breadth First Search if movement costs are all the same; use Dijkstra’s Algorithm if movement costs vary.</li><li>If you want to find paths to one location, use Greedy Best First Search or A*. Prefer A* in most cases. When you’re tempted to use Greedy Best First Search, consider using A* with an “inadmissible” heuristic.</li><li>If you want the optimal paths, Breadth First Search and Dijkstra’s Algorithm are guaranteed to find the shortest path given the input graph. Greedy Best First Search is not. A* is guaranteed to find the shortest path if the heuristic is never larger than the true distance. (As the heuristic becomes smaller, A* turns into Dijkstra’s Algorithm. As the heuristic becomes larger, A* turns into Greedy Best First Search.)</li></ul></li></ul><h2 id=advanced-data-structures>Advanced Data Structures<a hidden class=anchor aria-hidden=true href=#advanced-data-structures>#</a></h2><h3 id=red-black-trees><a href=http://algs4.cs.princeton.edu/33balanced/>Red-Black Trees</a><a hidden class=anchor aria-hidden=true href=#red-black-trees>#</a></h3><p>Red-black tree leads to a natural implementation of the insertion algorithm for <a href=/posts/stanford-cs106a/b-programming-intro-%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8%E8%AF%BE/#2-3-trees>2-3 trees</a></p><ul><li><p>RBT definition</p><ul><li>Red-black tree means encoding 2-3 trees in this way: red links, which bind together two 2-nodes to represent 3-nodes, and black links, which bind together the 2-3 tree.</li><li>An equivalent definition is to define red-black BSTs as BSTs having red and black links and satisfying the following three restrictions:<ul><li>Red links lean left.</li><li>No node has two red links connected to it.</li><li>The tree has perfect black balance : every path from the root to a null link has the same number of black links.</li></ul></li><li>A 1-1 correspondence: If we draw the red links horizontally in a red-black BST, all of the null links are the same distance from the root, and if we then collapse together the nodes connected by red links, the result is a 2-3 tree.
<img alt="A 1-1 correspondence" loading=lazy src=http://algs4.cs.princeton.edu/33balanced/images/redblack-1-1.png title=http://algs4.cs.princeton.edu/33balanced/images/redblack-1-1.png></li></ul></li><li><p>RBT implementaion</p><ul><li>Color representation:<ul><li>Each node is pointed to by precisely one link from its parent,</li><li>Encode the color of links in nodes, by adding a boolean instance variable color to our Node data type, which is true if the link from the parent is red and false if it is black. By convention, null links are black.</li><li>For clarity, define constants <code>RED</code> and <code>BLACK</code> for use in setting and testing this variable.</li></ul></li><li>Rotation
To correct right-leaning red links or two red links in a row conditions.<ul><li>takes a link to a red-black BST as argument and, assuming that link to be to a Node h whose right link is red, makes the necessary adjustments and returns a link to a node that is the root of a red-black BST for the same set of keys whose left link is red. Actually it is switching from having the smaller of the two keys at the root to having the larger of the two keys at the root.</li></ul></li><li>Flipping colors<ul><li>to split a 4-node</li><li>In addition to flipping the colors of the children from red to black, we also flip the color of the parent from black to red.</li></ul></li><li>Keeping the root black.</li><li>Insertion
Maintain the 1-1 correspondence between 2-3 trees and red-black BSTs during insertion by judicious use of three simple operations: left rotate, right rotate, and color flip.<ul><li>If the right child is red and the left child is black, rotate left.</li><li>If both the left child and its left child are red, rotate right.</li><li>If both children are red, flip colors.</li></ul></li><li>Deletion</li></ul></li></ul><hr><h3 id=assignments><a href=https://github.com/ShootingSpace/CS106B_assignments>Assignments</a><a hidden class=anchor aria-hidden=true href=#assignments>#</a></h3><ol start=0><li>Name Hash</li><li>Game of Life</li><li>Serafini</li><li>Recursion</li><li>Boggle!</li><li><a href=http://web.stanford.edu/class/cs106b/assn/patient-queue.html>Patient Queue</a></li><li><a href=http://web.stanford.edu/class/cs106b/assn/huffman.html>Huffman Encoding</a></li><li><a href=http://web.stanford.edu/class/cs106b/assn/trailblazer.html>Trailblazer</a></li></ol></div><footer class=post-footer><ul class=post-tags><li><a href=https://congchan.github.io/tags/software-engineer/>Software Engineer</a></li><li><a href=https://congchan.github.io/tags/c++/>C++</a></li><li><a href=https://congchan.github.io/tags/%E7%BC%96%E7%A8%8B/>编程</a></li><li><a href=https://congchan.github.io/tags/java/>Java</a></li></ul><nav class=paginav><a class=prev href=https://congchan.github.io/posts/algorithms-01-asymptotic-analysis-%E6%B8%90%E8%BF%9B%E5%88%86%E6%9E%90/><span class=title>« Prev</span><br><span>Algorithms 01 - Asymptotic Analysis 渐进分析</span>
</a><a class=next href=https://congchan.github.io/posts/java-hash-table/><span class=title>Next »</span><br><span>Java Hash Table</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Stanford CS106A/B Programming Intro 斯坦福大学编程入门课 on x" href="https://x.com/intent/tweet/?text=Stanford%20CS106A%2fB%20Programming%20Intro%20%e6%96%af%e5%9d%a6%e7%a6%8f%e5%a4%a7%e5%ad%a6%e7%bc%96%e7%a8%8b%e5%85%a5%e9%97%a8%e8%af%be&amp;url=https%3a%2f%2fcongchan.github.io%2fposts%2fstanford-cs106a%2fb-programming-intro-%25E6%2596%25AF%25E5%259D%25A6%25E7%25A6%258F%25E5%25A4%25A7%25E5%25AD%25A6%25E7%25BC%2596%25E7%25A8%258B%25E5%2585%25A5%25E9%2597%25A8%25E8%25AF%25BE%2f&amp;hashtags=SoftwareEngineer%2cC%2b%2b%2c%e7%bc%96%e7%a8%8b%2cJava"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Stanford CS106A/B Programming Intro 斯坦福大学编程入门课 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fcongchan.github.io%2fposts%2fstanford-cs106a%2fb-programming-intro-%25E6%2596%25AF%25E5%259D%25A6%25E7%25A6%258F%25E5%25A4%25A7%25E5%25AD%25A6%25E7%25BC%2596%25E7%25A8%258B%25E5%2585%25A5%25E9%2597%25A8%25E8%25AF%25BE%2f&amp;title=Stanford%20CS106A%2fB%20Programming%20Intro%20%e6%96%af%e5%9d%a6%e7%a6%8f%e5%a4%a7%e5%ad%a6%e7%bc%96%e7%a8%8b%e5%85%a5%e9%97%a8%e8%af%be&amp;summary=Stanford%20CS106A%2fB%20Programming%20Intro%20%e6%96%af%e5%9d%a6%e7%a6%8f%e5%a4%a7%e5%ad%a6%e7%bc%96%e7%a8%8b%e5%85%a5%e9%97%a8%e8%af%be&amp;source=https%3a%2f%2fcongchan.github.io%2fposts%2fstanford-cs106a%2fb-programming-intro-%25E6%2596%25AF%25E5%259D%25A6%25E7%25A6%258F%25E5%25A4%25A7%25E5%25AD%25A6%25E7%25BC%2596%25E7%25A8%258B%25E5%2585%25A5%25E9%2597%25A8%25E8%25AF%25BE%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Stanford CS106A/B Programming Intro 斯坦福大学编程入门课 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fcongchan.github.io%2fposts%2fstanford-cs106a%2fb-programming-intro-%25E6%2596%25AF%25E5%259D%25A6%25E7%25A6%258F%25E5%25A4%25A7%25E5%25AD%25A6%25E7%25BC%2596%25E7%25A8%258B%25E5%2585%25A5%25E9%2597%25A8%25E8%25AF%25BE%2f&title=Stanford%20CS106A%2fB%20Programming%20Intro%20%e6%96%af%e5%9d%a6%e7%a6%8f%e5%a4%a7%e5%ad%a6%e7%bc%96%e7%a8%8b%e5%85%a5%e9%97%a8%e8%af%be"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Stanford CS106A/B Programming Intro 斯坦福大学编程入门课 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fcongchan.github.io%2fposts%2fstanford-cs106a%2fb-programming-intro-%25E6%2596%25AF%25E5%259D%25A6%25E7%25A6%258F%25E5%25A4%25A7%25E5%25AD%25A6%25E7%25BC%2596%25E7%25A8%258B%25E5%2585%25A5%25E9%2597%25A8%25E8%25AF%25BE%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Stanford CS106A/B Programming Intro 斯坦福大学编程入门课 on whatsapp" href="https://api.whatsapp.com/send?text=Stanford%20CS106A%2fB%20Programming%20Intro%20%e6%96%af%e5%9d%a6%e7%a6%8f%e5%a4%a7%e5%ad%a6%e7%bc%96%e7%a8%8b%e5%85%a5%e9%97%a8%e8%af%be%20-%20https%3a%2f%2fcongchan.github.io%2fposts%2fstanford-cs106a%2fb-programming-intro-%25E6%2596%25AF%25E5%259D%25A6%25E7%25A6%258F%25E5%25A4%25A7%25E5%25AD%25A6%25E7%25BC%2596%25E7%25A8%258B%25E5%2585%25A5%25E9%2597%25A8%25E8%25AF%25BE%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Stanford CS106A/B Programming Intro 斯坦福大学编程入门课 on telegram" href="https://telegram.me/share/url?text=Stanford%20CS106A%2fB%20Programming%20Intro%20%e6%96%af%e5%9d%a6%e7%a6%8f%e5%a4%a7%e5%ad%a6%e7%bc%96%e7%a8%8b%e5%85%a5%e9%97%a8%e8%af%be&amp;url=https%3a%2f%2fcongchan.github.io%2fposts%2fstanford-cs106a%2fb-programming-intro-%25E6%2596%25AF%25E5%259D%25A6%25E7%25A6%258F%25E5%25A4%25A7%25E5%25AD%25A6%25E7%25BC%2596%25E7%25A8%258B%25E5%2585%25A5%25E9%2597%25A8%25E8%25AF%25BE%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Stanford CS106A/B Programming Intro 斯坦福大学编程入门课 on ycombinator" href="https://news.ycombinator.com/submitlink?t=Stanford%20CS106A%2fB%20Programming%20Intro%20%e6%96%af%e5%9d%a6%e7%a6%8f%e5%a4%a7%e5%ad%a6%e7%bc%96%e7%a8%8b%e5%85%a5%e9%97%a8%e8%af%be&u=https%3a%2f%2fcongchan.github.io%2fposts%2fstanford-cs106a%2fb-programming-intro-%25E6%2596%25AF%25E5%259D%25A6%25E7%25A6%258F%25E5%25A4%25A7%25E5%25AD%25A6%25E7%25BC%2596%25E7%25A8%258B%25E5%2585%25A5%25E9%2597%25A8%25E8%25AF%25BE%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://congchan.github.io/>Cong's Log</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>