<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Entity Linking | Cong's Log</title><meta name=keywords content="NLP,Entity Linking"><meta name=description content="Entity Linking
 

Knowledge Graph (知识图谱)：一种语义网络，旨在描述客观世界的概念实体及其之间的关系，有时也称为Knowledge Base (知识库)。

图谱由三元组构成：<实体1，关系，实体2> 或者 <实体，属性，属性值>；
例如：<姚明，plays-in，NBA>、<姚明，身高，2.29m>；
常见的KB有：Wikidata、DBpedia、YAGO。


Entity 实体：实体是知识图谱的基本单元，也是文本中承载信息的重要语言单位。
Mention 提及：自然文本中表达实体的语言片段。

应用方向

Question Answering：EL是KBQA的刚需，linking到实体之后才能查询图数据库；
Content Analysis：舆情分析、内容推荐、阅读增强；
Information Retrieval：基于语义实体的搜索引擎，google搜索一些实体，右侧会出现wikipedia页面；
Knowledge Base population：扩充知识库，更新实体和关系。

候选实体和消歧
Entity linking system consists of two components:

candidate entity generation：从mention出发，找到KB中所有可能的实体，组成候选实体集 (candidate entities)；
Entity Disambiguation：从candidate entities中，选择最可能的实体作为预测实体。

Entity Disambiguation (ED)
是最重要的部分

Features

Context-Independent Features：

LinkCount：#(m->e)，知识库中某个提及m指向实体e的次数；
Entity Attributes：Popularity、Type；


Context-Dependent Features：

Textual Context：BOW, Concept Vector
Coherence Between Entities：WLM、PMI、Jaccard Distance





Context-Independent Features
mention到实体的LinkCount、实体自身的一些属性（比如热度、类型等等）

LinkCount作为一个先验知识，在消歧时，往往很有用

Context-Dependent Features
全局地进行entities的消歧实际上是一个NP-hard的问题，因此核心问题是如何更加快速有效地利用一致性特征"><meta name=author content="Cong Chan"><link rel=canonical href=https://congchan.github.io/posts/entity-linking/><link crossorigin=anonymous href=/assets/css/stylesheet.1f908d890a7e84b56b73a7a0dc6591e6e3f782fcba048ce1eb46319195bedaef.css integrity="sha256-H5CNiQp+hLVrc6eg3GWR5uP3gvy6BIzh60YxkZW+2u8=" rel="preload stylesheet" as=style><link rel=icon href=https://congchan.github.io/favicons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://congchan.github.io/favicons/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://congchan.github.io/favicons/favicon-32x32.png><link rel=apple-touch-icon href=https://congchan.github.io/favicons/apple-touch-icon.png><link rel=mask-icon href=https://congchan.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://congchan.github.io/posts/entity-linking/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}]})'></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-6T0DPR6SMC"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-6T0DPR6SMC")}</script><meta property="og:url" content="https://congchan.github.io/posts/entity-linking/"><meta property="og:site_name" content="Cong's Log"><meta property="og:title" content="Entity Linking"><meta property="og:description" content="Entity Linking
Knowledge Graph (知识图谱)：一种语义网络，旨在描述客观世界的概念实体及其之间的关系，有时也称为Knowledge Base (知识库)。 图谱由三元组构成：<实体1，关系，实体2> 或者 <实体，属性，属性值>； 例如：<姚明，plays-in，NBA>、<姚明，身高，2.29m>； 常见的KB有：Wikidata、DBpedia、YAGO。 Entity 实体：实体是知识图谱的基本单元，也是文本中承载信息的重要语言单位。 Mention 提及：自然文本中表达实体的语言片段。 应用方向
Question Answering：EL是KBQA的刚需，linking到实体之后才能查询图数据库； Content Analysis：舆情分析、内容推荐、阅读增强； Information Retrieval：基于语义实体的搜索引擎，google搜索一些实体，右侧会出现wikipedia页面； Knowledge Base population：扩充知识库，更新实体和关系。 候选实体和消歧
Entity linking system consists of two components:
candidate entity generation：从mention出发，找到KB中所有可能的实体，组成候选实体集 (candidate entities)； Entity Disambiguation：从candidate entities中，选择最可能的实体作为预测实体。 Entity Disambiguation (ED) 是最重要的部分
Features Context-Independent Features： LinkCount：#(m->e)，知识库中某个提及m指向实体e的次数； Entity Attributes：Popularity、Type； Context-Dependent Features： Textual Context：BOW, Concept Vector Coherence Between Entities：WLM、PMI、Jaccard Distance Context-Independent Features mention到实体的LinkCount、实体自身的一些属性（比如热度、类型等等）
LinkCount作为一个先验知识，在消歧时，往往很有用 Context-Dependent Features 全局地进行entities的消歧实际上是一个NP-hard的问题，因此核心问题是如何更加快速有效地利用一致性特征"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-01-02T00:00:00+00:00"><meta property="article:modified_time" content="2020-01-02T00:00:00+00:00"><meta property="article:tag" content="NLP"><meta property="article:tag" content="Entity Linking"><meta name=twitter:card content="summary"><meta name=twitter:title content="Entity Linking"><meta name=twitter:description content="Entity Linking
 

Knowledge Graph (知识图谱)：一种语义网络，旨在描述客观世界的概念实体及其之间的关系，有时也称为Knowledge Base (知识库)。

图谱由三元组构成：<实体1，关系，实体2> 或者 <实体，属性，属性值>；
例如：<姚明，plays-in，NBA>、<姚明，身高，2.29m>；
常见的KB有：Wikidata、DBpedia、YAGO。


Entity 实体：实体是知识图谱的基本单元，也是文本中承载信息的重要语言单位。
Mention 提及：自然文本中表达实体的语言片段。

应用方向

Question Answering：EL是KBQA的刚需，linking到实体之后才能查询图数据库；
Content Analysis：舆情分析、内容推荐、阅读增强；
Information Retrieval：基于语义实体的搜索引擎，google搜索一些实体，右侧会出现wikipedia页面；
Knowledge Base population：扩充知识库，更新实体和关系。

候选实体和消歧
Entity linking system consists of two components:

candidate entity generation：从mention出发，找到KB中所有可能的实体，组成候选实体集 (candidate entities)；
Entity Disambiguation：从candidate entities中，选择最可能的实体作为预测实体。

Entity Disambiguation (ED)
是最重要的部分

Features

Context-Independent Features：

LinkCount：#(m->e)，知识库中某个提及m指向实体e的次数；
Entity Attributes：Popularity、Type；


Context-Dependent Features：

Textual Context：BOW, Concept Vector
Coherence Between Entities：WLM、PMI、Jaccard Distance





Context-Independent Features
mention到实体的LinkCount、实体自身的一些属性（比如热度、类型等等）

LinkCount作为一个先验知识，在消歧时，往往很有用

Context-Dependent Features
全局地进行entities的消歧实际上是一个NP-hard的问题，因此核心问题是如何更加快速有效地利用一致性特征"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://congchan.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Entity Linking","item":"https://congchan.github.io/posts/entity-linking/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Entity Linking","name":"Entity Linking","description":"Entity Linking\nKnowledge Graph (知识图谱)：一种语义网络，旨在描述客观世界的概念实体及其之间的关系，有时也称为Knowledge Base (知识库)。 图谱由三元组构成：\u0026lt;实体1，关系，实体2\u0026gt; 或者 \u0026lt;实体，属性，属性值\u0026gt;； 例如：\u0026lt;姚明，plays-in，NBA\u0026gt;、\u0026lt;姚明，身高，2.29m\u0026gt;； 常见的KB有：Wikidata、DBpedia、YAGO。 Entity 实体：实体是知识图谱的基本单元，也是文本中承载信息的重要语言单位。 Mention 提及：自然文本中表达实体的语言片段。 应用方向\nQuestion Answering：EL是KBQA的刚需，linking到实体之后才能查询图数据库； Content Analysis：舆情分析、内容推荐、阅读增强； Information Retrieval：基于语义实体的搜索引擎，google搜索一些实体，右侧会出现wikipedia页面； Knowledge Base population：扩充知识库，更新实体和关系。 候选实体和消歧\nEntity linking system consists of two components:\ncandidate entity generation：从mention出发，找到KB中所有可能的实体，组成候选实体集 (candidate entities)； Entity Disambiguation：从candidate entities中，选择最可能的实体作为预测实体。 Entity Disambiguation (ED) 是最重要的部分\nFeatures Context-Independent Features： LinkCount：#(m-\u0026gt;e)，知识库中某个提及m指向实体e的次数； Entity Attributes：Popularity、Type； Context-Dependent Features： Textual Context：BOW, Concept Vector Coherence Between Entities：WLM、PMI、Jaccard Distance Context-Independent Features mention到实体的LinkCount、实体自身的一些属性（比如热度、类型等等）\nLinkCount作为一个先验知识，在消歧时，往往很有用 Context-Dependent Features 全局地进行entities的消歧实际上是一个NP-hard的问题，因此核心问题是如何更加快速有效地利用一致性特征\n","keywords":["NLP","Entity Linking"],"articleBody":"Entity Linking\nKnowledge Graph (知识图谱)：一种语义网络，旨在描述客观世界的概念实体及其之间的关系，有时也称为Knowledge Base (知识库)。 图谱由三元组构成：\u003c实体1，关系，实体2\u003e 或者 \u003c实体，属性，属性值\u003e； 例如：\u003c姚明，plays-in，NBA\u003e、\u003c姚明，身高，2.29m\u003e； 常见的KB有：Wikidata、DBpedia、YAGO。 Entity 实体：实体是知识图谱的基本单元，也是文本中承载信息的重要语言单位。 Mention 提及：自然文本中表达实体的语言片段。 应用方向\nQuestion Answering：EL是KBQA的刚需，linking到实体之后才能查询图数据库； Content Analysis：舆情分析、内容推荐、阅读增强； Information Retrieval：基于语义实体的搜索引擎，google搜索一些实体，右侧会出现wikipedia页面； Knowledge Base population：扩充知识库，更新实体和关系。 候选实体和消歧\nEntity linking system consists of two components:\ncandidate entity generation：从mention出发，找到KB中所有可能的实体，组成候选实体集 (candidate entities)； Entity Disambiguation：从candidate entities中，选择最可能的实体作为预测实体。 Entity Disambiguation (ED) 是最重要的部分\nFeatures Context-Independent Features： LinkCount：#(m-\u003ee)，知识库中某个提及m指向实体e的次数； Entity Attributes：Popularity、Type； Context-Dependent Features： Textual Context：BOW, Concept Vector Coherence Between Entities：WLM、PMI、Jaccard Distance Context-Independent Features mention到实体的LinkCount、实体自身的一些属性（比如热度、类型等等）\nLinkCount作为一个先验知识，在消歧时，往往很有用 Context-Dependent Features 全局地进行entities的消歧实际上是一个NP-hard的问题，因此核心问题是如何更加快速有效地利用一致性特征\nLearning to Rank Methods：Point-wise、Pair-wise、List-wise。由于ED任务ground truth只有一个实体，一般都是用point-wise来做。输入是文本的context、mention、某个entity的一些attributes，输出mention指向该entity的置信度，以此rank，选出最可信的entity； Probabilistic Methods：Incorporate heterogeneous knowledge into a probabilistic model。结合不同信息，得到条件概率 $P(e|m,c)$，其中 c 是输入文本，e 为实体， m 是mention。比如用归一化的LinkCount信息，作为先验概率 $P(e|m)$ ； Graph-Based Approaches：maximize coherene between entities。利用图特征 (entity embedding、relation)，在消歧时，考虑全局消歧后实体的一致性； Deep Type Discovering Types for Entity Disambiguation\nHigh-level overview Our system uses the following steps:\nExtract every Wikipedia-internal link to determine, for each word, the set of conceivable entities it can refer to. For example, when encountering the link [jaguar](https://en.wikipedia.org/wiki/Jaguar) in a Wikipedia page, we conclude that https://en.wikipedia.org/wiki/Jaguar is one of the meanings of jaguar.\nWalk the Wikipedia category tree (using the Wikidata knowledge graph) to determine, for each entity, the set of categories it belongs to. For example, at the bottom of https://en.wikipedia.org/wiki/Jaguar_Cars’s Wikipedia page, are the following categories (which themselves have their own categories, such as Automobiles):\nPick a list of ~100 categories to be your “type” system, and optimize over this choice of categories so that they compactly express any entity. We know the mapping of entities to categories, so given a type system, we can represent each entity as a ~100-dimensional binary vector indicating membership in each category.\nUsing every Wikipedia-internal link and its surrounding context, produce training data mapping a word plus context to the ~100-dimensional binary representation of the corresponding entity, and train a neural network to predict this mapping. This chains together the previous steps: Wikipedia links map a word to an entity, we know the categories for each entity from step 2, and step 3 picked the categories in our type system.\nAt test time, given a word and surrounding context, our neural network’s output can be interpreted as the probability that the word belongs to each category. If we knew the exact set of category memberships, we would narrow down to one entity (assuming well-chosen categories). But instead, we must play a probabilistic 20 questions: use Bayes’ theorem to calculate the chance of the word disambiguating to each of its possible entities.\nUnlinkable Mention Prediction 拒识掉未知实体 NIL Threshold：通过一个置信度的阈值来卡一下； Binary Classification：训练一个二分类的模型，判断Top-rankeded Entity是否真的是文中的mention想要表达的实体； Rank with NIL：在rank的时候，在候选实体中加入NIL Entity。 一般就阈值卡一下就好了，不是太大的问题。但如果具体的场景是做KB Population且实体还不是很全的时候，就需要重点关注一下了。\nCandidate Entity Generation (CEG) CEG的方法都比较朴素\n最重要的方法：Name Dictionary ( {mention: entity} ) 哪些别名：首字母缩写、模糊匹配、昵称、拼写错误等。 构建方法： Wikipedia（Redirect pages, Disambiguation pages, Hyperlinks）； 基于搜索引擎：调google api，搜mention。若前m个有wiki entity，建立map； Heuristic Methods； 人工标注、用户日志。 对于每一个entity，紧凑而充分地配置别名，才能保证生成的candidate entites没有遗漏掉ground truth entity。\n具体的，要配置哪些别名，要用什么构建方法，往往取决于EL的使用场景。比如做百科问答或是通用文本的阅读增强，就很依赖于wikipedia和搜索引擎；但如果是某个具体的行业领域，就需要通过一些启发式的方法、用户日志、网页爬取，甚至人工标注的方法来构建Name Dictionary。\nReference 【知识图谱】实体链接：一份\"由浅入深\"的综述 Discovering Types for Entity Disambiguation ","wordCount":"440","inLanguage":"en","datePublished":"2020-01-02T00:00:00Z","dateModified":"2020-01-02T00:00:00Z","author":{"@type":"Person","name":"Cong Chan"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://congchan.github.io/posts/entity-linking/"},"publisher":{"@type":"Organization","name":"Cong's Log","logo":{"@type":"ImageObject","url":"https://congchan.github.io/favicons/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://congchan.github.io/ accesskey=h title="Cong's Log (Alt + H)">Cong's Log</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://congchan.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://congchan.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://congchan.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://congchan.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://congchan.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Entity Linking</h1><div class=post-meta><span title='2020-01-02 00:00:00 +0000 UTC'>2020-01-02</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;Cong Chan&nbsp;|&nbsp;<a href=https://github.com/%3cgitlab%20user%3e/%3crepo%20name%3e/tree/%3cbranch%20name%3e/%3cpath%20to%20content%3e//posts/entity-linking.md rel="noopener noreferrer edit" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#entity-disambiguation-ed aria-label="Entity Disambiguation (ED)">Entity Disambiguation (ED)</a><ul><li><a href=#context-independent-features aria-label="Context-Independent Features">Context-Independent Features</a></li><li><a href=#context-dependent-features aria-label="Context-Dependent Features">Context-Dependent Features</a><ul><li><a href=#deep-type aria-label="Deep Type">Deep Type</a></li></ul></li><li><a href=#high-level-overview aria-label="High-level overview">High-level overview</a></li><li><a href=#unlinkable-mention-prediction-%e6%8b%92%e8%af%86%e6%8e%89%e6%9c%aa%e7%9f%a5%e5%ae%9e%e4%bd%93 aria-label="Unlinkable Mention Prediction 拒识掉未知实体">Unlinkable Mention Prediction 拒识掉未知实体</a></li><li><a href=#candidate-entity-generation-ceg aria-label="Candidate Entity Generation (CEG)">Candidate Entity Generation (CEG)</a></li></ul></li><li><a href=#reference aria-label=Reference>Reference</a></li></ul></div></details></div><div class=post-content><p>Entity Linking</p><ul><li>Knowledge Graph (知识图谱)：一种语义网络，旨在描述客观世界的概念实体及其之间的关系，有时也称为Knowledge Base (知识库)。<ul><li>图谱由三元组构成：<code>&lt;实体1，关系，实体2></code> 或者 <code>&lt;实体，属性，属性值></code>；</li><li>例如：<code>&lt;姚明，plays-in，NBA></code>、<code>&lt;姚明，身高，2.29m></code>；</li><li>常见的KB有：Wikidata、DBpedia、YAGO。</li></ul></li><li>Entity 实体：实体是知识图谱的基本单元，也是文本中承载信息的重要语言单位。</li><li>Mention 提及：自然文本中表达实体的语言片段。</li></ul><p>应用方向</p><ol><li><strong>Question Answering</strong>：EL是KBQA的刚需，linking到实体之后才能查询图数据库；</li><li><strong>Content Analysis</strong>：舆情分析、内容推荐、阅读增强；</li><li><strong>Information Retrieval</strong>：基于语义实体的搜索引擎，google搜索一些实体，右侧会出现wikipedia页面；</li><li><strong>Knowledge Base population</strong>：扩充知识库，更新实体和关系。</li></ol><p>候选实体和消歧</p><p>Entity linking system consists of two components:</p><ol><li>candidate entity generation：从mention出发，找到KB中所有可能的实体，组成候选实体集 (candidate entities)；</li><li>Entity Disambiguation：从candidate entities中，选择最可能的实体作为预测实体。</li></ol><h1 id=entity-disambiguation-ed>Entity Disambiguation (ED)<a hidden class=anchor aria-hidden=true href=#entity-disambiguation-ed>#</a></h1><p>是最重要的部分</p><ul><li>Features<ul><li>Context-Independent Features：<ul><li>LinkCount：#(m->e)，知识库中某个提及m指向实体e的次数；</li><li>Entity Attributes：Popularity、Type；</li></ul></li><li>Context-Dependent Features：<ul><li>Textual Context：BOW, Concept Vector</li><li>Coherence Between Entities：WLM、PMI、Jaccard Distance</li></ul></li></ul></li></ul><h2 id=context-independent-features>Context-Independent Features<a hidden class=anchor aria-hidden=true href=#context-independent-features>#</a></h2><p>mention到实体的LinkCount、实体自身的一些属性（比如热度、类型等等）</p><ul><li>LinkCount作为一个先验知识，在消歧时，往往很有用</li></ul><h2 id=context-dependent-features>Context-Dependent Features<a hidden class=anchor aria-hidden=true href=#context-dependent-features>#</a></h2><p>全局地进行entities的消歧实际上是一个NP-hard的问题，因此核心问题是如何更加快速有效地利用一致性特征</p><ul><li><strong>Learning to Rank Methods</strong>：Point-wise、Pair-wise、List-wise。由于ED任务ground truth只有一个实体，一般都是用<strong>point-wise</strong>来做。输入是文本的context、mention、某个entity的一些attributes，输出mention指向该entity的置信度，以此rank，选出最可信的entity；</li><li><strong>Probabilistic Methods</strong>：Incorporate heterogeneous knowledge into a probabilistic model。结合不同信息，得到条件概率  $P(e|m,c)$，其中 c 是输入文本，e 为实体， m 是mention。比如用归一化的LinkCount信息，作为先验概率 $P(e|m)$ ；</li><li><strong>Graph-Based Approaches</strong>：maximize coherene between entities。利用图特征 (entity embedding、relation)，在消歧时，考虑全局消歧后实体的一致性；</li></ul><h3 id=deep-type>Deep Type<a hidden class=anchor aria-hidden=true href=#deep-type>#</a></h3><p><a href=https://openai.com/blog/discovering-types-for-entity-disambiguation/>Discovering Types for Entity Disambiguation</a></p><h2 id=high-level-overview><strong>High-level overview</strong><a hidden class=anchor aria-hidden=true href=#high-level-overview>#</a></h2><p>Our system uses the following steps:</p><ol><li><p><strong>Extract every Wikipedia-internal link to determine, for each word, the set of conceivable entities it can refer to.</strong> For example, when encountering the link <code>[jaguar](https://en.wikipedia.org/wiki/Jaguar)</code> in a Wikipedia page, we conclude that <code>https://en.wikipedia.org/wiki/Jaguar</code> is one of the meanings of <code>jaguar</code>.</p></li><li><p><strong>Walk the Wikipedia category tree (using the <a href=https://www.wikidata.org/wiki/Wikidata:Introduction>Wikidata</a> knowledge graph) to determine, for each entity, the set of categories it belongs to.</strong> For example, at the bottom of <code>https://en.wikipedia.org/wiki/Jaguar_Cars</code>’s Wikipedia page, are the following categories (which themselves have their own categories, such as <a href=https://en.wikipedia.org/wiki/Category:Automobiles>Automobiles</a>):</p><p><img alt=https://openai.com/content/images/2018/02/jaguar.png loading=lazy src=https://openai.com/content/images/2018/02/jaguar.png></p></li><li><p><strong>Pick a list of ~100 categories to be your “type” system, and optimize over this choice of categories so that they compactly express any entity.</strong> We know the mapping of entities to categories, so given a type system, we can represent each entity as a ~100-dimensional binary vector indicating membership in each category.</p></li><li><p><strong>Using every Wikipedia-internal link and its surrounding context, produce training data mapping a word plus context to the ~100-dimensional binary representation of the corresponding entity, and train a neural network to predict this mapping.</strong> This chains together the previous steps: Wikipedia links map a word to an entity, we know the categories for each entity from step 2, and step 3 picked the categories in our type system.</p></li><li><p><strong>At test time, given a word and surrounding context, our neural network’s output can be interpreted as the probability that the word belongs to each category.</strong> If we knew the exact set of category memberships, we would narrow down to one entity (assuming well-chosen categories). But instead, we must play a probabilistic 20 questions: use <a href=https://en.wikipedia.org/wiki/Bayes%27_theorem>Bayes’ theorem</a> to calculate the chance of the word disambiguating to each of its possible entities.</p></li></ol><h2 id=unlinkable-mention-prediction-拒识掉未知实体>Unlinkable Mention Prediction 拒识掉未知实体<a hidden class=anchor aria-hidden=true href=#unlinkable-mention-prediction-拒识掉未知实体>#</a></h2><ul><li><strong>NIL Threshold</strong>：通过一个置信度的阈值来卡一下；</li><li><strong>Binary Classification</strong>：训练一个二分类的模型，判断Top-rankeded Entity是否真的是文中的mention想要表达的实体；</li><li><strong>Rank with NIL</strong>：在rank的时候，在候选实体中加入NIL Entity。</li></ul><p>一般就阈值卡一下就好了，不是太大的问题。但如果具体的场景是做KB Population且实体还不是很全的时候，就需要重点关注一下了。</p><h2 id=candidate-entity-generation-ceg><strong>Candidate Entity Generation (CEG)</strong><a hidden class=anchor aria-hidden=true href=#candidate-entity-generation-ceg>#</a></h2><p>CEG的方法都比较朴素</p><ul><li>最重要的方法：Name Dictionary ( <code>{mention: entity}</code> )</li><li>哪些别名：首字母缩写、模糊匹配、昵称、拼写错误等。</li><li>构建方法：<ul><li>Wikipedia（Redirect pages, Disambiguation pages, Hyperlinks）；</li><li>基于搜索引擎：调google api，搜mention。若前m个有wiki entity，建立map；</li><li>Heuristic Methods；</li><li>人工标注、用户日志。</li></ul></li></ul><p>对于每一个entity，紧凑而充分地配置别名，才能保证生成的candidate entites没有遗漏掉ground truth entity。</p><p>具体的，要配置哪些别名，要用什么构建方法，往往取决于EL的使用场景。比如做百科问答或是通用文本的阅读增强，就很依赖于<strong>wikipedia和搜索引擎</strong>；但如果是某个具体的行业领域，就需要通过一些<strong>启发式的方法、用户日志、网页爬取，甚至人工标注的方法</strong>来构建Name Dictionary。</p><h1 id=reference>Reference<a hidden class=anchor aria-hidden=true href=#reference>#</a></h1><ul><li><a href=https://zhuanlan.zhihu.com/p/100248426>【知识图谱】实体链接：一份"由浅入深"的综述</a></li><li><a href=https://openai.com/blog/discovering-types-for-entity-disambiguation/>Discovering Types for Entity Disambiguation</a></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://congchan.github.io/tags/nlp/>NLP</a></li><li><a href=https://congchan.github.io/tags/entity-linking/>Entity Linking</a></li></ul><nav class=paginav><a class=prev href=https://congchan.github.io/posts/a-lite-bertalbert-%E5%8E%9F%E7%90%86%E5%92%8C%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/><span class=title>« Prev</span><br><span>A Lite BERT(AlBERT) 原理和源码解析</span>
</a><a class=next href=https://congchan.github.io/posts/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E8%A1%A5%E5%85%A8/><span class=title>Next »</span><br><span>知识图谱补全</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Entity Linking on x" href="https://x.com/intent/tweet/?text=Entity%20Linking&amp;url=https%3a%2f%2fcongchan.github.io%2fposts%2fentity-linking%2f&amp;hashtags=NLP%2cEntityLinking"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Entity Linking on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fcongchan.github.io%2fposts%2fentity-linking%2f&amp;title=Entity%20Linking&amp;summary=Entity%20Linking&amp;source=https%3a%2f%2fcongchan.github.io%2fposts%2fentity-linking%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Entity Linking on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fcongchan.github.io%2fposts%2fentity-linking%2f&title=Entity%20Linking"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Entity Linking on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fcongchan.github.io%2fposts%2fentity-linking%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Entity Linking on whatsapp" href="https://api.whatsapp.com/send?text=Entity%20Linking%20-%20https%3a%2f%2fcongchan.github.io%2fposts%2fentity-linking%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Entity Linking on telegram" href="https://telegram.me/share/url?text=Entity%20Linking&amp;url=https%3a%2f%2fcongchan.github.io%2fposts%2fentity-linking%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Entity Linking on ycombinator" href="https://news.ycombinator.com/submitlink?t=Entity%20Linking&u=https%3a%2f%2fcongchan.github.io%2fposts%2fentity-linking%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://congchan.github.io/>Cong's Log</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>