<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>2022 on Cong&#39;s Log</title>
    <link>https://congchan.github.io/tags/2022/</link>
    <description>Recent content in 2022 on Cong&#39;s Log</description>
    <generator>Hugo -- 0.147.9</generator>
    <language>en</language>
    <lastBuildDate>Sun, 13 Nov 2022 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://congchan.github.io/tags/2022/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>CoT on BBH - Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them</title>
      <link>https://congchan.github.io/posts/cot-on-bbh-challenging-big-bench-tasks-and-whether-chain-of-thought-can-solve-them/</link>
      <pubDate>Sun, 13 Nov 2022 00:00:00 +0000</pubDate>
      <guid>https://congchan.github.io/posts/cot-on-bbh-challenging-big-bench-tasks-and-whether-chain-of-thought-can-solve-them/</guid>
      <description>&lt;p&gt;CoT on BBH：M. Suzgun et al., ‘Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them’. arXiv, Oct. 17, 2022. Available: &lt;a href=&#34;http://arxiv.org/abs/2210.09261&#34;&gt;http://arxiv.org/abs/2210.09261&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;method&#34;&gt;Method&lt;/h1&gt;
&lt;p&gt;Applying chain-of-thought (CoT) prompting to BIG-Bench Hard tasks&lt;/p&gt;
&lt;p&gt;Evaluate few-shot performance via standard “answer-only” prompting and &lt;strong&gt;chain-of-thought prompting&lt;/strong&gt; on BIG-Bench Hard Benchmark&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://congchan.github.io/images/papers/paper17.png&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;resultsanalysisfindings&#34;&gt;Results/Analysis/Findings&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Benchmark: &lt;strong&gt;BIG-Bench Hard (BBH)&lt;/strong&gt;. These are the task for which prior language model evaluations did not outperform the average human-rater. many tasks in BBH require multi-step reasoning&lt;/p&gt;</description>
    </item>
    <item>
      <title>Efficient Training of Language Models to Fill in the Middle</title>
      <link>https://congchan.github.io/posts/efficient-training-of-language-models-to-fill-in-the-middle/</link>
      <pubDate>Fri, 11 Nov 2022 00:00:00 +0000</pubDate>
      <guid>https://congchan.github.io/posts/efficient-training-of-language-models-to-fill-in-the-middle/</guid>
      <description>&lt;p&gt;Bavarian, Mohammad, et al. Efficient Training of Language Models to Fill in the Middle. arXiv:2207.14255, arXiv, 28 July 2022. arXiv.org, &lt;a href=&#34;http://arxiv.org/abs/2207.14255&#34;&gt;http://arxiv.org/abs/2207.14255&lt;/a&gt;.
data: &lt;a href=&#34;https://www.github.com/openai/human-eval-infilling&#34;&gt;https://www.github.com/openai/human-eval-infilling&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;tldr&#34;&gt;TL:DR&lt;/h1&gt;
&lt;p&gt;Autoregressive language models can effectively learn to infill text by moving a span of text from the middle of a document to its end, without harming the original generative capability. The training models with this technique, called fill-in-the-middle (FIM), is useful, simple, and efficient, and should be used by default in future autoregressive language models. The study provides best practices and strong default settings for training FIM models and releases infilling benchmarks to aid future research.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
