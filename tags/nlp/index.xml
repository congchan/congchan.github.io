<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>NLP on Cong&#39;s Log</title>
    <link>https://congchan.github.io/tags/nlp/</link>
    <description>Recent content in NLP on Cong&#39;s Log</description>
    <generator>Hugo -- 0.147.9</generator>
    <language>en</language>
    <lastBuildDate>Sat, 10 Jul 2021 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://congchan.github.io/tags/nlp/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Switch Transformers - Scaling to Trillion Parameter Models with Simple and Efficient Sparsity</title>
      <link>https://congchan.github.io/posts/switch-transformers-scaling-to-trillion-parameter-models-with-simple-and-efficient-sparsity/</link>
      <pubDate>Sat, 10 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://congchan.github.io/posts/switch-transformers-scaling-to-trillion-parameter-models-with-simple-and-efficient-sparsity/</guid>
      <description>&lt;p&gt;Links: &lt;a href=&#34;https://arxiv.org/abs/2101.03961&#34;&gt;https://arxiv.org/abs/2101.03961&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“SWITCH TRANSFORMERS: SCALING TO TRILLION PARAMETER MODELS WITH SIMPLE AND EFFICIENT SPARSITY”，提出了一种可以扩展到万亿参数的网络，有两个比较大的创新，基于Transformer MoE网络结构，简化了MoE的routing机制，降低了计算量；进一步通过数据并行+模型并行+expert并行的方式降低了训练通信量，提升训练性能。&lt;/p&gt;
&lt;!-- more --&gt;
&lt;h1 id=&#34;模型&#34;&gt;模型&lt;/h1&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://congchan.github.io/images/papers/paper12.png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;simplifying-sparse-routing&#34;&gt;Simplifying Sparse Routing&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Mixture of Expert Routing&lt;/strong&gt; which takes as an input a token representation x and then routes this to the best deter- mined top-k experts&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Switch Routing&lt;/strong&gt;: route to only a single expert, this simplification preserves model quality, reduces routing computation and performs better.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://congchan.github.io/images/papers/paper12-1.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Sparse routing通过参数Wr计算出一个在N个experts上的softmax分布，对每个token输入筛选概率最高的 top k 个 experts，对应的是MOE中的门控机制。这样对算力的需求并没有随着参数量的增加而大幅增长，使得这个模型更加容易训练。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mixture of Experts (MOE)</title>
      <link>https://congchan.github.io/posts/mixture-of-experts-moe/</link>
      <pubDate>Sat, 03 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://congchan.github.io/posts/mixture-of-experts-moe/</guid>
      <description>&lt;h1 id=&#34;mixture-of-experts-moe&#34;&gt;Mixture of Experts (MOE)&lt;/h1&gt;
&lt;p&gt;MOE属于Ensemble Method中的一个方法, 采用分治思想：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将复杂的建模任务分解为多个相对简单的子任务，为每个子任务训练专门的模型：涉及子任务分解，或者Clustering&lt;/li&gt;
&lt;li&gt;需要一个门控模型，基于数据输入选择如何组合多个专家模型的结果&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- more --&gt;
&lt;blockquote&gt;
&lt;p&gt;Mixture of experts aims at increasing the accuracy of a function approximation by replacing a single global model by a weighted sum of local models (experts). It is based on a partition of the problem domain into several subdomains via clustering algorithms followed by a local expert training on each subdomain.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt=&#34;Page 94, Ensemble Methods, 2012.&#34; loading=&#34;lazy&#34; src=&#34;https://congchan.github.io/images/moe.png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;local-models--global-models&#34;&gt;Local Models &amp;amp; Global Models&lt;/h2&gt;
&lt;p&gt;Hinton的课件介绍了模型拟合分布的两个极端方式:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Survey - Pre-Trained Models - Past, Present and Future</title>
      <link>https://congchan.github.io/posts/survey-pre-trained-models-past-present-and-future/</link>
      <pubDate>Sat, 19 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://congchan.github.io/posts/survey-pre-trained-models-past-present-and-future/</guid>
      <description>&lt;p&gt;Links: &lt;a href=&#34;https://arxiv.org/abs/2106.07139&#34;&gt;https://arxiv.org/abs/2106.07139&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;最新出炉的 Pre-Trained Models 综述速览。&lt;/p&gt;
&lt;!-- more --&gt;
&lt;p&gt;先确定综述中的一些名词的定义&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Transfer learning：迁移学习，一种用于应对机器学习中的data hungry问题的方法，是有监督的&lt;/li&gt;
&lt;li&gt;Self-Supervised Learning：自监督学习，也用于应对机器学习中的data hungry问题，特别是针对完全没有标注的数据，可以通过某种方式以数据自身为标签进行学习（比如language modeling）。所以和无监督学习有异曲同工之处。
&lt;ul&gt;
&lt;li&gt;一般我们说无监督主要集中于clustering, community discovery, and anomaly detection等模式识别问题&lt;/li&gt;
&lt;li&gt;而self-supervised learning还是在监督学习的范畴，集中于classification and generation等问题&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Pre-trained models (PTMs) ：预训练模型，Pre-training是一种具体的训练方案，可以采用transfer learning或者Self-Supervised Learning方法&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;2-background-脉络图谱&#34;&gt;2 Background 脉络图谱&lt;/h1&gt;
&lt;p&gt;Pre-training 可分为两大类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2.1 &lt;strong&gt;Transfer Learning&lt;/strong&gt; and &lt;strong&gt;Supervised&lt;/strong&gt; Pre-Training
&lt;ul&gt;
&lt;li&gt;此类可进一步细分为 feature transfer 和 parameter transfer.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2.2 &lt;strong&gt;Self-Supervised Learning&lt;/strong&gt; and Self-Supervised Pre-Training&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://congchan.github.io/images/papers/paper11.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Transfer learning 可细分为四个子类&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;inductive transfer learning (Lawrence and Platt, 2004; Mihalkova et al., 2007; Evgeniou and Pontil, 2007),&lt;/li&gt;
&lt;li&gt;transductive transfer learning (Shimodaira, 2000; Zadrozny,2004; Daume III and Marcu, 2006),&lt;/li&gt;
&lt;li&gt;self-taught learning (Raina et al., 2007; Dai et al., 2008)&lt;/li&gt;
&lt;li&gt;unsupervised transfer learning (Wang et al., 2008).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;inductive transfer learning 和 transductive transfer learning 的研究进展主要集中以imageNet为labeled source data资源的图像领域&lt;/p&gt;</description>
    </item>
    <item>
      <title>CorefQA - Coreference resolution as query-based span prediction</title>
      <link>https://congchan.github.io/posts/corefqa-coreference-resolution-as-query-based-span-prediction/</link>
      <pubDate>Tue, 11 May 2021 00:00:00 +0000</pubDate>
      <guid>https://congchan.github.io/posts/corefqa-coreference-resolution-as-query-based-span-prediction/</guid>
      <description>&lt;p&gt;2020, ACL&lt;/p&gt;
&lt;p&gt;data: CoNLL-2012, GAP&lt;/p&gt;
&lt;p&gt;task: Coreference Resolution&lt;/p&gt;
&lt;!-- more --&gt;
&lt;p&gt;通过QA方式处理coreference问题，A query is generated for each candidate mention using its surrounding con- text, and a span prediction module is em- ployed to extract the text spans of the corefer- ences within the document using the generated query.&lt;/p&gt;
&lt;p&gt;近期的方法有consider all text spans in a document as potential mentions and learn to find an antecedent for each possible mention. There。这种仅依靠mention的做对比的方法的缺点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;At the task formalization level： 因为当前数据集有很多遗漏的mention， mentions left out at the mention proposal stage can never be recov- ered since the downstream module only operates on the proposed mentions.&lt;/li&gt;
&lt;li&gt;At the algorithm level：Semantic matching operations be- tween two mentions (and their contexts) are per- formed only at the output layer and are relatively superficial&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;方法&#34;&gt;方法&lt;/h1&gt;
&lt;p&gt;Speaker information： directly concatenates the speaker’s name with the corresponding utterance.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Early Rumour Detection</title>
      <link>https://congchan.github.io/posts/early-rumour-detection/</link>
      <pubDate>Sat, 01 May 2021 00:00:00 +0000</pubDate>
      <guid>https://congchan.github.io/posts/early-rumour-detection/</guid>
      <description>&lt;p&gt;2019, ACL&lt;/p&gt;
&lt;p&gt;data: TWITTER, WEIBO&lt;/p&gt;
&lt;p&gt;links: &lt;a href=&#34;https://www.aclweb.org/anthology/N19-1163&#34;&gt;https://www.aclweb.org/anthology/N19-1163&lt;/a&gt;, &lt;a href=&#34;https://github.com/DeepBrainAI/ERD&#34;&gt;https://github.com/DeepBrainAI/ERD&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;task: Rumour Detection&lt;/p&gt;
&lt;p&gt;这篇文章采用GRU编码社交媒体posts stream，作为环境的状态表示；训练一个分类器以GRU的状态输出为输入，对文本做二分类判断是否是rumor。用DQN训练agent，根据状态做出是否启动rumor分类器进行判断，并根据分类结果对错给予奖惩。目标就是尽可能准尽可能早地预测出社交媒体posts是否是rumor。&lt;/p&gt;
&lt;!-- more --&gt;
&lt;p&gt;Focuses on the task of rumour detection; particularly, we are in- terested in understanding &lt;strong&gt;how early&lt;/strong&gt; we can detect them.&lt;/p&gt;
&lt;p&gt;Our model treats social media posts (e.g. tweets) as a data stream and integrates reinforcement learning to learn the number minimum num- ber of posts required before we classify an event as a rumour.&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://congchan.github.io/images/papers/paper8.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Let $E$ denote an event, and it consists of a series of relevant posts $x_i$, where $x_0$ denotes the source message and $x_T$ the last relevant message. The objective of early rumor detection is to &lt;strong&gt;make a classification decision&lt;/strong&gt; &lt;strong&gt;whether E is a rumour as early as possible&lt;/strong&gt; while keeping an acceptable detection accuracy.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Matching the Blanks - Distributional Similarity for Relation Learning</title>
      <link>https://congchan.github.io/posts/matching-the-blanks-distributional-similarity-for-relation-learning/</link>
      <pubDate>Wed, 21 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://congchan.github.io/posts/matching-the-blanks-distributional-similarity-for-relation-learning/</guid>
      <description>&lt;p&gt;2019, ACL&lt;/p&gt;
&lt;p&gt;data: KBP37, SemEval 2010 Task 8, TACRED&lt;/p&gt;
&lt;p&gt;task: Entity and Relation Extraction&lt;/p&gt;
&lt;!-- more --&gt;
&lt;p&gt;Build task agnostic relation representations solely from entity-linked text.&lt;/p&gt;
&lt;h1 id=&#34;缺陷&#34;&gt;缺陷&lt;/h1&gt;
&lt;p&gt;文章认为网页中, 相同的的实体对一般指代相同的实体关系, 把实体不同的构建为负样本. 这个在单份文件中可能大概率是对的.&lt;/p&gt;
&lt;p&gt;但是实体不完全一直不代表这个两对实体的关系不同. 所以这个作为负样本是本质上映射的是实体识别而不是关系.&lt;/p&gt;
&lt;p&gt;比较好的方式是把实体不同但是关系一样的也考虑进来.&lt;/p&gt;
&lt;h1 id=&#34;方法&#34;&gt;方法&lt;/h1&gt;
&lt;h2 id=&#34;define-relation-statement&#34;&gt;Define Relation Statement&lt;/h2&gt;
&lt;p&gt;We define a relation statement to be a block of text containing two marked entities. From this, we create training data that contains relation statements in which the entities have been replaced with a special [BLANK]&lt;/p&gt;</description>
    </item>
    <item>
      <title>A Frustratingly Easy Approach for Joint Entity and Relation Extraction</title>
      <link>https://congchan.github.io/posts/a-frustratingly-easy-approach-for-joint-entity-and-relation-extraction/</link>
      <pubDate>Tue, 20 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://congchan.github.io/posts/a-frustratingly-easy-approach-for-joint-entity-and-relation-extraction/</guid>
      <description>&lt;p&gt;2020, NAACL&lt;/p&gt;
&lt;p&gt;data: ACE 04, ACE 05, SciERC&lt;/p&gt;
&lt;p&gt;links: &lt;a href=&#34;https://github.com/princeton-nlp/PURE&#34;&gt;https://github.com/princeton-nlp/PURE&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;task: Entity and Relation Extraction&lt;/p&gt;
&lt;!-- more --&gt;
&lt;p&gt;提出了一种简单但是有效的pipeline方法:builds on two independent pre-trained encoders and merely uses the entity model to provide input features for the relation model.&lt;/p&gt;
&lt;p&gt;实验说明: validate the importance of&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;learning distinct contextual representations for entities and relations&lt;/strong&gt;,&lt;/li&gt;
&lt;li&gt;fusing entity information at the input layer of the relation model,&lt;/li&gt;
&lt;li&gt;and incorporating global context.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;从效果上看, 似乎是因为cross sentence的context加成更大&lt;/p&gt;
&lt;h1 id=&#34;方法&#34;&gt;方法&lt;/h1&gt;
&lt;p&gt;Input: a sentence X consisting of n tokens &lt;code&gt;x1, . . . , xn&lt;/code&gt;. Let &lt;code&gt;S = {s1, . . . , sm}&lt;/code&gt; be all the possible spans in &lt;code&gt;X&lt;/code&gt; of up to length &lt;code&gt;L&lt;/code&gt; and &lt;code&gt;START(i)&lt;/code&gt; and &lt;code&gt;END(i)&lt;/code&gt; denote start and end indices of &lt;code&gt;si&lt;/code&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Two are Better than One - Joint Entity and Relation Extraction with Table-Sequence Encoders</title>
      <link>https://congchan.github.io/posts/two-are-better-than-one-joint-entity-and-relation-extraction-with-table-sequence-encoders/</link>
      <pubDate>Sat, 27 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://congchan.github.io/posts/two-are-better-than-one-joint-entity-and-relation-extraction-with-table-sequence-encoders/</guid>
      <description>&lt;p&gt;2020, EMNLP&lt;/p&gt;
&lt;p&gt;data: ACE 04, ACE 05, ADE, CoNLL04&lt;/p&gt;
&lt;p&gt;links: &lt;a href=&#34;https://github.com/LorrinWWW/two-are-better-than-one&#34;&gt;https://github.com/LorrinWWW/two-are-better-than-one&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;task: Entity and Relation Extraction&lt;/p&gt;
&lt;!-- more --&gt;
&lt;p&gt;In this work, we propose the novel table-sequence encoders where two different encoders – a table encoder and a sequence encoder are designed to help each other in the representation learning process.&lt;/p&gt;
&lt;p&gt;这篇ACL 2020文章认为, 之前的Joint learning方法侧重于learning a single encoder (usually learning representation in the form of a table) to capture information required for both tasks within the same space. We argue that it can be beneficial to design two distinct encoders to capture such two different types of information in the learning process.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Improving Event Detection via Open-domain Trigger Knowledge</title>
      <link>https://congchan.github.io/posts/improving-event-detection-via-open-domain-trigger-knowledge/</link>
      <pubDate>Thu, 25 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://congchan.github.io/posts/improving-event-detection-via-open-domain-trigger-knowledge/</guid>
      <description>&lt;p&gt;2020, ACL&lt;/p&gt;
&lt;p&gt;data: ACE 05&lt;/p&gt;
&lt;p&gt;task: Event Detection&lt;/p&gt;
&lt;!-- more --&gt;
&lt;p&gt;Propose a novel Enrichment Knowledge Distillation (EKD) model to efficiently distill external open-domain trigger knowledge to reduce the in-built biases to frequent trigger words in annotations.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;leverage the wealth of the open-domain trigger knowledge to improve ED&lt;/li&gt;
&lt;li&gt;propose a novel teacher-student model (EKD) that can learn from both labeled and unlabeled data&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt=&#34;/images/papers/paper2.png&#34; loading=&#34;lazy&#34; src=&#34;https://congchan.github.io/images/papers/paper2.png&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;缺点&#34;&gt;缺点&lt;/h1&gt;
&lt;p&gt;只能对付普遍情况, 即一般性的触发词; 但触发词不是在任何语境下都是触发词.&lt;/p&gt;
&lt;h1 id=&#34;方法&#34;&gt;方法&lt;/h1&gt;
&lt;p&gt;empower the model with external knowledge called Open-Domain Trigger Knowledge, defined as a prior that specifies which words can trigger events without subject to pre-defined event types and the domain of texts.&lt;/p&gt;</description>
    </item>
    <item>
      <title>DeepPath - A Reinforcement Learning Method for Knowledge Graph Reasoning</title>
      <link>https://congchan.github.io/posts/deeppath-a-reinforcement-learning-method-for-knowledge-graph-reasoning/</link>
      <pubDate>Wed, 11 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://congchan.github.io/posts/deeppath-a-reinforcement-learning-method-for-knowledge-graph-reasoning/</guid>
      <description>&lt;p&gt;2017, EMNLP&lt;/p&gt;
&lt;p&gt;data: FB15K-237, FB15K&lt;/p&gt;
&lt;p&gt;task: Knowledge Graph Reasoning&lt;/p&gt;
&lt;!-- more --&gt;
&lt;p&gt;Use a policy-based agent with continuous states based on knowledge graph embeddings, which &lt;strong&gt;reasons in a KG vector space&lt;/strong&gt; by sampling the most promising relation to extend its path.&lt;/p&gt;
&lt;h1 id=&#34;方法&#34;&gt;方法&lt;/h1&gt;
&lt;p&gt;RL 系统包含两部分，&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第一部分是外部环境，指定了 智能体 和知识图谱之间的动态交互。环境被建模为马尔可夫决策过程。&lt;/li&gt;
&lt;li&gt;系统的第二部分，RL 智能体，表示为策略网络，将状态向量映射到随机策略中。神经网络参数通过随机梯度下降更新。相比于 DQN，基于策略的 RL 方法更适合该知识图谱场景。一个原因是知识图谱的路径查找过程，行为空间因为关系图的复杂性可能非常大。这可能导致 DQN 的收敛性变差。另外，策略网络能学习梯度策略，防止 智能体 陷入某种中间状态，而避免基于值的方法如 DQN 在学习策略梯度中遇到的问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt=&#34;/images/papers/paper7.png&#34; loading=&#34;lazy&#34; src=&#34;https://congchan.github.io/images/papers/paper7.png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;关系推理的强化学习&#34;&gt;关系推理的强化学习&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;行为&lt;/strong&gt; 给定一些实体对和一个关系，我们想让 智能体 找到最有信息量的路径来连接这些实体对。从源实体开始，智能体 使用策略网络找到最有希望的关系并每步扩展它的路径直到到达目标实体。为了保持策略网络的输出维度一致，动作空间被定义为知识图谱中的所有关系。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;状态&lt;/strong&gt; 知识图谱中的实体和关系是自然的离散原子符号。现有的实际应用的知识图谱例如 Freebase 和 NELL 通常有大量三元组，不可能直接将所有原子符号建模为状态。为了捕捉这些符号的语义信息，我们使用基于平移的嵌入方法，例如 TransE 和 TransH 来表示实体和关系。这些嵌入将所有符号映射到低维向量空间。在该框架中，每个状态捕捉 智能体 在知识图谱中的位置。在执行一个行为后，智能体 会从一个实体移动到另一个实体。两个状态通过刚执行的行为（关系）由 智能体 连接。第 t 步的状态向量：&lt;/p&gt;</description>
    </item>
    <item>
      <title>Knowledge-Graph-Embedding的Translate族（TransE，TransH，TransR，TransD）</title>
      <link>https://congchan.github.io/posts/knowledge-graph-embedding%E7%9A%84translate%E6%97%8Ftransetranshtransrtransd/</link>
      <pubDate>Thu, 05 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://congchan.github.io/posts/knowledge-graph-embedding%E7%9A%84translate%E6%97%8Ftransetranshtransrtransd/</guid>
      <description>&lt;p&gt;data: WN18, WN11, FB15K, FB13, FB40K&lt;/p&gt;
&lt;p&gt;task: Knowledge Graph Embedding&lt;/p&gt;
&lt;!-- more --&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://congchan.github.io/images/papers/paper9.png&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;transe&#34;&gt;TransE&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Trans&lt;/strong&gt;lating &lt;strong&gt;E&lt;/strong&gt;mbeddings for Modeling Multi-relational Data（2013）&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://proceedings.neurips.cc/paper/2013/file/1cecc7a77928ca8133fa24680a88d2f9-Paper.pdf&#34;&gt;https://proceedings.neurips.cc/paper/2013/file/1cecc7a77928ca8133fa24680a88d2f9-Paper.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这是转换模型系列的第一部作品。该模型的基本思想是使head向量和relation向量的和尽可能靠近tail向量。这里我们用L1或L2范数来衡量它们的靠近程度。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;/images/papers/paper9-1.png&#34; loading=&#34;lazy&#34; src=&#34;https://congchan.github.io/images/papers/paper9-1.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;/images/papers/paper9-2.png&#34; loading=&#34;lazy&#34; src=&#34;https://congchan.github.io/images/papers/paper9-2.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;损失函数 $\mathrm{L}(h, r, t)=\max \left(0, d_{\text {pos }}-d_{\text {neg }}+\text { margin }\right)$使损失函数值最小化，当这两个分数之间的差距大于margin的时候就可以了(我们会设置这个值，通常是1)&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;/images/papers/paper9-3.png&#34; loading=&#34;lazy&#34; src=&#34;https://congchan.github.io/images/papers/paper9-3.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;但是这个模型只能处理一对一的关系，不适合一对多/多对一关系&lt;/strong&gt;，例如，有两个知识，(skytree, location, tokyo)和(gundam, location, tokyo)。经过训练，“sky tree”实体向量将非常接近“gundam”实体向量。但实际上它们没有这样的相似性。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;name_scope&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;embedding&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ent_embeddings&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_variable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;ent_embedding&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;shape&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;entity_total&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;initializer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;contrib&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;layers&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xavier_initializer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;uniform&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rel_embeddings&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_variable&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;rel_embedding&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;shape&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;relation_total&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;initializer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;contrib&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;layers&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xavier_initializer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;uniform&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;pos_h_e&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;embedding_lookup&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ent_embeddings&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pos_h&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;pos_t_e&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;embedding_lookup&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ent_embeddings&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pos_t&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;pos_r_e&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;embedding_lookup&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rel_embeddings&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pos_r&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;neg_h_e&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;embedding_lookup&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ent_embeddings&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;neg_h&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;neg_t_e&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;embedding_lookup&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ent_embeddings&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;neg_t&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;neg_r_e&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;nn&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;embedding_lookup&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rel_embeddings&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;neg_r&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;config&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;L1_flag&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;pos&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reduce_sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;abs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pos_h_e&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pos_r_e&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pos_t_e&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keep_dims&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;neg&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reduce_sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;abs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;neg_h_e&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;neg_r_e&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;neg_t_e&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keep_dims&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;predict&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pos&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;pos&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reduce_sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pos_h_e&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pos_r_e&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pos_t_e&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keep_dims&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;neg&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reduce_sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;neg_h_e&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;neg_r_e&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;neg_t_e&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;keep_dims&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;predict&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pos&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;name_scope&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;output&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;loss&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;reduce_sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;maximum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pos&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;neg&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;margin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;transh&#34;&gt;TransH&lt;/h1&gt;
&lt;p&gt;Knowledge Graph Embedding by Translating on Hyperplanes（2014）&lt;/p&gt;</description>
    </item>
    <item>
      <title>综述 A Survey on Knowledge Graphs - Representation, Acquisition and Applications</title>
      <link>https://congchan.github.io/posts/%E7%BB%BC%E8%BF%B0-a-survey-on-knowledge-graphs-representation-acquisition-and-applications/</link>
      <pubDate>Sat, 01 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://congchan.github.io/posts/%E7%BB%BC%E8%BF%B0-a-survey-on-knowledge-graphs-representation-acquisition-and-applications/</guid>
      <description>&lt;p&gt;Survey: &lt;a href=&#34;https://arxiv.org/abs/2002.00388v4&#34;&gt;https://arxiv.org/abs/2002.00388v4&lt;/a&gt;&lt;/p&gt;
&lt;!-- more --&gt;
&lt;p&gt;A knowledge graph is a structured representation of facts, consisting of entities, relationships and semantic descriptions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Entities&lt;/strong&gt; can be real-world objects and abstract concepts,&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Relationships&lt;/strong&gt; represent the relation between entities,&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Semantic descriptions&lt;/strong&gt; of entities and their relationships contain types and properties with a well-defined meaning&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;G: A knowledge graph
F: A set of facts
(h, r, t): A triple of head, relation and tail
$(\mathbf{h}, \mathbf{r}, \mathbf{t})$: Embedding of head, relation and tail&lt;/p&gt;</description>
    </item>
    <item>
      <title>Open-Domain Targeted Sentiment Analysis via Span-Based Extraction and Classification</title>
      <link>https://congchan.github.io/posts/open-domain-targeted-sentiment-analysis-via-span-based-extraction-and-classification/</link>
      <pubDate>Fri, 24 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://congchan.github.io/posts/open-domain-targeted-sentiment-analysis-via-span-based-extraction-and-classification/</guid>
      <description>&lt;p&gt;2019, ACL&lt;/p&gt;
&lt;p&gt;data: SemEval 2014, SemEval 2014 ABSA, SemEval 2015, SemEval 2016&lt;/p&gt;
&lt;p&gt;task: ABSA&lt;/p&gt;
&lt;!-- more --&gt;
&lt;p&gt;propose a &lt;strong&gt;span-based extract-then-classify framework&lt;/strong&gt;, where multiple opinion targets are directly extracted from the sentence under the supervision of target span boundaries, and corresponding polarities are then classified using their span representations.&lt;/p&gt;
&lt;p&gt;优点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;用指针网络选取target，避免了序列标注的搜索空间过大问题&lt;/li&gt;
&lt;li&gt;用span边界+极性的标注方式，解决多极性的target问题&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;方法&#34;&gt;方法&lt;/h1&gt;
&lt;p&gt;Input:&lt;/p&gt;
&lt;p&gt;sentence &lt;code&gt;x =(x1,..., xn)&lt;/code&gt; with length &lt;code&gt;n&lt;/code&gt;,&lt;/p&gt;
&lt;p&gt;Target list &lt;code&gt;T = {t1,..., tm}&lt;/code&gt;： each target ti is annotated with its start, end position, and its sentiment polarity&lt;/p&gt;</description>
    </item>
    <item>
      <title>A Lite BERT(AlBERT) 原理和源码解析</title>
      <link>https://congchan.github.io/posts/a-lite-bertalbert-%E5%8E%9F%E7%90%86%E5%92%8C%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/</link>
      <pubDate>Sat, 11 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://congchan.github.io/posts/a-lite-bertalbert-%E5%8E%9F%E7%90%86%E5%92%8C%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/</guid>
      <description>&lt;h3 id=&#34;a-lite-bert&#34;&gt;A Lite BERT&lt;/h3&gt;
&lt;p&gt;BERT(Devlin et al., 2019)的参数很多, 模型很大, 内存消耗很大, 在分布式计算中的通信开销很大.&lt;/p&gt;
&lt;p&gt;但是BERT的高内存消耗边际收益并不高, 如果继续增大BERT-large这种大模型的隐含层大小, 模型效果不升反降.&lt;/p&gt;
&lt;p&gt;针对这些问题, 启发于mobilenet, Alert使用了两种减少参数的方法来降低模型大小和提高训练速度, 分别是Factorized embedding parameterization和Cross-layer parameter sharing. 这些设计让ALBERT增加参数大小的边界收益远远大于BERT.&lt;/p&gt;
&lt;p&gt;除此之外, 在句子关系任务上抛弃了bert的&lt;code&gt;nsp&lt;/code&gt;任务, 改为&lt;code&gt;sop&lt;/code&gt;任务.&lt;/p&gt;
&lt;!-- more --&gt;
&lt;p&gt;整体而言, ALBERT是当前众多BERT系列模型的集大成者, 其思路值得学习, 代码也写得很清楚. 下面仔细过一遍.&lt;/p&gt;
&lt;h3 id=&#34;factorized-embedding-parameterization&#34;&gt;Factorized embedding parameterization&lt;/h3&gt;
&lt;p&gt;BERT以及后续的XLNet(Yang et al., 2019), RoBERTa(Liu et al., 2019)等, WordPiece embedding的维度&lt;code&gt;E&lt;/code&gt;是和隐层维度&lt;code&gt;H&lt;/code&gt;绑定的. WordPiece embedding本意是学习context-independent的表达，而hidden-layer旨在学习context-dependent的表达。将WordPiece embedding大小&lt;code&gt;E&lt;/code&gt;与隐层大小&lt;code&gt;H&lt;/code&gt;解绑，可以更有效地利用建模所需的总模型参数.&lt;/p&gt;
&lt;p&gt;从实用性的角度看, 这样可以减少词汇量对模型大小的影响. 在NLP中词汇量一般都很大, 所以这个解绑收益是很明显的.&lt;/p&gt;
&lt;p&gt;具体的做法就是对embedding进行因式分解, 把非常大的单词embedding分解成两个小的矩阵, &lt;code&gt;O(V × H)&lt;/code&gt;变成&lt;code&gt;O(V × E + E × H)&lt;/code&gt;, 可以显著减少单词映射embedding的参数量. 这个在topic models一文中的隐变量模型中类似的思路体现.&lt;/p&gt;
&lt;h3 id=&#34;cross-layer-parameter-sharing&#34;&gt;Cross-layer parameter sharing&lt;/h3&gt;
&lt;p&gt;各个 transformer blocks 所有参数共享, 这样参数不再随着模型层数加深而增大.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Entity Linking</title>
      <link>https://congchan.github.io/posts/entity-linking/</link>
      <pubDate>Thu, 02 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://congchan.github.io/posts/entity-linking/</guid>
      <description>&lt;p&gt;Entity Linking&lt;/p&gt;
&lt;!-- more --&gt; 
&lt;ul&gt;
&lt;li&gt;Knowledge Graph (知识图谱)：一种语义网络，旨在描述客观世界的概念实体及其之间的关系，有时也称为Knowledge Base (知识库)。
&lt;ul&gt;
&lt;li&gt;图谱由三元组构成：&lt;code&gt;&amp;lt;实体1，关系，实体2&amp;gt;&lt;/code&gt; 或者 &lt;code&gt;&amp;lt;实体，属性，属性值&amp;gt;&lt;/code&gt;；&lt;/li&gt;
&lt;li&gt;例如：&lt;code&gt;&amp;lt;姚明，plays-in，NBA&amp;gt;&lt;/code&gt;、&lt;code&gt;&amp;lt;姚明，身高，2.29m&amp;gt;&lt;/code&gt;；&lt;/li&gt;
&lt;li&gt;常见的KB有：Wikidata、DBpedia、YAGO。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Entity 实体：实体是知识图谱的基本单元，也是文本中承载信息的重要语言单位。&lt;/li&gt;
&lt;li&gt;Mention 提及：自然文本中表达实体的语言片段。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;应用方向&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Question Answering&lt;/strong&gt;：EL是KBQA的刚需，linking到实体之后才能查询图数据库；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Content Analysis&lt;/strong&gt;：舆情分析、内容推荐、阅读增强；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Information Retrieval&lt;/strong&gt;：基于语义实体的搜索引擎，google搜索一些实体，右侧会出现wikipedia页面；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Knowledge Base population&lt;/strong&gt;：扩充知识库，更新实体和关系。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;候选实体和消歧&lt;/p&gt;
&lt;p&gt;Entity linking system consists of two components:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;candidate entity generation：从mention出发，找到KB中所有可能的实体，组成候选实体集 (candidate entities)；&lt;/li&gt;
&lt;li&gt;Entity Disambiguation：从candidate entities中，选择最可能的实体作为预测实体。&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;entity-disambiguation-ed&#34;&gt;Entity Disambiguation (ED)&lt;/h1&gt;
&lt;p&gt;是最重要的部分&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Features
&lt;ul&gt;
&lt;li&gt;Context-Independent Features：
&lt;ul&gt;
&lt;li&gt;LinkCount：#(m-&amp;gt;e)，知识库中某个提及m指向实体e的次数；&lt;/li&gt;
&lt;li&gt;Entity Attributes：Popularity、Type；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Context-Dependent Features：
&lt;ul&gt;
&lt;li&gt;Textual Context：BOW, Concept Vector&lt;/li&gt;
&lt;li&gt;Coherence Between Entities：WLM、PMI、Jaccard Distance&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;context-independent-features&#34;&gt;Context-Independent Features&lt;/h2&gt;
&lt;p&gt;mention到实体的LinkCount、实体自身的一些属性（比如热度、类型等等）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LinkCount作为一个先验知识，在消歧时，往往很有用&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;context-dependent-features&#34;&gt;Context-Dependent Features&lt;/h2&gt;
&lt;p&gt;全局地进行entities的消歧实际上是一个NP-hard的问题，因此核心问题是如何更加快速有效地利用一致性特征&lt;/p&gt;</description>
    </item>
    <item>
      <title>知识图谱补全</title>
      <link>https://congchan.github.io/posts/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E8%A1%A5%E5%85%A8/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://congchan.github.io/posts/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E8%A1%A5%E5%85%A8/</guid>
      <description>&lt;p&gt;知识图谱补全&lt;/p&gt;
&lt;!-- more --&gt;
&lt;h1 id=&#34;基于知识表示的方法&#34;&gt;基于知识表示的方法&lt;/h1&gt;
&lt;p&gt;知识表示学习：对知识图谱中的实体和关系学习其低维度的嵌入式表示。&lt;/p&gt;
&lt;p&gt;常见的知识表示学习方法：主要是以 TransE 法及其变种为核心，针对空间映射等场景做的改进&lt;/p&gt;
&lt;p&gt;基于实体和关系的表示对缺失三元组进行预测；&lt;/p&gt;
&lt;p&gt;利用实体描述信息，可以解决开放域实体补全的问题；&lt;/p&gt;
&lt;h1 id=&#34;基于路径查找的方法&#34;&gt;基于路径查找的方法&lt;/h1&gt;
&lt;p&gt;可使用基于路径查找的方法来处理这类多步推理问题。&lt;/p&gt;
&lt;p&gt;传统的路径查找方法主要是 PRA 方法（Path Ranking Algorithm）；但是这种方法对于包含较大规模的知识图谱来说，会由于路径数量爆炸式增长，导致特征空间急剧膨胀&lt;/p&gt;
&lt;p&gt;可以尝试用 embedding 的方式表示关系，对关系进行泛化，并基于此对知识的补全进行建模，以缓解路径数量过多导致的特征空间膨胀问题。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;给定实体对集合，利用 PRA 查找一定数量的路径；&lt;/li&gt;
&lt;li&gt;路径计算过程中加入实体类型信息（减少长尾实体影响）；&lt;/li&gt;
&lt;li&gt;使用 RNN 沿着路径进行向量化建模；RNN 模型参数在不同关系之间共享；&lt;/li&gt;
&lt;li&gt;通过比较路径向量与待预测关系向量间的关联度来进行关系补全。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;基于强化学习的方法&#34;&gt;基于强化学习的方法&lt;/h1&gt;
&lt;p&gt;前面提到的两种方法，仍然存在若干的问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;需要基于 random walk 来查找路径；&lt;/li&gt;
&lt;li&gt;而 random walk 算法在离散空间中运行，难以评价知识图谱中相似的实体和关系；&lt;/li&gt;
&lt;li&gt;超级结点可能影响 random walk 算法运行速度。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;强化学习方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在连续空间中进行路径搜索；&lt;/li&gt;
&lt;li&gt;通过引入多种奖励函数，使得路径查找更加灵活、可控。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;deeppath&#34;&gt;DeepPath&lt;/h2&gt;
&lt;p&gt;DeepPath: A Reinforcement Learning Method for Knowledge Graph Reasoning&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/xwhan/DeepPath&#34;&gt;xwhan/DeepPath&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;/images/papers/paper7.png&#34; loading=&#34;lazy&#34; src=&#34;https://congchan.github.io/images/papers/paper7.png&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;任务：查找 Band of Brothers 和 English 之间的关系。&lt;/li&gt;
&lt;li&gt;路径起点：Band of Brothers&lt;/li&gt;
&lt;li&gt;状态：实体中的 embedding&lt;/li&gt;
&lt;li&gt;动作：图谱中的关系；&lt;/li&gt;
&lt;li&gt;奖励
&lt;ul&gt;
&lt;li&gt;Binary，是否到达终点&lt;/li&gt;
&lt;li&gt;路径长度&lt;/li&gt;
&lt;li&gt;路径多样性&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;策略网络：使用全连接网络。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;DeepPath 方法仍然存在一些缺陷：知识图谱本身的不完善很可能对路径查找造成影响。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Word Lattice</title>
      <link>https://congchan.github.io/posts/word-lattice/</link>
      <pubDate>Thu, 24 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://congchan.github.io/posts/word-lattice/</guid>
      <description>&lt;p&gt;What is &lt;a href=&#34;http://www.statmt.org/moses/?n=Moses.WordLattices#:~:text=A%20word%20lattice%20is%20a%20directed%20acyclic%20graph,and%20edges%20labeled%20with%20a%20word%20and%20weight.&#34;&gt;Word Lattices&lt;/a&gt;?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A word lattice is a directed acyclic graph with a single start point and edges labeled with a word and weight. Unlike confusion networks which additionally impose the requirement that every path must pass through every node, word lattices can represent any finite set of strings (although this generality makes word lattices slightly less space-efficient than confusion networks)&lt;/p&gt;&lt;/blockquote&gt;
&lt;!-- more --&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://congchan.github.io/images/lattice.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;语音识别结果的最优路径不一定与实际字序列匹配，所以人们一般希望能够得到得分最靠前的&lt;code&gt;k-best&lt;/code&gt;条候选路径。为了紧凑地保存候选路径，防止占用过多内存空间，可以采用词格（Word Lattice）来保存识别的候选序列。&lt;/p&gt;
&lt;p&gt;在序列标注任务中，一般的编码器+CRF的分词模型，因为实体标签的定义不同，词汇不同，语料不同等等原因，普遍无法适应垂直领域的问题。如果要适配，需要走一遍数据准备和模型训练验证的流程。&lt;/p&gt;
&lt;p&gt;所以实践中一般都需要词典来匹配。词典匹配方法直接针对文本进行匹配从而获得成分识别候选集合，再基于词频（基于各种工程经验统计获得）筛选输出最终结果。这种策略比较简陋，对词库准确度和覆盖度要求极高，所以存在以下几个问题：&lt;/p&gt;</description>
    </item>
    <item>
      <title>利用bert进行迁移学习</title>
      <link>https://congchan.github.io/posts/%E5%88%A9%E7%94%A8bert%E8%BF%9B%E8%A1%8C%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Wed, 12 Dec 2018 00:00:00 +0000</pubDate>
      <guid>https://congchan.github.io/posts/%E5%88%A9%E7%94%A8bert%E8%BF%9B%E8%A1%8C%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/</guid>
      <description>&lt;h3 id=&#34;nlp任务的难点&#34;&gt;NLP任务的难点&lt;/h3&gt;
&lt;p&gt;不像图像的普适性, 语言本身有其多样性, 如语境的偏移, 背景的变化, 人与人间的分歧, 这导致以下问题:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;有标注数据的通用性低&lt;/li&gt;
&lt;li&gt;标注数据质量不稳定&lt;/li&gt;
&lt;li&gt;现实世界的语言和使用场景不断更新, 导致模型的维护更新换代成本极高&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ol&gt;
&lt;!-- more --&gt;
&lt;p&gt;为了应对NLP的难点, 需要充分利用各种可用的监督信号，包括但不限于传统监督学习（supervision），自监督学习（self-supervised），弱监督(weak supervision)，迁移学习（transfer learning），多任务学习（multi-task learning, MTL）。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Near-term improvements in NLP will be mostly about making clever use of &amp;ldquo;free&amp;rdquo; data.&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;语言模型---经典的自监督学习模型&#34;&gt;语言模型 - 经典的自监督学习模型&lt;/h3&gt;
&lt;p&gt;Lecun有给自监督学习下定义，但我个人对自监督的理解是，基于数据本身进行学习，让模型学习到数据隐含的特征。&lt;/p&gt;
&lt;p&gt;比如语言模型的根据前文预测下一个单词。&lt;/p&gt;
&lt;p&gt;最近的BERT丰富了玩法，提出了Mask language model，就是通过上下文预测掩码位置的单词，作为其核心学习任务；BERT的训练过程还应用了多任务学习，把 next sentence prediction 也作为任务之一一起学习。&lt;/p&gt;
&lt;p&gt;目前除了语言模型和句模型(&lt;code&gt;next sentence&lt;/code&gt;)，是否还有其他任务?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Baidu ERNIE: 引入了论坛对话类数据，利用 DLM（Dialogue Language Model）建模 Query-Response 对话结构，将对话 Pair 对作为输入，引入 Dialogue Embedding 标识对话的角色，利用 Dialogue Response Loss 学习对话的隐式关系。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;elmo-vs-gpt-vs-bert&#34;&gt;ELMo vs GPT vs BERT&lt;/h3&gt;
&lt;p&gt;经典Word2vec表达是context free的，&lt;code&gt;open a bank account&lt;/code&gt;和&lt;code&gt;on the river bank&lt;/code&gt;的&lt;code&gt;bank&lt;/code&gt;共用一个向量值&lt;code&gt;[0.3, 0.2, -0.8, …]&lt;/code&gt;. 如指公司的&lt;code&gt;苹果&lt;/code&gt;和指水果的&lt;code&gt;苹果&lt;/code&gt;共用一个向量.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Transformer &amp; Self-Attention (多头)自注意力编码</title>
      <link>https://congchan.github.io/posts/transformer-self-attention-%E5%A4%9A%E5%A4%B4%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E7%BC%96%E7%A0%81/</link>
      <pubDate>Fri, 30 Nov 2018 00:00:00 +0000</pubDate>
      <guid>https://congchan.github.io/posts/transformer-self-attention-%E5%A4%9A%E5%A4%B4%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E7%BC%96%E7%A0%81/</guid>
      <description>&lt;p&gt;注意力机制的原理是计算query和每个key之间的相关性$\alpha_c(q,k_i)$以获得注意力分配权重。在大部分NLP任务中，key和value都是输入序列的编码。&lt;/p&gt;
&lt;!-- more --&gt;
&lt;p&gt;注意力机制一般是用于提升seq2seq或者encoder-decoder架构的表现。但这篇2017 NIPS的文章&lt;a href=&#34;https://arxiv.org/abs/1706.03762&#34;&gt;Attention is all you need&lt;/a&gt;提出我们可以仅依赖注意力机制就可以完成很多任务. 文章的动机是LSTM这种时序模型速度实在是太慢了。&lt;/p&gt;
&lt;p&gt;近些年来，RNN（及其变种 LSTM, GRU）已成为很多nlp任务如机器翻译的经典网络结构。RNN从左到右或从右到左的方式顺序处理语言。RNN的按顺序处理的性质也使得其更难以充分利用现代快速计算设备，例如GPU等优于并行而非顺序处理的计算单元。虽然卷积神经网络（CNN）的时序性远小于RNN，但CNN体系结构如ByteNet或ConvS2S中，糅合远距离部分的信息所需的步骤数仍随着距离的增加而增长。&lt;/p&gt;
&lt;p&gt;因为一次处理一个单词，RNN需要处理多个时序的单词来做出依赖于长远离单词的决定。但各种研究和实验逐渐表明，决策需要的步骤越多，循环网络就越难以学习如何做出这些决定。而本身LSTM就是为了解决long term dependency问题，但是解决得并不好。很多时候还需要额外加一层注意力层来处理long term dependency。&lt;/p&gt;
&lt;p&gt;所以这次他们直接在编码器和解码器之间直接用attention，这样句子单词的依赖长度最多只有1，减少了信息传输路径。他们称之为Transformer。Transformer只执行一小段constant的步骤（根据经验选择）。在encoder和decoder中，分别应用&lt;strong&gt;self-attention 自注意力机制&lt;/strong&gt;(也称为intra Attention), 顾名思义，指的不是传统的seq2seq架构中target和source之间的Attention机制，而是source或者target自身元素之间的Attention机制。也就是说此时&lt;code&gt;Query&lt;/code&gt;, &lt;code&gt;Key&lt;/code&gt;和&lt;code&gt;Value&lt;/code&gt;都一样, 都是输入或者输出的序列编码. 具体计算过程和其他attention一样的，只是计算对象发生了变化. Self-attention 直接模拟句子中所有单词之间的关系，不管它们之间的位置如何。比如子“I arrived at the bank after crossing the river”，要确定“bank”一词是指河岸而不是金融机构，Transformer可以学会立即关注“river”这个词并在一步之内做出这个决定。&lt;/p&gt;
&lt;h3 id=&#34;transformer总体架构&#34;&gt;Transformer总体架构&lt;/h3&gt;
&lt;p&gt;与过去流行的使用基于自回归网络的Seq2Seq模型框架不同:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Transformer使用注意力来编码(不需要LSTM/CNN之类的)。&lt;/li&gt;
&lt;li&gt;引入自注意力机制&lt;/li&gt;
&lt;li&gt;Multi-Headed Attention Mechanism: 在编码器和解码器中使用 Multi-Headed self-attention。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Transformer也是基于encoder-decoder的架构。具体地说，为了计算给定单词的下一个表示 - 例如“bank” - Transformer将其与句子中的所有其他单词进行比较。这些比较的结果就是其他单词的注意力权重。这些注意力权重决定了其他单词应该为“bank”的下一个表达做出多少贡献。在计算“bank”的新表示时，能够消除歧义的“river”可以获得更高的关注。将注意力权重用来加权平均所有单词的表达，然后将加权平均的表达喂给一个全连接网络以生成“bank”的新表达，以反映出该句子正在谈论的是“河岸”。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://congchan.github.io/images/transform20fps.gif&#34; title=&#34;image from: https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html&#34;&gt;&lt;/p&gt;
&lt;p&gt;Transformer的编码阶段概括起来就是：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;首先为每个单词生成初始表达或embeddings。这些由空心圆表示。&lt;/li&gt;
&lt;li&gt;然后，对于每一个词, 使用自注意力聚合来自所有其他上下文单词的信息，生成参考了整个上下文的每个单词的新表达，由实心球表示。并基于前面生成的表达, 连续地构建新的表达（下一层的实心圆）对每个单词并行地重复多次这种处理。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Encoder的self-attention中, 所有&lt;code&gt;Key&lt;/code&gt;, &lt;code&gt;Value&lt;/code&gt;和&lt;code&gt;Query&lt;/code&gt;都来自同一位置, 即上一层encoder的输出。&lt;/p&gt;
&lt;p&gt;解码器类似，所有&lt;code&gt;Key&lt;/code&gt;, &lt;code&gt;Value&lt;/code&gt;和&lt;code&gt;Query&lt;/code&gt;都来自同一位置, 即上一层decoder的输出, 不过只能看到上一层对应当前&lt;code&gt;query&lt;/code&gt;位置之前的部分。生成&lt;code&gt;Query&lt;/code&gt;时, 不仅关注前一步的输出，还参考编码器的最后一层输出。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://congchan.github.io/images/transformer.png&#34; title=&#34;单层编码器（左）和解码器（右），由 N = 6 个相同的层构建。&#34;&gt;
&lt;code&gt;N = 6&lt;/code&gt;, 这些“层”中的每一个由两个子层组成：position-wise FNN 和一个（编码器），或两个（解码器），基于注意力的子层。其中每个还包含4个线性投影和注意逻辑。&lt;/p&gt;</description>
    </item>
    <item>
      <title>概率图模型 - 朴素贝叶斯 - 隐马尔科夫 - 条件随机场 - 逻辑回归</title>
      <link>https://congchan.github.io/posts/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF-%E9%9A%90%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB-%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/</link>
      <pubDate>Sun, 16 Sep 2018 00:00:00 +0000</pubDate>
      <guid>https://congchan.github.io/posts/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF-%E9%9A%90%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB-%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/</guid>
      <description>&lt;h2 id=&#34;序列标注sequence-labeling&#34;&gt;序列标注（Sequence Labeling）&lt;/h2&gt;
&lt;p&gt;序列标注任务是指根据观察得到的序列（如一个句子）, 推断出序列每个元素（单词）对应的标注。&lt;/p&gt;
&lt;p&gt;具体的任务包括分词(Segmentation), 词性标注（Part-of-Speach tagging, POS）, 实体识别(Named Entity Recognition, NER), 等等. 所谓POS, 就是对于一个句子, 如&lt;code&gt;Bob drank coffee at Starbucks&lt;/code&gt;, 标注可能为&lt;code&gt;Bob (NOUN) drank (VERB) coffee (NOUN) at (PREPOSITION) Starbucks (NOUN)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;除此之外, 还有其他涉及到需要根据观察序列推断隐含状态的问题, 这种问题的特点是每一个位置的标签都不是独立的, 而是和上下文相关依存的, 可以用序列标注的思路来处理.&lt;/p&gt;
&lt;p&gt;单个分类器仅能预测单个类变量，但是序列标注基于概率图模型, 图模型(Graphical Models)的真正功能在于它们能够对许多有相互依赖的变量进行建模。最简单的依赖关系可以描述为一种线性链(Linear Chain), 也就是后续介绍到的隐马尔可夫模型(Hidden Markov Model, HMM)用到的假设.&lt;/p&gt;
&lt;!-- more --&gt;
&lt;h2 id=&#34;概率图模型&#34;&gt;概率图模型&lt;/h2&gt;
&lt;p&gt;Graphical Models, 用图的形式表示随机变量之间条件依赖关系的概率模型，是概率论与图论的结合。图中的节点表示随机变量，缺少边表示条件独立假设。&lt;/p&gt;
&lt;p&gt;G = (V, E). 其中 V: vertex, 顶点/节点, 表示随机变量. E: edge, 边/弧. 如果两个节点不存在边, 则二者条件独立.
&lt;img loading=&#34;lazy&#34; src=&#34;https://congchan.github.io/images/probabilistic_graphical_models.png&#34; title=&#34;image from: Probabilistic Graphical Models Principles and Techniques&#34;&gt; 从图上可以看到, 贝叶斯网络(Bayesian Networks, BNs)是有向图, 每个节点的条件概率分布表示为&lt;code&gt;P(当前节点 | 父节点)&lt;/code&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>机器阅读理解 - LSTM与注意力机制 - 斯坦福问答数据集 (SQuAD)</title>
      <link>https://congchan.github.io/posts/%E6%9C%BA%E5%99%A8%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3-lstm%E4%B8%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-%E6%96%AF%E5%9D%A6%E7%A6%8F%E9%97%AE%E7%AD%94%E6%95%B0%E6%8D%AE%E9%9B%86-squad/</link>
      <pubDate>Fri, 20 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://congchan.github.io/posts/%E6%9C%BA%E5%99%A8%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3-lstm%E4%B8%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-%E6%96%AF%E5%9D%A6%E7%A6%8F%E9%97%AE%E7%AD%94%E6%95%B0%E6%8D%AE%E9%9B%86-squad/</guid>
      <description>&lt;p&gt;本文介绍注意力机制如何应用于阅读理解类任务, 并介绍了由此任务催生的一些注意力变种.&lt;/p&gt;
&lt;!-- more --&gt;
&lt;h2 id=&#34;注意力机制应用于阅读理解&#34;&gt;注意力机制应用于阅读理解&lt;/h2&gt;
&lt;p&gt;The Standford question and answer dataset &lt;a href=&#34;https://rajpurkar.github.io/SQuAD-explorer/&#34;&gt;(SQuAD)&lt;/a&gt; 是由 Rajpurkar 等人提出的一个较有挑战性的阅读理解数据集。该数据集包含 10 万个（问题，原文，答案）三元组，原文来自于 536 篇维基百科文章，而问题和答案的构建主要是通过众包的方式，让标注人员提出最多 5 个基于文章内容的问题并提供正确答案，且答案出现在原文中。SQuAD 和之前的完形填空类阅读理解数据集如 CNN/DM，CBT 等最大的区别在于：SQuAD 中的答案不在是单个实体或单词，而可能是一段短语，这使得其答案更难预测。SQuAD 包含公开的训练集和开发集，以及一个隐藏的测试集，其采用了与 ImageNet 类似的封闭评测的方式，研究人员需提交算法到一个开放平台，并由 SQuAD 官方人员进行测试并公布结果。&lt;/p&gt;
&lt;p&gt;由于 SQuAD 的答案限定于来自原文，模型只需要判断原文中哪些词是答案即可，因此是一种抽取式的 QA 任务而不是生成式任务。简单的 SQuAD 的模型框架可以参考seq2seq：Embed 层，Encode 层 和 Decode 层。Embed 层负责将原文和问题中的 tokens 映射为向量表示；Encode 层主要使用 RNN 来对原文和问题进行编码，这样编码后每个 token 的向量表示就蕴含了上下文的语义信息；Decode 层则基于 query-aware 的原文表示来预测答案起始位置。&lt;/p&gt;
&lt;p&gt;但这个文本数据集涉及问题，原文，答案三个部分, 特别是需要根据问题在原文中搜寻答案的范围, 这就涉及如果把问题的信息提取出来并作用于原文. 目前各种前沿模型的关注点几乎都是在如何捕捉问题和原文之间的交互关系，也就是在 Encode 层和 Decode 层之间, 使用一个 Interaction 层处理编码了问题语义信息的原文表示，即 query-aware 的原文表示，再输入给 Decode 层。而本来应用机器翻译Attention机制就能很好的处理这种交互。&lt;/p&gt;
&lt;p&gt;虽然注意力机制大同小异，但是不同的注意力权重（打分函数）带来的效果是不一样的。比较常用的是就是使用&lt;a href=&#34;%5Cattention#%E5%85%A8%E5%B1%80%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6&#34;&gt;全局注意力机制&lt;/a&gt;中提到的
&lt;/p&gt;
$$
\begin{aligned}
    score_{general}(t&#39; t) &amp;= s^\top_{t&#39;} W_\alpha h_t, \\\
\end{aligned}
$$&lt;p&gt;
就是用一个交互矩阵$W_\alpha$来捕捉问题和原文之间的交互关系. 原文作者称之为 &lt;strong&gt;Bilinear&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>从头理解注意力机制</title>
      <link>https://congchan.github.io/posts/%E4%BB%8E%E5%A4%B4%E7%90%86%E8%A7%A3%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/</link>
      <pubDate>Tue, 10 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://congchan.github.io/posts/%E4%BB%8E%E5%A4%B4%E7%90%86%E8%A7%A3%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/</guid>
      <description>&lt;h3 id=&#34;注意力机制如何起源的&#34;&gt;注意力机制如何起源的&lt;/h3&gt;
&lt;p&gt;神经网络中的注意力机制启发自人类的&lt;strong&gt;视觉注意力机制&lt;/strong&gt;，能够（高分辨率地）聚焦于图像中需要重点关注的目标区域（节省大脑资源），同时（低分辨率地）感知周围的图像，然后随着时间的推移调整焦点（状态调整）。&lt;/p&gt;
&lt;p&gt;在神经网路中，注意力机制是为了解决什么问题？&lt;/p&gt;
&lt;!-- more --&gt;
&lt;p&gt;在深度学习还没流行的时候, 传统的算法早已应用了注意力机制的思想.&lt;/p&gt;
&lt;p&gt;比如一个非线性回归问题，对于代表位置的输入变量${x_1, ..., x_m}$ 和 代表位置对应的输出值${y_1, ..., y_m}$, 如何预测新的$x_n$对应的输出? Baseline 就是求均值, &lt;/p&gt;
$$\frac{1}{m} \sum_{i=1}^{m} y_i$$&lt;p&gt; 当然更好的方案(Watson, Nadaraya, 1964)是根据不同的输入$x_i$给与$y_i$不同的权重, &lt;/p&gt;
$$y = \sum_{i=1}^{m} \alpha(x, x_i) y_i $$&lt;p&gt;这里$x$代表一个新的输入(作为&lt;strong&gt;query&lt;/strong&gt;), 根据$x$和已有的位置$x_i$(作为&lt;strong&gt;key&lt;/strong&gt;)进行某种运算, 得到$x_i$对应的输出$y_i$(作为&lt;strong&gt;value&lt;/strong&gt;)的权重. 如果每一个权重都是一个Guassians分布, 并正则化, 则一个&lt;strong&gt;加权的回归预测模型&lt;/strong&gt;就是:&lt;/p&gt;
$$f(x) = \sum_i y_i \frac{k(x_i, x)}{\sum_j k(x_j, x)}$$&lt;p&gt;这个算法的&amp;quot;深度学习&amp;quot;版本, 就是其权重是通过优化器(如sgd)学习得来, 并且把平均运算改为&lt;strong&gt;加权池化(weighted pooling)&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;如何简单直观地理解注意力机制&#34;&gt;如何简单直观地理解注意力机制&lt;/h3&gt;
&lt;p&gt;虽然注意力机制一开始被应用于图像识别领域，但是后来推广到神经机器翻译(NMT)中(&lt;code&gt;Seq2Seq for Machine Translation, Sutskever, Vinyals, Le ‘14&lt;/code&gt;). NMT也是注意力机制在NLP领域最早最成功的应用之一.&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://www.wildml.com/wp-content/uploads/2015/09/Screen-Shot-2015-09-17-at-10.39.06-AM.png&#34; title=&#34;一个典型的seq2seq(encoder-decoder)翻译模型, 向量h表示编码器的内部状态&#34;&gt;
在上图中，&lt;code&gt;Echt&lt;/code&gt;，&lt;code&gt;Dicke&lt;/code&gt;和&lt;code&gt;Kiste&lt;/code&gt;词被送到编码器中，并且在特殊信号（未显示）之后，解码器开始生成翻译后的句子。解码器不断生成单词，直到产生特殊的句子结尾标记(如&lt;code&gt;&amp;lt;eos&amp;gt;&lt;/code&gt;)。也就是说解码器仅根据最后一个隐含状态$h_3$来生成序列. 假如这个句子很短, 那么效果其实是很好的.&lt;/p&gt;
&lt;p&gt;不过对于比较长的句子, 那么这个架构的弱点就暴露无疑了.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;首先, 编码器能否把句子的所有信息(语言学上的和常识等知识)都理解/捕捉到?&lt;/li&gt;
&lt;li&gt;其次, 受限于目前的实现技术(主要是硬件), 单个隐含状态(如$h_3$这个向量)的维度大小是有限的, 而句子长度以及语言的组合情况是无限的, 单靠$h_3$自身是存储信息能力是有限的.&lt;/li&gt;
&lt;li&gt;再者, 解码器是否有足够的解码能力从一个隐含状态中解码出所有的信息?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;虽然大部分句子是相对紧凑的, 但语言有个特点, 就是一个词有可能和前面好几步之外的词有联系, 比如一些指代词用于指代文本最开头出现的名词; 语义上, 某个句子的理解, 可能依赖于前面多个句子; 当然往大了说, 要理解一篇文章或一本书, 我们通常需要理解并联系多个段落, 多个章节. 这种现象称之为语言的长距离依赖(&lt;strong&gt;long-term dependency&lt;/strong&gt;), 在一般性的序列数据中, 这个现象称之为的Long-range dependence(LRD). 即使是使用了LSTM这种理论上可以克服长距离依赖问题地网络, 也无法很好的克服语言的长距离依赖问题, 究其原因, 除了LSTM自身的局限性之外, 更主要是深度学习的梯度学习方法的局限性(在梯度反向传播中, 会出现梯度消失).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Inf Course Note - Accelerated Natural Language Processing</title>
      <link>https://congchan.github.io/posts/inf-course-note-accelerated-natural-language-processing/</link>
      <pubDate>Sat, 30 Jun 2018 00:00:00 +0000</pubDate>
      <guid>https://congchan.github.io/posts/inf-course-note-accelerated-natural-language-processing/</guid>
      <description>&lt;p&gt;爱丁堡大学信息学院课程笔记 Accelerated Natural Language Processing, Informatics, University of Edinburgh&lt;/p&gt;
&lt;p&gt;References:
&lt;a href=&#34;http://www.inf.ed.ac.uk/teaching/courses/anlp/&#34;&gt;Accelerated natural language processing&lt;/a&gt;
&lt;a href=&#34;https://www.inf.ed.ac.uk/teaching/courses/anlp/review/review_ay17.html&#34;&gt;ANLP revision guide&lt;/a&gt;
&lt;a href=&#34;https://web.stanford.edu/~jurafsky/NLPCourseraSlides.html&#34;&gt;Lecture Slides from the Stanford Coursera course Natural Language Processing, by Dan Jurafsky and Christopher Manning&lt;/a&gt;&lt;/p&gt;
&lt;!-- more --&gt;
&lt;h2 id=&#34;概率模型-probability-model&#34;&gt;概率模型 Probability Model&lt;/h2&gt;
&lt;p&gt;概率模型是随机现象的数学表示，由样本空间，样本空间内的事件以及与每个事件相关的概率定义。目标是模拟给一个事件发生的概率&lt;/p&gt;
&lt;p&gt;估算概率（Probability Estimation）一般使用最大似然估计（MLE，相关频率）：&lt;/p&gt;
$$p(x_i) = \frac{Count(x_i)}{\sum_{i=0}^nCount(x_i)}$$&lt;h3 id=&#34;平滑smoothing&#34;&gt;平滑Smoothing&lt;/h3&gt;
&lt;p&gt;一般用于处理0概率的问题，比如在训练集中看不到, 但出现在测试集中的词。&lt;/p&gt;
&lt;h2 id=&#34;language-modeling&#34;&gt;Language modeling&lt;/h2&gt;
&lt;p&gt;To compute the probability of sentence /sequence of words $P(w_1, w_2, w_3...)$, or to predict upcomming words $P(w|w_1, w_2, w_3...)$&amp;hellip; a language model is also a probability model.&lt;/p&gt;</description>
    </item>
    <item>
      <title>循环神经网络</title>
      <link>https://congchan.github.io/posts/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</link>
      <pubDate>Tue, 15 May 2018 00:00:00 +0000</pubDate>
      <guid>https://congchan.github.io/posts/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</guid>
      <description>&lt;h2 id=&#34;循环神经网络&#34;&gt;循环神经网络&lt;/h2&gt;
&lt;p&gt;当人类阅读时，会根据对之前单词的理解和记忆来辅助理解当前看到的每个单词。也就是人能够很好地处理语言的长距离依赖特性（long-term dependency）。在自然语言处理任务中，很多传统的模型无法做到这一点，比如前馈神经网络；而传统的n-gram模型固然可以通过把把n系数增大来捕捉长距离依赖，但带来的非常巨大的内存消耗。&lt;/p&gt;
&lt;!-- more --&gt;
&lt;p&gt;循环神经网络（Recurrent Neural Networks, RNNs)可以看做是多个&lt;strong&gt;共享参数&lt;/strong&gt;的前馈神经网络不断叠加的结果
![](&lt;a href=&#34;http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png&#34;&gt;http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png&lt;/a&gt; &amp;ldquo;A recurrent neural network and the unfolding in time of the computation involved in its forward computation. &amp;ldquo;image from: &lt;a href=&#34;http://colah.github.io&#34;&gt;http://colah.github.io&lt;/a&gt;&amp;rdquo;)&lt;/p&gt;
&lt;p&gt;这里的核心是想办法解码历史信息, 即通过递归方程$s_i = R(x_i, s_{i−1})$让$s_i$解码序列$x_{1:n}$. 比如把所有历史信息累加就是一种非常简单粗暴的方式, 这样得到的是连续词袋模型(continuous-bag-of-words model)$s_i = R_{CBOW}(x_i, s_{i-1}) = x_i + s_{i−1}$, 虽然简单，但这种RNN其实忽略了数据的时序性质。&lt;/p&gt;
&lt;p&gt;一般意义上的RNN是指Elman Network or Simple-RNN (S-RNN)(&lt;code&gt;Elman [1990]&lt;/code&gt;), $s_i = R_{SRNN}(x_i, s_{i-1}) = g(x_iW^x + s_{i−1}W^s + b)$, 也就是把历史信息先进行线性变换(乘以矩阵), 再和bias加起来, 再通过一个非线性激活函数(tanh或ReLU). 添加了线性变换再进行非线性激活, 使网络对输入的顺序变得敏感。&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/09/rnn.jpg&#34; title=&#34;image from: Nature&#34;&gt;
在使用时, 给定输入序列（单词序列或语音）得出输出序列的过程如下：&lt;/p&gt;</description>
    </item>
    <item>
      <title>神经网络用于文本分类</title>
      <link>https://congchan.github.io/posts/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%94%A8%E4%BA%8E%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/</link>
      <pubDate>Mon, 15 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://congchan.github.io/posts/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%94%A8%E4%BA%8E%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/</guid>
      <description>&lt;h2 id=&#34;文本分类&#34;&gt;文本分类&lt;/h2&gt;
&lt;p&gt;文本分类是很多业务问题中广泛使用到的NLP/监督机器学习（ML）。文本分类的目标是自动将文本/文档分类为一个或多个预定义类别。目前的成熟思路是用词向量解码文本，然后使用传统机器学习模型或者深度神经网络模型来做分类。&lt;/p&gt;
&lt;p&gt;文本分类是学术界和工业界非常活跃的研究领域。本文主要介绍用于文本分类的几种神经网络模型方法，并比较它们的性能，代码实现主要基于Keras。文中代码都在这个&lt;a href=&#34;https://github.com/congchan/DeepText&#34;&gt;DeepText&lt;/a&gt;GitHub项目中.&lt;/p&gt;
&lt;!-- more --&gt;
&lt;p&gt;文本分类的一些示例包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;从社交媒体中了解受众情绪（😁 😐 😥）&lt;/li&gt;
&lt;li&gt;检测垃圾邮件和非垃圾邮件&lt;/li&gt;
&lt;li&gt;自动标记客户查询&lt;/li&gt;
&lt;li&gt;将新闻文章📰分类为预定义主题&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;端到端文本分类流水线&#34;&gt;端到端文本分类流水线&lt;/h2&gt;
&lt;p&gt;端到端文本分类流水线由以下组件组成：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;训练文本：输入文本，有监督模型能够通过已标注数据来学习和预测所需的类。&lt;/li&gt;
&lt;li&gt;特征向量：特征向量是用于解码输入数据特征的信息的向量。&lt;/li&gt;
&lt;li&gt;标签：预定义的类别/类，作为模型预测的目标。&lt;/li&gt;
&lt;li&gt;算法模型：能够处理文本分类的算法（在我们的例子中：CNN，RNN，HAN, Fasttext）&lt;/li&gt;
&lt;li&gt;预测：已经在历史数据集上训练过的模型，可以用于执行标签预测。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这里使用汽车消费者的评测数据集，在&lt;code&gt;tsv&lt;/code&gt;文件中, 第一列是序号对我们没用, 第二列是&lt;code&gt;label(0, 1)&lt;/code&gt;，分别代表&lt;code&gt;（消极，积极）&lt;/code&gt;评价，第三列是文本.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;1	操控性舒服、油耗低，性价比高
0	动力的确有点点让我相信了up的确是个代步车而已!
1	1。车的外观很喜欢。2。省油，现在磨合期7.3，相信以后还会下降。
1	内饰的做工和用料同级别同价位最厚道的
0	减震系统太硬！
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;数据处理使用的类，具体见&lt;a href=&#34;https://github.com/congchan/DeepText/blob/a33fe1b8e895916b26bc658f0a02ac8253291d8a/data_process.py#L29&#34;&gt;代码链接&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;DataProcessor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;object&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&amp;#34; Base class for data converters for sequence classification data sets.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        helper funcitons [read_tsv, read_text, read_json]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;o&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;SampleProcessor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;DataProcessor&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&amp;#34; Sample processor for the classification data set.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        Tranform the text to tensor for training
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        if use pre-train model, need vocabulary file
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;        usage:
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;            process data files
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;            &amp;gt;&amp;gt;&amp;gt; processer = SampleProcessor(config, )
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;            provide your own data in list format [train_X, train_Y, test_X, test_Y]
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;            &amp;gt;&amp;gt;&amp;gt; processer = SampleProcessor(config, data)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;    &amp;#34;&amp;#34;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;词向量&#34;&gt;词向量&lt;/h3&gt;
&lt;p&gt;使用包含外部知识的embedding表达字词是目前的主流方法，经典的如word2vec，GLoVe，较新进的 ELMo，BERT，等预训练向量，集成了关于单词的新信息（词汇和语义），这些信息已经在非常大的数据集上进行了训练和提炼。&lt;/p&gt;</description>
    </item>
    <item>
      <title>信息抽取</title>
      <link>https://congchan.github.io/posts/%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96/</link>
      <pubDate>Thu, 11 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://congchan.github.io/posts/%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96/</guid>
      <description>&lt;h2 id=&#34;信息抽取&#34;&gt;信息抽取&lt;/h2&gt;
&lt;p&gt;1997年MUC会议（MUC-7） 召开时，评测任务已经增加到5个：
① 场景模板（scenario template, ST）填充：定义了描述场景的模板及槽填充规范；
② 命名实体（named entity, NE）识别：识别出文本中出现的专有名称和有意义的数量短语， 并加以归类；
③ 共指（coreference, CR）关系确定：识别出给定文本中的参照表达（ referring expressions），并确定这些表达之间的共指关系；
④ 模板元素（template element, TE）填充：类似于人名和组织机构名识别，但是要求系统必须识别出实体的描述和名字，如果一个实体在文本中被提到了多次，使用了几种可能的描述和不同的名字形式，要求系统都要把它们识别出来，一个文本中的每个实体只有一个模板元素［Grishman and Sundheim, 1996］；
⑤ 模板关系（template relation, TR）：确定实体之间与特定领域无关的关系。&lt;/p&gt;
&lt;!-- more --&gt;
&lt;p&gt;1999年起美国NIST组织了自动内容抽取（automatic content extraction, ACE）评测会议，旨在研究和
开发自动内容技术以支持对三种不同来源文本（普通文本、经语音识别后得到的文本、 由OCR识别得到的文本）的自动处理，以实现新闻语料中出现的实体、关系、事件等内容的自动抽取。评测任务设计:
实体检测与跟踪（entity detection and tracking, EDT）、数值检测与识别（value detection and recognition, VDR）、时间识别和规范化（time expression recognition and normalization, TERN）、关系检测与描述（relation detection and characterization, RDC）、事件检测与描述（event detection and characterization, EDC）和实体翻译（entity translation, ET）等。&lt;/p&gt;
&lt;h3 id=&#34;tf-idf-关键词抽取&#34;&gt;TF-IDF 关键词抽取&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;jieba.analyse&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;jieba&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;analyse&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;extract_tags&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sentence&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;topK&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;withWeight&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;allowPOS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;sentence&lt;/code&gt; 为待提取的文本
&lt;code&gt;topK&lt;/code&gt; 为返回几个 TF/IDF 权重最大的关键词，默认值为 &lt;code&gt;20&lt;/code&gt;
&lt;code&gt;withWeight&lt;/code&gt; 为是否一并返回关键词权重值，默认值为 &lt;code&gt;False&lt;/code&gt;
&lt;code&gt;allowPOS&lt;/code&gt; 仅包括指定词性的词，默认值为空，即不筛选. 如电商评论指定要形容词&lt;/p&gt;</description>
    </item>
    <item>
      <title>Topic Modelling - 主题建模以及隐变量模型</title>
      <link>https://congchan.github.io/posts/topic-modelling-%E4%B8%BB%E9%A2%98%E5%BB%BA%E6%A8%A1%E4%BB%A5%E5%8F%8A%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Sat, 23 Dec 2017 00:00:00 +0000</pubDate>
      <guid>https://congchan.github.io/posts/topic-modelling-%E4%B8%BB%E9%A2%98%E5%BB%BA%E6%A8%A1%E4%BB%A5%E5%8F%8A%E9%9A%90%E5%8F%98%E9%87%8F%E6%A8%A1%E5%9E%8B/</guid>
      <description>&lt;p&gt;本篇介绍 topic modeling, 以及一个经典的算法Latent Dirichlet allocation, 文本挖掘与语义理解的集大成者(至少在深度学习统治之前). 当然LDA不仅仅局限于文本, 还可应用于涉及大量数据集的各种问题，包括协同过滤，基于内容的图像检索和生物信息学等领域的数据。&lt;/p&gt;
&lt;!-- more --&gt;
&lt;h2 id=&#34;topic-modelling&#34;&gt;Topic Modelling&lt;/h2&gt;
&lt;p&gt;大规模文本挖掘的核心问题, 就是用数学模型代替人力来理解文本语义，目标是找到对集合成员（如一堆文本）的数学/统计描述，以便能够对这些大型集合进行高效处理，同时保留对基本任务（如分类，检测，摘要以及相似性和相关性判断）有用的基本统计关系。&lt;/p&gt;
&lt;p&gt;在这方面的研究方法很多，特别是信息检索(IR)领域. 一个基本方法是将语料库中的每个文档向量化，向量中的每个实数代表计数率。比如经典的tf-idf方法，用&lt;strong&gt;Document-Term Matrix&lt;/strong&gt;来表达不同词在不同文档出现的情况差异, 一般term就是word作为features, 所以在这里我们表示document-word matrix(DWM), 就是&lt;code&gt;DWM[i][j] = The number of occurrences of word_j in document_i&lt;/code&gt;.
Doc 1: I have a fluffy cat.
Doc 2: I see a fluffy dog.&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;DWM&lt;/th&gt;
          &lt;th&gt;I&lt;/th&gt;
          &lt;th&gt;have&lt;/th&gt;
          &lt;th&gt;a&lt;/th&gt;
          &lt;th&gt;fluffy&lt;/th&gt;
          &lt;th&gt;cat&lt;/th&gt;
          &lt;th&gt;see&lt;/th&gt;
          &lt;th&gt;dog&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;doc1&lt;/td&gt;
          &lt;td&gt;1&lt;/td&gt;
          &lt;td&gt;1&lt;/td&gt;
          &lt;td&gt;1&lt;/td&gt;
          &lt;td&gt;1&lt;/td&gt;
          &lt;td&gt;1&lt;/td&gt;
          &lt;td&gt;0&lt;/td&gt;
          &lt;td&gt;0&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;doc2&lt;/td&gt;
          &lt;td&gt;1&lt;/td&gt;
          &lt;td&gt;0&lt;/td&gt;
          &lt;td&gt;1&lt;/td&gt;
          &lt;td&gt;1&lt;/td&gt;
          &lt;td&gt;0&lt;/td&gt;
          &lt;td&gt;1&lt;/td&gt;
          &lt;td&gt;1&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;然后进行normalization, 去和 inverse document frequency count(IDF)进行比较. IDF统计每个词在整个文档集合中出现的总次数, 通常转化为log scale, 并进行适当的normalization.&lt;/p&gt;</description>
    </item>
    <item>
      <title>语言模型</title>
      <link>https://congchan.github.io/posts/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Sun, 12 Nov 2017 00:00:00 +0000</pubDate>
      <guid>https://congchan.github.io/posts/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/</guid>
      <description>&lt;h2 id=&#34;语言模型&#34;&gt;语言模型&lt;/h2&gt;
&lt;p&gt;语言模型Language modeling（LM）最初是针对语音识别问题而开发的, 现在广泛用于其他NLP应用中, 比如机器翻译需要利用LM来给翻译出的句子打分.&lt;/p&gt;
&lt;!-- more --&gt;
&lt;p&gt;假设我们有一个语料库 - 某种语言的句子的无限集合$\mathcal{V^+}$（这些句子是由有限的词$\mathcal{V}$组成的）。例如，我们可能从网上获得大量文本。给定了此语料库，我们想估计LM的参数。这些参数包含语料库中所有单词的有限集合$\mathcal{V}$, 以及句子的概率分布函数$p(x_1, x_2, ..., x_n)$，必须满足&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;For any $\langle x_1...x_n \rangle \in \mathcal{V^+}$, $p(x_1, x_2, ..., x_n) ≥ 0$&lt;/li&gt;
&lt;li&gt;$\sum_{\langle x_1...x_n \rangle \in \mathcal{V^+}}p(x_1, x_2, ..., x_n) = 1$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;比如，当$\mathcal{V}$只有&lt;code&gt;cat, eat, fish&lt;/code&gt;, 那么它组合成的句子按照人类的评价标准, 通顺程度从高到低是: &lt;code&gt;cat eat fish&lt;/code&gt;, &lt;code&gt;fish eat cat&lt;/code&gt;, &lt;code&gt;cat fish eat&lt;/code&gt;, &lt;code&gt;eat cat fish&lt;/code&gt;, &lt;code&gt;eat fish cat&lt;/code&gt;, &lt;code&gt;fish cat eat&lt;/code&gt;. 这些是可能出现的句子(还没出现的不代表未来不会出现), 从概率分布的角度看待, 这些句子的概率之和是&lt;code&gt;1&lt;/code&gt;, 因为这三个词只能组成这几个句子. 而LM的意义就在于能够赋予&lt;code&gt;cat eat fish&lt;/code&gt;最大的概率, 代替人来判断句子是否准确, 通俗的说是一个句子通顺打分机器.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
