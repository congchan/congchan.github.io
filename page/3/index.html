<!doctype html><html lang=en dir=auto><head><meta name=generator content="Hugo 0.147.9"><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Cong's Log</title><meta name=description content="Hi, this is Cong. I’m documenting my learning notes in this blog."><meta name=author content="Cong"><link rel=canonical href=https://congchan.github.io/><link crossorigin=anonymous href=/assets/css/stylesheet.1f908d890a7e84b56b73a7a0dc6591e6e3f782fcba048ce1eb46319195bedaef.css integrity="sha256-H5CNiQp+hLVrc6eg3GWR5uP3gvy6BIzh60YxkZW+2u8=" rel="preload stylesheet" as=style><link rel=icon href=https://congchan.github.io/favicons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://congchan.github.io/favicons/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://congchan.github.io/favicons/favicon-32x32.png><link rel=apple-touch-icon href=https://congchan.github.io/favicons/apple-touch-icon.png><link rel=mask-icon href=https://congchan.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://congchan.github.io/index.xml><link rel=alternate type=application/json href=https://congchan.github.io/index.json><link rel=alternate hreflang=en href=https://congchan.github.io/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}]})'></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-6T0DPR6SMC"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-6T0DPR6SMC")}</script><meta property="og:url" content="https://congchan.github.io/"><meta property="og:site_name" content="Cong's Log"><meta property="og:title" content="Cong's Log"><meta property="og:description" content="Hi, this is Cong. I’m documenting my learning notes in this blog."><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Cong's Log"><meta name=twitter:description content="Hi, this is Cong. I’m documenting my learning notes in this blog."><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"Cong's Log","url":"https://congchan.github.io/","description":"Hi, this is Cong. I’m documenting my learning notes in this blog.","logo":"https://congchan.github.io/favicons/favicon.ico","sameAs":["https://github.com/congchan"]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://congchan.github.io/ accesskey=h title="Cong's Log (Alt + H)">Cong's Log</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://congchan.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://congchan.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://congchan.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Mixture of Experts (MOE)</h2></header><div class=entry-content><p>Mixture of Experts (MOE) MOE属于Ensemble Method中的一个方法, 采用分治思想：
将复杂的建模任务分解为多个相对简单的子任务，为每个子任务训练专门的模型：涉及子任务分解，或者Clustering 需要一个门控模型，基于数据输入选择如何组合多个专家模型的结果 Mixture of experts aims at increasing the accuracy of a function approximation by replacing a single global model by a weighted sum of local models (experts). It is based on a partition of the problem domain into several subdomains via clustering algorithms followed by a local expert training on each subdomain.
Local Models & Global Models Hinton的课件介绍了模型拟合分布的两个极端方式:
...</p></div><footer class=entry-footer><span title='2021-07-03 00:00:00 +0000 UTC'>2021-07-03</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;Cong Chan</footer><a class=entry-link aria-label="post link to Mixture of Experts (MOE)" href=https://congchan.github.io/posts/mixture-of-experts-moe/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Survey - Pre-Trained Models - Past, Present and Future</h2></header><div class=entry-content><p>Links: https://arxiv.org/abs/2106.07139
最新出炉的 Pre-Trained Models 综述速览。
先确定综述中的一些名词的定义
Transfer learning：迁移学习，一种用于应对机器学习中的data hungry问题的方法，是有监督的 Self-Supervised Learning：自监督学习，也用于应对机器学习中的data hungry问题，特别是针对完全没有标注的数据，可以通过某种方式以数据自身为标签进行学习（比如language modeling）。所以和无监督学习有异曲同工之处。 一般我们说无监督主要集中于clustering, community discovery, and anomaly detection等模式识别问题 而self-supervised learning还是在监督学习的范畴，集中于classification and generation等问题 Pre-trained models (PTMs) ：预训练模型，Pre-training是一种具体的训练方案，可以采用transfer learning或者Self-Supervised Learning方法 2 Background 脉络图谱 Pre-training 可分为两大类：
2.1 Transfer Learning and Supervised Pre-Training 此类可进一步细分为 feature transfer 和 parameter transfer. 2.2 Self-Supervised Learning and Self-Supervised Pre-Training Transfer learning 可细分为四个子类
inductive transfer learning (Lawrence and Platt, 2004; Mihalkova et al., 2007; Evgeniou and Pontil, 2007), transductive transfer learning (Shimodaira, 2000; Zadrozny,2004; Daume III and Marcu, 2006), self-taught learning (Raina et al., 2007; Dai et al., 2008) unsupervised transfer learning (Wang et al., 2008). inductive transfer learning 和 transductive transfer learning 的研究进展主要集中以imageNet为labeled source data资源的图像领域
...</p></div><footer class=entry-footer><span title='2021-06-19 00:00:00 +0000 UTC'>2021-06-19</span>&nbsp;·&nbsp;10 min&nbsp;·&nbsp;Cong Chan</footer><a class=entry-link aria-label="post link to Survey - Pre-Trained Models - Past, Present and Future" href=https://congchan.github.io/posts/survey-pre-trained-models-past-present-and-future/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>CorefQA - Coreference resolution as query-based span prediction</h2></header><div class=entry-content><p>2020, ACL
data: CoNLL-2012, GAP
task: Coreference Resolution
通过QA方式处理coreference问题，A query is generated for each candidate mention using its surrounding con- text, and a span prediction module is em- ployed to extract the text spans of the corefer- ences within the document using the generated query.
近期的方法有consider all text spans in a document as potential mentions and learn to find an antecedent for each possible mention. There。这种仅依靠mention的做对比的方法的缺点：
At the task formalization level： 因为当前数据集有很多遗漏的mention， mentions left out at the mention proposal stage can never be recov- ered since the downstream module only operates on the proposed mentions. At the algorithm level：Semantic matching operations be- tween two mentions (and their contexts) are per- formed only at the output layer and are relatively superficial 方法 Speaker information： directly concatenates the speaker’s name with the corresponding utterance.
...</p></div><footer class=entry-footer><span title='2021-05-11 00:00:00 +0000 UTC'>2021-05-11</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Cong Chan</footer><a class=entry-link aria-label="post link to CorefQA - Coreference resolution as query-based span prediction" href=https://congchan.github.io/posts/corefqa-coreference-resolution-as-query-based-span-prediction/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>在loss层面针对样本不平衡问题的优化</h2></header><div class=entry-content><p>针对样本不平衡问题，除了上下采样，调整样本权重等统计方法，还有可以通过对loss函数进行设计。
对于多分类问题（n选1），一般使用softmax；对于多标签分类问题（n选k），一般是转换为n各sigmoid二分类问题。
...</p></div><footer class=entry-footer><span title='2021-05-07 00:00:00 +0000 UTC'>2021-05-07</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Cong Chan</footer><a class=entry-link aria-label="post link to 在loss层面针对样本不平衡问题的优化" href=https://congchan.github.io/posts/%E5%9C%A8loss%E5%B1%82%E9%9D%A2%E9%92%88%E5%AF%B9%E6%A0%B7%E6%9C%AC%E4%B8%8D%E5%B9%B3%E8%A1%A1%E9%97%AE%E9%A2%98%E7%9A%84%E4%BC%98%E5%8C%96/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Early Rumour Detection</h2></header><div class=entry-content><p>2019, ACL
data: TWITTER, WEIBO
links: https://www.aclweb.org/anthology/N19-1163, https://github.com/DeepBrainAI/ERD
task: Rumour Detection
这篇文章采用GRU编码社交媒体posts stream，作为环境的状态表示；训练一个分类器以GRU的状态输出为输入，对文本做二分类判断是否是rumor。用DQN训练agent，根据状态做出是否启动rumor分类器进行判断，并根据分类结果对错给予奖惩。目标就是尽可能准尽可能早地预测出社交媒体posts是否是rumor。
Focuses on the task of rumour detection; particularly, we are in- terested in understanding how early we can detect them.
Our model treats social media posts (e.g. tweets) as a data stream and integrates reinforcement learning to learn the number minimum num- ber of posts required before we classify an event as a rumour.
Let $E$ denote an event, and it consists of a series of relevant posts $x_i$, where $x_0$ denotes the source message and $x_T$ the last relevant message. The objective of early rumor detection is to make a classification decision whether E is a rumour as early as possible while keeping an acceptable detection accuracy.
...</p></div><footer class=entry-footer><span title='2021-05-01 00:00:00 +0000 UTC'>2021-05-01</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;Cong Chan</footer><a class=entry-link aria-label="post link to Early Rumour Detection" href=https://congchan.github.io/posts/early-rumour-detection/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Matching the Blanks - Distributional Similarity for Relation Learning</h2></header><div class=entry-content><p>2019, ACL
data: KBP37, SemEval 2010 Task 8, TACRED
task: Entity and Relation Extraction
Build task agnostic relation representations solely from entity-linked text.
缺陷 文章认为网页中, 相同的的实体对一般指代相同的实体关系, 把实体不同的构建为负样本. 这个在单份文件中可能大概率是对的.
但是实体不完全一直不代表这个两对实体的关系不同. 所以这个作为负样本是本质上映射的是实体识别而不是关系.
比较好的方式是把实体不同但是关系一样的也考虑进来.
方法 Define Relation Statement We define a relation statement to be a block of text containing two marked entities. From this, we create training data that contains relation statements in which the entities have been replaced with a special [BLANK]
...</p></div><footer class=entry-footer><span title='2021-04-21 00:00:00 +0000 UTC'>2021-04-21</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;Cong Chan</footer><a class=entry-link aria-label="post link to Matching the Blanks - Distributional Similarity for Relation Learning" href=https://congchan.github.io/posts/matching-the-blanks-distributional-similarity-for-relation-learning/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>A Frustratingly Easy Approach for Joint Entity and Relation Extraction</h2></header><div class=entry-content><p>2020, NAACL
data: ACE 04, ACE 05, SciERC
links: https://github.com/princeton-nlp/PURE
task: Entity and Relation Extraction
提出了一种简单但是有效的pipeline方法:builds on two independent pre-trained encoders and merely uses the entity model to provide input features for the relation model.
实验说明: validate the importance of
learning distinct contextual representations for entities and relations, fusing entity information at the input layer of the relation model, and incorporating global context. 从效果上看, 似乎是因为cross sentence的context加成更大
方法 Input: a sentence X consisting of n tokens x1, . . . , xn. Let S = {s1, . . . , sm} be all the possible spans in X of up to length L and START(i) and END(i) denote start and end indices of si.
...</p></div><footer class=entry-footer><span title='2021-04-20 00:00:00 +0000 UTC'>2021-04-20</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Cong Chan</footer><a class=entry-link aria-label="post link to A Frustratingly Easy Approach for Joint Entity and Relation Extraction" href=https://congchan.github.io/posts/a-frustratingly-easy-approach-for-joint-entity-and-relation-extraction/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Two are Better than One - Joint Entity and Relation Extraction with Table-Sequence Encoders</h2></header><div class=entry-content><p>2020, EMNLP
data: ACE 04, ACE 05, ADE, CoNLL04
links: https://github.com/LorrinWWW/two-are-better-than-one.
task: Entity and Relation Extraction
In this work, we propose the novel table-sequence encoders where two different encoders – a table encoder and a sequence encoder are designed to help each other in the representation learning process.
这篇ACL 2020文章认为, 之前的Joint learning方法侧重于learning a single encoder (usually learning representation in the form of a table) to capture information required for both tasks within the same space. We argue that it can be beneficial to design two distinct encoders to capture such two different types of information in the learning process.
...</p></div><footer class=entry-footer><span title='2021-03-27 00:00:00 +0000 UTC'>2021-03-27</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Cong Chan</footer><a class=entry-link aria-label="post link to Two are Better than One - Joint Entity and Relation Extraction with Table-Sequence Encoders" href=https://congchan.github.io/posts/two-are-better-than-one-joint-entity-and-relation-extraction-with-table-sequence-encoders/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Improving Event Detection via Open-domain Trigger Knowledge</h2></header><div class=entry-content><p>2020, ACL
data: ACE 05
task: Event Detection
Propose a novel Enrichment Knowledge Distillation (EKD) model to efficiently distill external open-domain trigger knowledge to reduce the in-built biases to frequent trigger words in annotations.
leverage the wealth of the open-domain trigger knowledge to improve ED propose a novel teacher-student model (EKD) that can learn from both labeled and unlabeled data 缺点 只能对付普遍情况, 即一般性的触发词; 但触发词不是在任何语境下都是触发词.
方法 empower the model with external knowledge called Open-Domain Trigger Knowledge, defined as a prior that specifies which words can trigger events without subject to pre-defined event types and the domain of texts.
...</p></div><footer class=entry-footer><span title='2021-03-25 00:00:00 +0000 UTC'>2021-03-25</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;Cong Chan</footer><a class=entry-link aria-label="post link to Improving Event Detection via Open-domain Trigger Knowledge" href=https://congchan.github.io/posts/improving-event-detection-via-open-domain-trigger-knowledge/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Cross-media Structured Common Space for Multimedia Event Extraction</h2></header><div class=entry-content><p>2020, ACL Task: MultiMedia Event Extraction
Introduce a new task, MultiMedia Event Extraction (M2E2), which aims to extract events and their arguments from multimedia documents. Construct the first benchmark and evaluation dataset for this task, which consists of 245 fully annotated news articles
Propose a novel method, Weakly Aligned Structured Embedding (WASE), that encodes structured representations of semantic information from textual and visual data into a common embedding space. which takes advantage of annotated unimodal corpora to separately learn visual and textual event extraction, and uses an image-caption dataset to align the modalities
...</p></div><footer class=entry-footer><span title='2021-03-24 00:00:00 +0000 UTC'>2021-03-24</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Cong Chan</footer><a class=entry-link aria-label="post link to Cross-media Structured Common Space for Multimedia Event Extraction" href=https://congchan.github.io/posts/cross-media-structured-common-space-for-multimedia-event-extraction/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://congchan.github.io/page/2/>«&nbsp;Prev&nbsp;2/14
</a><a class=next href=https://congchan.github.io/page/4/>Next&nbsp;4/14&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://congchan.github.io/>Cong's Log</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>