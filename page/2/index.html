<!doctype html><html lang=en dir=auto><head><meta name=generator content="Hugo 0.147.9"><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Cong's Log</title><meta name=description content="Hi, this is Cong. I’m documenting my learning notes in this blog."><meta name=author content="Cong"><link rel=canonical href=https://congchan.github.io/><link crossorigin=anonymous href=/assets/css/stylesheet.1f908d890a7e84b56b73a7a0dc6591e6e3f782fcba048ce1eb46319195bedaef.css integrity="sha256-H5CNiQp+hLVrc6eg3GWR5uP3gvy6BIzh60YxkZW+2u8=" rel="preload stylesheet" as=style><link rel=icon href=https://congchan.github.io/favicons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://congchan.github.io/favicons/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://congchan.github.io/favicons/favicon-32x32.png><link rel=apple-touch-icon href=https://congchan.github.io/favicons/apple-touch-icon.png><link rel=mask-icon href=https://congchan.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://congchan.github.io/index.xml><link rel=alternate type=application/json href=https://congchan.github.io/index.json><link rel=alternate hreflang=en href=https://congchan.github.io/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}]})'></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-6T0DPR6SMC"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-6T0DPR6SMC")}</script><meta property="og:url" content="https://congchan.github.io/"><meta property="og:site_name" content="Cong's Log"><meta property="og:title" content="Cong's Log"><meta property="og:description" content="Hi, this is Cong. I’m documenting my learning notes in this blog."><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Cong's Log"><meta name=twitter:description content="Hi, this is Cong. I’m documenting my learning notes in this blog."><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"Cong's Log","url":"https://congchan.github.io/","description":"Hi, this is Cong. I’m documenting my learning notes in this blog.","logo":"https://congchan.github.io/favicons/favicon.ico","sameAs":["https://github.com/congchan"]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://congchan.github.io/ accesskey=h title="Cong's Log (Alt + H)">Cong's Log</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://congchan.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://congchan.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://congchan.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Paper Reading - Let’s Verify Step by Step</h2></header><div class=entry-content><p>TLDR In order to train more dependable models, there are two known options: outcome supervision, which gives feedback on the final result, and process supervision, which provides feedback on each intermediate reasoning step.
This papers provides two finding:
The use of process supervision yields significantly better results than outcome supervision when training models to solve problems from the challenging MATH dataset. The efficacy of process supervision is significantly improved by active learning. The exclusive focus of this paper is to provide insights on training the most reliable reward model.
...</p></div><footer class=entry-footer><span title='2023-06-18 00:00:00 +0000 UTC'>2023-06-18</span>&nbsp;·&nbsp;9 min&nbsp;·&nbsp;Cong</footer><a class=entry-link aria-label="post link to Paper Reading - Let’s Verify Step by Step" href=https://congchan.github.io/posts/paper-reading-lets-verify-step-by-step/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>John Schulman和Yoav Goldberg关于Behavior Cloning(BC)、RL and Truthfulness的观点</h2></header><div class=entry-content><p>Cong Chen
University of Edinburgh
John Schulman最近在Berkeley分享了关于BC、RLHF and Truthfulness的观点1，Yoav Goldberg也针对John Schulman的观点进行了总结和扩展2，同时南大的俞扬教授也对BC和RL的对比进行了观点分享3。
归纳的核心观点有三个：
Behavior Cloning（BC, learning from demonstrations, or SFT）是最Effective的方法。RLHF过程中重度使用了BC，包括冷启动和奖励模型训练都用了BC。虽然BC更有效，相比RL也更容易work，但BC因为自身局限性，有一些固有的问题无法解决： 核心问题是，BC训练越泛化意味着LLM越会Hallucination和撒谎；而我们想鼓励LLM根据它的内部知识来回答，问题是我们不知道其内部知识包含什么，所以要利用RLHF让LLM知道什么问题是超过自己的知识范围的（让模型知道自己不知道）。 除此之外，RL还允许负反馈，而 negative feedback is much more powerful 基于 Ranking 的 Reward学习虽然不够好，但是实践起来更容易 未来优化方向：当LLM知道自己不知道时，目前更多的是诚实地表达“I dont know”来拒识，OpenAI的方向是让LLM尝试去搜索外部知识，生成更可信、带citing source的回答，也就是从Honest进化到Truthfulness。参考下面的 ChatGPT Browsing 详细分享 - by John Schulman Why there is Hallucination Is “if a model know something” a meaningful question? RL is the correct ways Long form QA (LFQA) is much difficult that short QA
...</p></div><footer class=entry-footer><span title='2023-04-30 00:00:00 +0000 UTC'>2023-04-30</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Cong Chan</footer><a class=entry-link aria-label="post link to John Schulman和Yoav Goldberg关于Behavior Cloning(BC)、RL and Truthfulness的观点" href=https://congchan.github.io/posts/john-schulman%E5%92%8Cyoav-goldberg%E5%85%B3%E4%BA%8Ebehavior-cloningbcrl-and-truthfulness%E7%9A%84%E8%A7%82%E7%82%B9/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Paper Reading - Complexity-Based Prompting for Multi-Step Reasoning</h2></header><div class=entry-content><p>Tags: 2023, ICLR Links: https://github.com/FranxYao/chain-of-thought-hub Paper: Fu, Yao, et al. Complexity-Based Prompting for Multi-Step Reasoning. arXiv:2210.00720, arXiv, 30 Jan. 2023. arXiv.org, http://arxiv.org/abs/2210.00720.
Motivation Example selection is a central problem in the prompting literature.
For CoT prompting, example selection is further related to annotation efficiency, as CoT requires manually-annotated reasoning chains. Which reasoning examples make the most effective prompts.
Propose complexity-based prompting, a simple and effective example selection scheme for multi-step reasoning. We show that prompts with higher reasoning complexity, i.e., chains with more reasoning steps, achieve substantially better performance on multistep reasoning tasks over strong baselines.
...</p></div><footer class=entry-footer><span title='2023-04-19 00:00:00 +0000 UTC'>2023-04-19</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Cong</footer><a class=entry-link aria-label="post link to Paper Reading -  Complexity-Based Prompting for Multi-Step Reasoning" href=https://congchan.github.io/posts/paper-reading-complexity-based-prompting-for-multi-step-reasoning/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>CoT on BBH - Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them</h2></header><div class=entry-content><p>CoT on BBH：M. Suzgun et al., ‘Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them’. arXiv, Oct. 17, 2022. Available: http://arxiv.org/abs/2210.09261
Method Applying chain-of-thought (CoT) prompting to BIG-Bench Hard tasks
Evaluate few-shot performance via standard “answer-only” prompting and chain-of-thought prompting on BIG-Bench Hard Benchmark
Results/Analysis/Findings Benchmark: BIG-Bench Hard (BBH). These are the task for which prior language model evaluations did not outperform the average human-rater. many tasks in BBH require multi-step reasoning
...</p></div><footer class=entry-footer><span title='2022-11-13 00:00:00 +0000 UTC'>2022-11-13</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Cong Chan</footer><a class=entry-link aria-label="post link to CoT on BBH - Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them" href=https://congchan.github.io/posts/cot-on-bbh-challenging-big-bench-tasks-and-whether-chain-of-thought-can-solve-them/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Efficient Training of Language Models to Fill in the Middle</h2></header><div class=entry-content><p>Bavarian, Mohammad, et al. Efficient Training of Language Models to Fill in the Middle. arXiv:2207.14255, arXiv, 28 July 2022. arXiv.org, http://arxiv.org/abs/2207.14255. data: https://www.github.com/openai/human-eval-infilling
TL:DR Autoregressive language models can effectively learn to infill text by moving a span of text from the middle of a document to its end, without harming the original generative capability. The training models with this technique, called fill-in-the-middle (FIM), is useful, simple, and efficient, and should be used by default in future autoregressive language models. The study provides best practices and strong default settings for training FIM models and releases infilling benchmarks to aid future research.
...</p></div><footer class=entry-footer><span title='2022-11-11 00:00:00 +0000 UTC'>2022-11-11</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;Cong Chan</footer><a class=entry-link aria-label="post link to Efficient Training of Language Models to Fill in the Middle" href=https://congchan.github.io/posts/efficient-training-of-language-models-to-fill-in-the-middle/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>The Curious Case of Neural Text Degeneration</h2></header><div class=entry-content><p>Holtzman, Ari, et al. The Curious Case of Neural Text Degeneration. arXiv:1904.09751, arXiv, 14 Feb. 2020. arXiv.org, http://arxiv.org/abs/1904.09751.
Introduction 从语言模型生成文本（例如生成故事）的最佳解码策略是什么仍然是一个悬而未决的问题。违反直觉的经验观察是，即使使用似然作为训练目标可以为广泛的语言理解任务生成高质量的模型，但基于maximization-based decoding的解码方法（例如beam search）会导致退化（degeneration）——输出文本平淡无奇，不连贯，或陷入重复循环。
文本生成中的decoding strategy主要可以分为两大类：
Argmax Decoding: 主要包括beam search, class-factored softmax等 Stochastic Decoding: 主要包括temperature sampling, top-k sampling等 为了解决这个问题，提出了 Nucleus Sampling（Top-p Sampling），这是一种简单但有效的方法，可以从神经语言模型中提取比以前的解码策略质量更高的文本。The key idea is to use the shape of the probability distribution to determine the set of tokens to be sampled from.
Method 通过截断概率分布的不可靠尾部分布、从包含绝大多数概率质量的标记的dynamic nucleus中采样来避免文本退化。
效果/Analysis/Findings 为了正确检查当前基于最大化和随机的解码方法，我们将这些方法中的每一种的生成与人类文本从几个方向（如可能性、多样性和重复）的分布进行了比较。
...</p></div><footer class=entry-footer><span title='2021-12-23 00:00:00 +0000 UTC'>2021-12-23</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;Cong Chan</footer><a class=entry-link aria-label="post link to The Curious Case of Neural Text Degeneration" href=https://congchan.github.io/posts/the-curious-case-of-neural-text-degeneration/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Codex - Evaluating Large Language Models Trained on Code</h2></header><div class=entry-content><p>Codex：M. Chen et al., ‘Evaluating Large Language Models Trained on Code’. arXiv, Jul. 14, 2021. Available: http://arxiv.org/abs/2107.03374
Intro Codex, a GPT language model finetuned on publicly available code from GitHub
Task: docstring-conditional code generation
Method Codex: fine-tune GPT3 models containing up to 12B parameters on code to produce Codex.
Codex-S: fine-tune Codex on standalone, correctly implemented functions.
Inference: assemble each HumanEval problem into a prompt consisting of a header, a signature, and a docstring. We use nucleus sampling (Holtzman et al., 2020) with top p = 0.95 for all sampling evaluation in this work
...</p></div><footer class=entry-footer><span title='2021-12-20 00:00:00 +0000 UTC'>2021-12-20</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;Cong Chan</footer><a class=entry-link aria-label="post link to Codex - Evaluating Large Language Models Trained on Code" href=https://congchan.github.io/posts/codex-evaluating-large-language-models-trained-on-code/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Scaling Laws for Neural Language Models</h2></header><div class=entry-content><p>Kaplan, Jared, et al. ‘Scaling Laws for Neural Language Models’. arXiv:2001.08361 [Cs, Stat], Jan. 2020. arXiv.org, http://arxiv.org/abs/2001.08361.
TL:DR key findings for Transformer language models are are as follows:
Performance depends strongly on scale, weakly on model shape: Model performance depends most strongly on scale, which consists of three factors: the number of model parameters N (excluding embeddings), the size of the dataset D, and the amount of compute C used for training. Within reasonable limits, performance depends very weakly on other architectural hyperparameters such as depth vs. width. (Section 3) Smooth power laws: Performance has a power-law relationship with each of the three scale factors N, D, C when not bottlenecked by the other two, with trends spanning more than six orders of magnitude (see Figure 1). We observe no signs of deviation from these trends on the upper end, though performance must flatten out eventually before reaching zero loss. (Section 3) ...</p></div><footer class=entry-footer><span title='2021-12-19 00:00:00 +0000 UTC'>2021-12-19</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;Cong Chan</footer><a class=entry-link aria-label="post link to Scaling Laws for Neural Language Models" href=https://congchan.github.io/posts/scaling-laws-for-neural-language-models/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Switch Transformers - Scaling to Trillion Parameter Models with Simple and Efficient Sparsity</h2></header><div class=entry-content><p>Links: https://arxiv.org/abs/2101.03961
“SWITCH TRANSFORMERS: SCALING TO TRILLION PARAMETER MODELS WITH SIMPLE AND EFFICIENT SPARSITY”，提出了一种可以扩展到万亿参数的网络，有两个比较大的创新，基于Transformer MoE网络结构，简化了MoE的routing机制，降低了计算量；进一步通过数据并行+模型并行+expert并行的方式降低了训练通信量，提升训练性能。
模型 Simplifying Sparse Routing Mixture of Expert Routing which takes as an input a token representation x and then routes this to the best deter- mined top-k experts Switch Routing: route to only a single expert, this simplification preserves model quality, reduces routing computation and performs better. Sparse routing通过参数Wr计算出一个在N个experts上的softmax分布，对每个token输入筛选概率最高的 top k 个 experts，对应的是MOE中的门控机制。这样对算力的需求并没有随着参数量的增加而大幅增长，使得这个模型更加容易训练。
...</p></div><footer class=entry-footer><span title='2021-07-10 00:00:00 +0000 UTC'>2021-07-10</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Cong Chan</footer><a class=entry-link aria-label="post link to Switch Transformers - Scaling to Trillion Parameter Models with Simple and Efficient Sparsity" href=https://congchan.github.io/posts/switch-transformers-scaling-to-trillion-parameter-models-with-simple-and-efficient-sparsity/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Mixture of Experts (MOE)</h2></header><div class=entry-content><p>Mixture of Experts (MOE) MOE属于Ensemble Method中的一个方法, 采用分治思想：
将复杂的建模任务分解为多个相对简单的子任务，为每个子任务训练专门的模型：涉及子任务分解，或者Clustering 需要一个门控模型，基于数据输入选择如何组合多个专家模型的结果 Mixture of experts aims at increasing the accuracy of a function approximation by replacing a single global model by a weighted sum of local models (experts). It is based on a partition of the problem domain into several subdomains via clustering algorithms followed by a local expert training on each subdomain.
Local Models & Global Models Hinton的课件介绍了模型拟合分布的两个极端方式:
...</p></div><footer class=entry-footer><span title='2021-07-03 00:00:00 +0000 UTC'>2021-07-03</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;Cong Chan</footer><a class=entry-link aria-label="post link to Mixture of Experts (MOE)" href=https://congchan.github.io/posts/mixture-of-experts-moe/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://congchan.github.io/>«&nbsp;Prev&nbsp;1/14
</a><a class=next href=https://congchan.github.io/page/3/>Next&nbsp;3/14&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://congchan.github.io/>Cong's Log</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>